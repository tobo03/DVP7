{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrainedModel import pretrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "image = Image.fromarray(x_train[0]).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pretrainedModel()\n",
    "model(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB7ElEQVR4nO2UP8hxURjAz0VKittd/CuLwSDKICWDDEbdE5OyyMZksTEpg0ky3AwmC2VQdyAKpQwGA5IMhJXrT7crx32H2/flfT/vHzJ93/ebTj3P+XWenvM8APzn70EsFhO/SCQS6XS6Wq1qtdpSqcTzPMuyyWTyNl/ymUiv10ulUofD4XQ6cRz3+Xy30dVqlc1mIYSHw2E4HLbb7dsodtdotVqbzaZSqbwbvV6voVDodDoBADabzXa7nU6n39dLEMRsNkPv6fV6NE2zLMswzPeKu5AkWSgUIpGIYBwMBnK5HABgMpkoinpSCgBQKBQYhlEUhRAKBAI/vyj6Irbf73meF4oNh8Mi0VfJjyGXy1utFkLI4/G8TAoAMBgMDMMsFotisRiNRjHs/p95GAjhbrcTmhaPxzUazWu8ZrO5Xq8L3nw+r9PpXuPFcTwYDF4uF4RQo9F4jVSA4ziEEMdxLpfrbsKns/8nFovF7/fbbDaJRAIAGI/HnU7n+acZjcZcLrder3+P7Pl8pmn6SZ1arY7FYvP5/HYJ9Pt9r9f7jE6lUrnd7tFo9GGnQAifGS2CIMrl8oct1e12SZKUyWQP6+x2e6VSWS6Xt7rj8ZhKpYQV9UPedR9CCCEUzpPJpFarIYQymcxut3v4gf8wb5vwG2+h9UGFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "n_hash = 32\n",
    "\n",
    "model2 = nn.Sequential(nn.Linear( 2048 , 128 ),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear( 128 ,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, n_hash ),\n",
    "                     nn.Sigmoid()\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4673, 0.5045, 0.5344, 0.5262, 0.4840, 0.4839, 0.4896, 0.5186, 0.5215,\n",
       "        0.4847, 0.5193, 0.4905, 0.5079, 0.5002, 0.4955, 0.5085, 0.4890, 0.4833,\n",
       "        0.4876, 0.4926, 0.4990, 0.4897, 0.4726, 0.5146, 0.4843, 0.4990, 0.4974,\n",
       "        0.4808, 0.5122, 0.5399, 0.5172, 0.4935], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(model(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11\n",
      "35\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 5:\n",
    "        print(i)\n",
    "    \n",
    "    if i == 50: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABN0lEQVR4nO3TIc+CUBSA4buxOeccASkWjWC1uJmlYqCazEaLTTZG1kJwbCTGH7DwE+4YmVlwsziubIxAPIcvMA3Gi+ELPPGEd/du5xDS6fwf0+lUVVXTNBljjDHP81rlVquV4zhFUSAivCVJwplzXZdSim9lWTqOs91u+/0+T240Gl0uF0TM8zyKIsMwFEWZTCacr2ucTicAOJ/Pw+GwVYgQMhgMTNNM01TX9fV6zfnNL7ZtA0AQBL/JNeq6RkRd139WJIRQSgHg8Xhomta2tVgser0eIUSSpOPxCABlWc5mM87ceDyO4/j1em02m2Yiy3Kz3svlkjP6fD6rqtrtdp+JZVkAEIahKIqc0cPhUFXV52Zutxsi3u/3+XzOWWzs93vf97Msy7KMMXa9XhVFEQShVbTT4fYHAzWm/4A5kgIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Image.fromarray(x_train[11]).convert('RGB')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABlklEQVR4nO3Ur6vCUBQH8HMPY2BRFOQGRVgQ20wGDSIMRGxaZ1bw3zAJZpNJk02TwWRzOKMLKoJDQdtAUATZXhDU54/r3jC9975p9+zuc8/gcAH+8/sjSdJms4lEInd1vF0kk8lcLmcfjcViqqo+1r+hqVQqn8/bFBFREIRQKEQIYe2bz+etVssmGggETNNsNptvOkXExx2v0mg0AGA2m7FQURQppfZRj8cDAP1+n4Vms1mXy2VTpJQKggAA6/WahZ4nYzKZ2EFrtRqldDqd7na7x7fc3Xo0GjEst9udyWQKhUI6nQaASqViGMZ71OfzXZ6j0SgiSpIUDAZ5npdlGREPh4OiKMfjkeO48Xj89OzriNXr9VKpZBiGruvniiiKhJDT6bTf7zVNUxRFVdXBYLDdblerldfr5Xn+KXrttFwuL5fLRCJxqei63u12NU0bDoe33xSLRb/fv1gsnooO0263TdOsVquvNvxg2u/S6XQ+jzLiECWEhMPhD6OWZTEuCue/H4/HP4yy71AnaK/XsyzLWTd/IV/VrISFLCLl1wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Image.fromarray(x_train[2]).convert('RGB')\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5012, 0.4754, 0.5356, 0.5246, 0.4974, 0.4821, 0.4993, 0.4790, 0.5156,\n",
       "        0.5093, 0.5003, 0.5230, 0.4887, 0.5042, 0.4769, 0.5275, 0.4732, 0.4994,\n",
       "        0.5045, 0.5397, 0.4781, 0.4988, 0.5122, 0.4865, 0.4813, 0.4959, 0.4778,\n",
       "        0.5283, 0.4705, 0.5014, 0.5049, 0.4904], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4994, 0.4757, 0.5338, 0.5262, 0.4970, 0.4819, 0.4987, 0.4775, 0.5166,\n",
       "        0.5127, 0.5004, 0.5209, 0.4863, 0.5065, 0.4804, 0.5270, 0.4757, 0.5003,\n",
       "        0.5031, 0.5374, 0.4737, 0.4983, 0.5097, 0.4839, 0.4805, 0.4987, 0.4773,\n",
       "        0.5272, 0.4784, 0.4974, 0.5034, 0.4905], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pExam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5019, 0.4749, 0.5347, 0.5214, 0.4992, 0.4819, 0.4958, 0.4798, 0.5133,\n",
       "        0.5090, 0.5018, 0.5253, 0.4895, 0.5074, 0.4778, 0.5248, 0.4751, 0.4979,\n",
       "        0.5063, 0.5396, 0.4773, 0.4983, 0.5106, 0.4851, 0.4821, 0.4964, 0.4777,\n",
       "        0.5261, 0.4736, 0.4972, 0.5017, 0.4880], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nExam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n",
    "optimizer = optim.SGD(model2.parameters(),lr=0.7, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9961, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor = model2(model(image))\n",
    "pExam =  model2(model(p))\n",
    "nExam =  model2(model(n))\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = triplet_loss(\n",
    "            torch.stack([anchor,anchor]), \n",
    "            torch.stack([pExam,pExam]), \n",
    "            torch.stack([nExam,nExam]))\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4673, 0.5045, 0.5344, 0.5262, 0.4840, 0.4839, 0.4896, 0.5186, 0.5215,\n",
       "         0.4847, 0.5193, 0.4905, 0.5079, 0.5002, 0.4955, 0.5085, 0.4890, 0.4833,\n",
       "         0.4876, 0.4926, 0.4990, 0.4897, 0.4726, 0.5146, 0.4843, 0.4990, 0.4974,\n",
       "         0.4808, 0.5122, 0.5399, 0.5172, 0.4935],\n",
       "        [0.4673, 0.5045, 0.5344, 0.5262, 0.4840, 0.4839, 0.4896, 0.5186, 0.5215,\n",
       "         0.4847, 0.5193, 0.4905, 0.5079, 0.5002, 0.4955, 0.5085, 0.4890, 0.4833,\n",
       "         0.4876, 0.4926, 0.4990, 0.4897, 0.4726, 0.5146, 0.4843, 0.4990, 0.4974,\n",
       "         0.4808, 0.5122, 0.5399, 0.5172, 0.4935]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([anchor,anchor])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
