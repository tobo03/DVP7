{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            output = model(data)\n",
    "            output = output.view(data.size(0), -1)  # Flatten the output\n",
    "            features.append(output)\n",
    "            labels.append(target)\n",
    "    return torch.cat(features), torch.cat(labels)\n",
    "\n",
    "from torchvision import models\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier = torch.nn.Identity()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(281)\n",
    "dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "indices = np.random.permutation(len(dataset)) #with no permutation\n",
    "graphDB_indices = indices[:50] #50 images as Graph DB\n",
    "graphDB_subset = Subset(dataset, graphDB_indices)\n",
    "graphDB_loader = DataLoader(graphDB_subset, batch_size=16, shuffle=True)\n",
    "query_indices = indices[50:55] #5 images for query\n",
    "query_subset = Subset(dataset, query_indices)\n",
    "query_loader = DataLoader(query_subset, batch_size=16, shuffle=True)\n",
    "\n",
    "graphDB_features, graphDB_labels = extract_features(graphDB_loader, model)\n",
    "query_featuers, query_labels = extract_features(query_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSH med random projection \n",
    "def random_projection_lsh(data:list[list[float]], n_hash:int=20, seed = 1) -> list[int]:\n",
    "    \"\"\"\"    \n",
    "    data : a single image as a matrix of floats\n",
    "    n_hash : size of the hash\n",
    "    returns: list of binary values\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_dimensions = data.shape[1]\n",
    "    random_vectors = np.random.randn(n_hash, n_dimensions)\n",
    "    projections = np.dot(data, random_vectors.T)\n",
    "    hash_codes = (projections > 0).astype(int)\n",
    "    result_tensor = torch.tensor(hash_codes) #numpy arrays to 2 dimensional tensors\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_codes = random_projection_lsh(graphDB_features)\n",
    "query_codes = random_projection_lsh(query_featuers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def hamming_distance(b1, b2):\n",
    "    if len(b1) != len(b2):\n",
    "        raise ValueError(\"Input not in same length\")\n",
    "    return sum(b1 != b2 for b1,b2 in zip(b1,b2)) #zip create parelle interator like (a,1), (b,2) etc.\n",
    "\n",
    "def calculate_similarity(query_codes, hamming_codes):\n",
    "    '''\n",
    "    Hamming codes: Graph database binary codes\n",
    "    query codes: binary code for the query picture\n",
    "    '''\n",
    "    # Initialize the similarity matrix with zeros\n",
    "    similarity_matrix = torch.zeros(query_codes.size(0), hamming_codes.size(0))  # shape (num_queries, num_codes)\n",
    "\n",
    "    for i, query in enumerate(query_codes):  # Iterate over each query\n",
    "        for j, code in enumerate(hamming_codes):  # Iterate over each Hamming code\n",
    "            distance = hamming_distance(query, code)  # Calculate the Hamming distance\n",
    "            similarity_matrix[i, j] = distance  # Fill the similarity matrix\n",
    "\n",
    "    return similarity_matrix  # Return the similarity matrix\n",
    "\n",
    "def mean_average_precision(similarity_matrix, query_labels, graphDB_labels): \n",
    "    #input: similairty matrix: sim matrix for object i and j\n",
    "    #query labels, \n",
    "    #hamming labels are training labels\n",
    "    average_precision = []\n",
    "\n",
    "    query_labels = torch.tensor(query_labels)\n",
    "    graphDB_labels = torch.tensor(graphDB_labels)\n",
    "\n",
    "    for i in range(0, 4): #interate thourgh number of queries\n",
    "        similarities = similarity_matrix[i] #get simlarity for the current query\n",
    "        sorted_indices = similarities.argsort(descending=True) #for each similarity \n",
    "        sorted_labels = graphDB_labels[sorted_indices]\n",
    "\n",
    "        relevant_indices = (sorted_labels == query_labels[i]).nonzero(as_tuple=True)[0] #store kth indexes in sorted G' where True occurs \n",
    "\n",
    "        if len(relevant_indices) > 0:\n",
    "            precision_at_k = torch.arange(1, len(relevant_indices)+1).float()/(relevant_indices+1) #incrementally compute mean of relevant indices, for example if you have 1, 5, 7, relevant indices, then you get 1 + 0.0...+2/6 +...3/8   \n",
    "            #torch arrange is Returns a 1-D tensor of size end - start/step, with values from the interval [start, end) taken with common difference step beginning from start.\n",
    "            average_precision.append(precision_at_k.mean().item())\n",
    "        else:\n",
    "            average_precision.append(0.0) \n",
    "\n",
    "    return torch.tensor(average_precision).mean().item() #average over all mean average for each query stored in average_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = calculate_similarity(query_codes = query_codes, hamming_codes = hamming_codes) #each contains hamming distances for between graphDB and query image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_12248\\3185815265.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_labels = torch.tensor(query_labels)\n",
      "C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_12248\\3185815265.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  graphDB_labels = torch.tensor(graphDB_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10090954601764679"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(sim_matrix, query_labels, graphDB_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  7.,  7.,  8.,  7., 10.,  6.,  6.,  6., 10., 11., 11., 12.,  7.,\n",
       "          4., 10.,  8.,  7., 10.,  5.,  5.,  8.,  6.,  9.,  6.,  5.,  6.,  8.,\n",
       "          9.,  9.,  9.,  9.,  8., 10.,  8.,  7., 10.,  3.,  7.,  5.,  9., 11.,\n",
       "          9.,  4.,  9.,  7.,  6.,  6.,  8.,  9.],\n",
       "        [10.,  7.,  7.,  8.,  9.,  8.,  6.,  6.,  6.,  8., 11., 11., 12.,  9.,\n",
       "          8.,  8.,  8.,  5.,  6.,  9.,  3., 10.,  8.,  7., 10.,  7.,  6.,  6.,\n",
       "          7.,  7.,  9.,  7.,  8.,  8., 10.,  9., 10.,  7.,  7.,  7.,  9., 11.,\n",
       "         13.,  6.,  9.,  7.,  4.,  8.,  8.,  7.],\n",
       "        [ 9., 10.,  6.,  7.,  6.,  9.,  7.,  7.,  9.,  9., 10., 10., 13., 12.,\n",
       "          9., 13., 11.,  4.,  7.,  6.,  4.,  9.,  7.,  8.,  9.,  4.,  7.,  5.,\n",
       "         10.,  8., 12.,  6.,  5., 13.,  9.,  8., 11.,  6., 10.,  6., 10., 12.,\n",
       "         10.,  5.,  8., 12.,  7.,  7.,  7., 10.],\n",
       "        [13., 12., 10., 11., 12., 11.,  7.,  9.,  9.,  9., 12., 12., 11.,  8.,\n",
       "          7., 11.,  9.,  8.,  5., 14.,  8., 11.,  9.,  6., 11.,  6.,  9.,  9.,\n",
       "         10., 10.,  8.,  4., 11.,  9.,  9., 12.,  9.,  8.,  8., 10.,  8., 10.,\n",
       "         10.,  9., 14.,  8., 11.,  9., 13., 12.],\n",
       "        [ 9.,  6.,  6.,  9.,  6.,  3.,  9.,  9.,  9.,  7.,  6.,  8.,  7.,  8.,\n",
       "          9.,  7.,  9.,  8.,  9.,  6.,  6.,  5.,  9., 10.,  7.,  8.,  9.,  7.,\n",
       "         10.,  4., 10., 12.,  7., 11.,  7.,  8.,  9., 10.,  8.,  8., 10.,  8.,\n",
       "          6.,  9.,  6., 10.,  7.,  7.,  5.,  6.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,10+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#First make a subset for train test validation split, then a subset for query database\n",
    "#use indices tracking to implement to ensure no replacement\n",
    "np.random.seed(281)\n",
    "dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "indices = np.random.permutation(len(dataset)) #with no permutation\n",
    "\n",
    "training_indices = indices[:180]\n",
    "#validation_indices = indices[180:240]\n",
    "#test_indices = indices[240:300]\n",
    "query_indices = indices[300:330]\n",
    "#graphDB_indices = indices[360:460]\n",
    "\n",
    "train_subset = Subset(dataset, training_indices)\n",
    "#validation_subset = Subset(dataset, validation_indices)\n",
    "#test_subset = Subset(dataset, test_indices)\n",
    "query_subset = Subset(dataset, query_indices)\n",
    "#graphDB_subset = Subset(dataset, graphDB_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\n",
    "#valid_loader = DataLoader(validation_subset, batch_size=16, shuffle=True)\n",
    "#test_loader = DataLoader(test_subset, batch_size=16, shuffle=True)\n",
    "query_loader = DataLoader(query_subset, batch_size=16, shuffle=True)\n",
    "#graphDB_loader = DataLoader(graphDB_subset, batch_size=16, shuffle=True)\n",
    "\n",
    "train_features, train_labels = extract_features(train_loader, model)\n",
    "#valid_featuers, valid_labels = extract_features(valid_loader, model)\n",
    "#test_featuers, test_labels = extract_features(test_loader, model)\n",
    "query_featuers, query_labels = extract_features(query_loader, model)\n",
    "#DB_featuers, DB_labels = extract_features(graphDB_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_defined_CNN(nn.Module): #kan bruges senere\n",
    "    def __init__(self, output_dim): #output_dim: length of binary codes generated\n",
    "        super(HashingNet, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, stride=1) ##3 convolutaion pooling layers with 32, 32, and 64 5X5 filters \n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2) #2D max pool filter 3X3 stride 2\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5, stride=1)\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d(3, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5, stride=1)\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d(3, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 500) #\n",
    "        self.fc2 = nn.Linear(500, output_dim) #number of binary codes you'd to generated\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))  #apply ReLU on reuslts of a convulutional layer\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1) #flatten the tensor to feed to fully connected layer\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSH med random projection \n",
    "def random_projection_lsh(data:list[list[float]], n_hash:int=64, seed = 1) -> list[int]:\n",
    "    \"\"\"\"    \n",
    "    data : a single image as a matrix of floats\n",
    "\n",
    "    n_hash : size of the hash\n",
    "    \n",
    "    returns: list of binary values\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_dimensions = data.shape[1]\n",
    "    random_vectors = np.random.randn(n_hash, n_dimensions)\n",
    "    projections = np.dot(data, random_vectors.T)\n",
    "    hash_codes = (projections > 0).astype(int)\n",
    "    return hash_codes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def hamming_distance(b1, b2):\n",
    "    if len(b1) != len(b2):\n",
    "        raise ValueError(\"Input not in same length\")\n",
    "    return sum(b1 != b2 for b1,b2 in zip(b1,b2)) #zip create parelle interator like (a,1), (b,2) etc.\n",
    "\n",
    "def calculate_similarity(query_codes, hamming_codes):\n",
    "    '''\n",
    "    Hamming codes: Graph database binary codes\n",
    "    query codes: binary code for the query picture\n",
    "    '''\n",
    "    similarity_matrix = []  #similarity matrix generated\n",
    "    for query in query_codes: #for each vector in feature \n",
    "        distances = []\n",
    "        for code in hamming_codes:\n",
    "            distance = hamming_distance(query, code) #the hamming distance between feature and hamming space\n",
    "            distances.append(distance) #distance added to similarility matrice\n",
    "        similarity_matrix.append(distances)\n",
    "    return torch.stack(similarity_matrix) #each sim vector will be concanated to the new matrice 50X50\n",
    "\n",
    "def mean_average_precision(similarity_matrix, query_labels): \n",
    "    #input: similairty matrix: sim matrix for object i and j\n",
    "    #query labels, \n",
    "    #hamming labels are training labels\n",
    "    average_precision = []\n",
    "    for i, similarities in enumerate(similarity_matrix):\n",
    "        sorted_indices = similarities.argsort(descending=True) #for each similarity \n",
    "        sorted_labels = query_labels[sorted_indices]\n",
    "        relevant_indices = (sorted_labels == query_labels[i]).nonzero(as_tuple=True)[0] #find the indices where sorted labels match the query labels for caluclate TP TN etc.\n",
    "        \n",
    "\n",
    "        precision_at_k = torch.arange(1, len(relevant_indices) + 1).float() / (relevant_indices + 1)\n",
    "        average_precision.append(precision_at_k.mean().item())\n",
    "    return torch.tensor(average_precision).mean().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
