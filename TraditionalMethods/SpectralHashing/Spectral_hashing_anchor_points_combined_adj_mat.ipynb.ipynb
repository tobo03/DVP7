{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    # Flatten each image to a 1D array (assuming images are in shape (n_samples, height, width))\n",
    "    return np.array([image.flatten() for image in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_anchor_points(features, n_anchors):\n",
    "    # Perform K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=n_anchors, random_state=42)\n",
    "    kmeans.fit(features)\n",
    "    \n",
    "    # Get the centroids of the clusters\n",
    "    anchor_points = kmeans.cluster_centers_\n",
    "\n",
    "    # Optionally, find the closest samples to each centroid to get their indices\n",
    "    distances = np.linalg.norm(features[:, np.newaxis] - anchor_points, axis=2)\n",
    "    indices = np.argmin(distances, axis=0)  # Get the indices of the closest points\n",
    "    \n",
    "    return anchor_points, indices  # Return the anchor points and their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_adjacency_matrix(train_features, test_features, n_neighbors=5):\n",
    "    # Combine train and test features\n",
    "    combined_features = np.vstack((train_features, test_features))\n",
    "\n",
    "    # Fit KNN to find nearest neighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, metric='euclidean').fit(combined_features)\n",
    "    distances, indices = nbrs.kneighbors(combined_features)\n",
    "\n",
    "    # Create a sparse adjacency matrix\n",
    "    n_samples = combined_features.shape[0]\n",
    "    A = np.zeros((n_samples, n_samples))\n",
    "\n",
    "    # Fill the adjacency matrix\n",
    "    for i in range(n_samples):\n",
    "        for j in range(1, n_neighbors + 1):  # Start from 1 to ignore self-loops\n",
    "            if indices[i, j] < n_samples:  # Check if the index is within bounds\n",
    "                A[i, indices[i, j]] = 1  # Using binary adjacency (1 for neighbors)\n",
    "\n",
    "    return csr_matrix(A)  # Returning as sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash_codes(adjacency_matrix, n_bits=32):\n",
    "    # Compute the degree matrix\n",
    "    D = np.diag(np.array(adjacency_matrix.sum(axis=1)).flatten())\n",
    "\n",
    "    # Compute the graph Laplacian\n",
    "    L = D - adjacency_matrix.toarray()  # Convert to dense for Laplacian calculation\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    _, eigenvectors = np.linalg.eigh(L)  # Using numpy's eigenvalue decomposition\n",
    "\n",
    "    # Use the first n_bits eigenvectors to create hash codes\n",
    "    hash_codes = (eigenvectors[:, :n_bits] > 0).astype(int)  # Binarize eigenvectors\n",
    "    return hash_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_retrieval_pipeline(train_images, test_images, n_anchors=10, n_bits=32, n_neighbors=5):\n",
    "    # Step 1: Extract features from train and test images\n",
    "    train_features = extract_features(train_images)\n",
    "    test_features = extract_features(test_images)\n",
    "    print(\"features extracted\")\n",
    "    # Step 2: Select anchor points from the training set\n",
    "    anchors, anchor_indices = select_anchor_points(train_features, n_anchors)\n",
    "    print(\"anchor points done\")\n",
    "    # Step 3: Create the combined adjacency matrix\n",
    "    adjacency_matrix = create_combined_adjacency_matrix(train_features, test_features, n_neighbors)\n",
    "    print(\"anchor points generated\")\n",
    "    # Step 4: Generate hash codes from the adjacency matrix\n",
    "    hash_codes = generate_hash_codes(adjacency_matrix, n_bits)\n",
    "    print(\"DONE :))) PLS FUCKING WORK\")\n",
    "    return hash_codes, anchors, anchor_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features extracted\n",
      "anchor points done\n",
      "anchor points generated\n",
      "DONE :))) PLS FUCKING WORK\n",
      "Generated Hash Codes: [[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 1]\n",
      " [0 1 0 ... 1 1 1]\n",
      " ...\n",
      " [0 1 0 ... 1 1 1]\n",
      " [0 1 0 ... 1 1 1]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "Selected Anchor Points Indices: [3316 9092  639  423 4298 9063  322 9059 5244 7472]\n"
     ]
    }
   ],
   "source": [
    "# Example usage (assuming you have train_images and test_images as numpy arrays)\n",
    "n_train,n_test = 10000,10000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "x_train,y_train = x_train[0:n_train],y_train[0:n_train]\n",
    "x_test,y_test = x_test[0:n_test],y_test[0:n_test]\n",
    "\n",
    "train_images = x_train  # Load or generate your training images\n",
    "test_images = x_test   # Load or generate your test images\n",
    "\n",
    "hash_codes, anchors, anchor_indices = image_retrieval_pipeline(train_images, test_images)\n",
    "print(\"Generated Hash Codes:\", hash_codes)\n",
    "print(\"Selected Anchor Points Indices:\", anchor_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = hash_codes[0:10000]\n",
    "test = hash_codes[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_at_k(retrieved_labels, true_label):\n",
    "    \"\"\"Calculates the average precision for a single query based on retrieved labels.\"\"\"\n",
    "    correct = 0\n",
    "    precision_at_i = []\n",
    "    \n",
    "    for i in range(1, len(retrieved_labels) + 1):\n",
    "        if retrieved_labels[i - 1] == true_label:\n",
    "            correct += 1\n",
    "            precision_at_i.append(correct / i)\n",
    "    \n",
    "    if len(precision_at_i) == 0:\n",
    "        return 0\n",
    "    return np.mean(precision_at_i)\n",
    "\n",
    "def map_at_single_threshold(train_hash_codes, train_labels, test_hash_codes, test_labels, threshold):\n",
    "    \"\"\"Calculates MAP for a given distance threshold.\"\"\"\n",
    "    \n",
    "    # Calculate the distance matrix between test and train hash codes\n",
    "    distances = cdist(test_hash_codes, train_hash_codes, metric='cityblock')\n",
    "    \n",
    "    ap_scores = []\n",
    "    \n",
    "    for i in range(len(test_labels)):\n",
    "        # Get distances and corresponding labels for the i-th test sample\n",
    "        test_distances = distances[i]\n",
    "        \n",
    "        # Retrieve indices of training samples within the current threshold distance\n",
    "        retrieved_indices = np.where(test_distances <= threshold)[0]\n",
    "        \n",
    "        if len(retrieved_indices) == 0:\n",
    "            # If no neighbors are found within the distance threshold, skip this test sample\n",
    "            continue\n",
    "        \n",
    "        # Get the labels of the retrieved neighbors\n",
    "        retrieved_labels = train_labels[retrieved_indices]\n",
    "        true_label = test_labels[i]\n",
    "        \n",
    "        # Compute average precision for the current test sample\n",
    "        ap = average_precision_at_k(retrieved_labels, true_label)\n",
    "        ap_scores.append(ap)\n",
    "    \n",
    "    # Compute mean average precision (MAP)\n",
    "    if len(ap_scores) == 0:\n",
    "        return 0  # No valid samples for this threshold\n",
    "    return np.mean(ap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(retrieved_labels, true_label, k):\n",
    "    \"\"\"Calculates Precision at K for a single query based on retrieved labels.\"\"\"\n",
    "    relevant_items = 0\n",
    "    \n",
    "    for i in range(min(k, len(retrieved_labels))):\n",
    "        if retrieved_labels[i] == true_label:\n",
    "            relevant_items += 1\n",
    "    \n",
    "    return relevant_items / k if k > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP) at threshold 5: 0.7241\n",
      "Mean Precision at 1 (threshold 5): 0.8847\n",
      "Mean Precision at 5 (threshold 5): 0.8764\n",
      "Mean Precision at 10 (threshold 5): 0.8700\n",
      "Mean Precision at 15 (threshold 5): 0.8636\n",
      "Mean Average Precision (MAP) at threshold 10: 0.2564\n",
      "Mean Precision at 1 (threshold 10): 0.8847\n",
      "Mean Precision at 5 (threshold 10): 0.8764\n",
      "Mean Precision at 10 (threshold 10): 0.8700\n",
      "Mean Precision at 15 (threshold 10): 0.8636\n",
      "Mean Average Precision (MAP) at threshold 15: 0.1103\n",
      "Mean Precision at 1 (threshold 15): 0.8847\n",
      "Mean Precision at 5 (threshold 15): 0.8764\n",
      "Mean Precision at 10 (threshold 15): 0.8700\n",
      "Mean Precision at 15 (threshold 15): 0.8636\n"
     ]
    }
   ],
   "source": [
    "def evaluate_with_different_k_and_thresholds(train_hash_codes, train_labels, test_hash_codes, test_labels, k_values, thresholds):\n",
    "    \"\"\"Evaluates the image retrieval system using MAP and Precision at K for various thresholds and K values.\"\"\"\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        map_score = map_at_single_threshold(train_hash_codes, train_labels, test_hash_codes, test_labels, threshold)\n",
    "        print(f\"Mean Average Precision (MAP) at threshold {threshold}: {map_score:.4f}\")\n",
    "        \n",
    "        for k in k_values:\n",
    "            precision_scores = []\n",
    "            distances = cdist(test_hash_codes, train_hash_codes, metric='cityblock')\n",
    "            \n",
    "            for i in range(len(test_labels)):\n",
    "                test_distances = distances[i]\n",
    "                retrieved_indices = np.argsort(test_distances)\n",
    "                retrieved_labels = train_labels[retrieved_indices]\n",
    "                precision = precision_at_k(retrieved_labels, test_labels[i], k)\n",
    "                precision_scores.append(precision)\n",
    "            \n",
    "            mean_precision_at_k = np.mean(precision_scores) if precision_scores else 0\n",
    "            print(f\"Mean Precision at {k} (threshold {threshold}): {mean_precision_at_k:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "k_values = [1, 5, 10, 15]  # You can choose different values for K\n",
    "thresholds = [5, 10, 15]    # You can set various thresholds\n",
    "\n",
    "evaluate_with_different_k_and_thresholds(train, y_train, test, y_test, k_values, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
