{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing HOG, Random Projection, Min Hash running time with CIFAR10\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_projection_lsh(data, n_hash, n_dimensions):\n",
    "    random_vectors = np.random.randn(n_hash, n_dimensions)\n",
    "    projections = np.dot(data, random_vectors.T)\n",
    "    hash_codes = (projections > 0).astype(int)\n",
    "    return hash_codes \n",
    "\n",
    "def time_random_projection_query(query, hash_codes):\n",
    "    start_time = time.time()\n",
    "    query_hash = random_projection_lsh(query.reshape(1,-1))\n",
    "    hamming_distances = np.sum(query_hash != hash_codes, axis = 1)\n",
    "    sorted_indices = np.argsort(hamming_distances)\n",
    "    end_time = time.time()\n",
    "    return sorted_indices, end_time- start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash_lsh(data, num_perm=128):\n",
    "    # Create an LSH index using min hash for jaccard similarity\n",
    "    lsh = MinHashLSH(threshold=0.5, num_perm=num_perm)\n",
    "    minhashes = []\n",
    "    for i, vector in enumerate(data):\n",
    "        # Convert dense vector to a set of indices with non zero values\n",
    "        vector_set = set(np.nonzero(vector)[0])\n",
    "        m = MinHash(num_perm=num_perm)\n",
    "        for idx in vector_set:\n",
    "            m.update(str(idx).encode('utf8'))\n",
    "        minhashes.append(m)\n",
    "        lsh.insert(f\"data_{i}\", m)\n",
    "    return lsh, minhashes\n",
    "def time_minhash_query(query, lsh, num_perm=128):\n",
    "    query_set = set(np.nonzero(query)[0])\n",
    "    query_minhash = MinHash(num_perm=num_perm)\n",
    "    for idx in query_set:\n",
    "        query_minhash.update(str(idx).encode('utf8'))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = lsh.query(query_minhash)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "time_random_projection_query() missing 1 required positional argument: 'hash_codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m query_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m query_image \u001b[38;5;241m=\u001b[39m X_pca[query_index]\n\u001b[1;32m----> 4\u001b[0m _, rp_query_time \u001b[38;5;241m=\u001b[39mtime_random_projection_query(query_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: time_random_projection_query() missing 1 required positional argument: 'hash_codes'"
     ]
    }
   ],
   "source": [
    "query_index = 0\n",
    "query_image = X_pca[query_index]\n",
    "\n",
    "_, rp_query_time =time_random_projection_query(query_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaoy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "#load cifar10\n",
    "cifar10 = fetch_openml('CIFAR_10_small')\n",
    "#transform data to float, label to integers\n",
    "X = cifar10.data.astype(np.float32)\n",
    "y = cifar10.target.astype(np.int64)\n",
    "#PCA to reduce dimensionality for faster processing \n",
    "pca = PCA(n_components = 100)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "n_hash = 128\n",
    "n_dimensions = X_pca.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Random Projection LSH\n",
    "def random_projection_lsh(data:list[list[float]], n_hash:int=128, seed = 1) -> list[int]:\n",
    "    \"\"\"\"    \n",
    "    \n",
    "    data : a single image as a matrix of floats\n",
    "\n",
    "    n_hash : size of the hash\n",
    "    \n",
    "    returns: list of binary values\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_dimensions = data.shape[1]\n",
    "    random_vectors = np.random.randn(n_hash, n_dimensions)\n",
    "    projections = np.dot(data, random_vectors.T)\n",
    "    hash_codes = (projections > 0).astype(int)\n",
    "    return hash_codes \n",
    "\n",
    "# Timing Random Projection Query\n",
    "def time_random_projection_query(query, hash_codes, n_hash, n_dimensions):\n",
    "    start_time = time.time()\n",
    "    query_hash = random_projection_lsh(query.reshape(1, -1), n_hash, n_dimensions)\n",
    "    hamming_distances = np.sum(query_hash != hash_codes, axis=1) #computing eucleadian distance\n",
    "    sorted_indices = np.argsort(hamming_distances)\n",
    "    end_time = time.time()\n",
    "    return sorted_indices, end_time - start_time\n",
    "\n",
    "# Define MinHash LSH\n",
    "def minhash_lsh(data, num_perm=128):\n",
    "    # Create an LSH index using min hash for Jaccard similarity, intersection/union of two item sets\n",
    "    # Greater than 0.5 are considered similar, 128 is number of permutations to approximate jaccard similarity\n",
    "    lsh = MinHashLSH(threshold=0.5, num_perm=num_perm) \n",
    "    minhashes = []\n",
    "    for i, vector in enumerate(data): \n",
    "        #Convert each vector to a set of indices with non-zero values\n",
    "        vector_set = set(np.nonzero(vector)[0])  \n",
    "        m = MinHash(num_perm=num_perm) #sets are transoformed into MinHash signitures *based on jaccard similarity\n",
    "        for idx in vector_set:\n",
    "            m.update(str(idx).encode('utf8')) # Add elements of minhash object m, index non-zero transformed into hashable strings\n",
    "        minhashes.append(m)\n",
    "        lsh.insert(f\"data_{i}\", m) # Add minhash object to lsh index\n",
    "    return lsh, minhashes\n",
    "\n",
    "# Timing MinHash Query\n",
    "def time_minhash_query(query, lsh, num_perm=128):\n",
    "    query_set = set(np.nonzero(query)[0])\n",
    "    query_minhash = MinHash(num_perm=num_perm)\n",
    "    for idx in query_set:\n",
    "        query_minhash.update(str(idx).encode('utf8')) \n",
    "    start_time = time.time()\n",
    "    result = lsh.query(query_minhash)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# Sample Data and Parameters\n",
    "n_hash = 128\n",
    "n_dimensions = X_pca.shape[1]\n",
    "\n",
    "# Prepare the data for Random Projection\n",
    "hash_codes = random_projection_lsh(X_pca, n_hash, n_dimensions)\n",
    "\n",
    "# Prepare the data for MinHash\n",
    "lsh, minhashes = minhash_lsh(X_pca, num_perm=128)\n",
    "\n",
    "# Query Comparison\n",
    "query_index = 5\n",
    "query_image = X_pca[query_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Projection Query Time: 0.015003204345703125 seconds\n",
      "MinHash Query Time: 0.06342077255249023 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Projection LSH Query\n",
    "_, rp_query_time = time_random_projection_query(query_image, hash_codes, n_hash, n_dimensions)\n",
    "\n",
    "# MinHash Query\n",
    "_, minhash_query_time = time_minhash_query(query_image, lsh)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Random Projection Query Time: {rp_query_time} seconds\")\n",
    "print(f\"MinHash Query Time: {minhash_query_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_pca\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_pca' is not defined"
     ]
    }
   ],
   "source": [
    "X_pca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
