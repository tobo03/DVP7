{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_5952\\4150589690.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_hpo_tensor = torch.tensor(X_hpo, dtype=torch.long)\n",
      "C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_5952\\4150589690.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_valid_tensor = torch.tensor(X_valid, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "root = \"/Users/xiaoy/OneDrive/Desktop/P7/p7 project/data/HPO_Validering_3/CIFAR/\"\n",
    "# load data\n",
    "X_hpo = torch.tensor(np.load(root + \"X_hpo_Cifar.npy\" ))                       \n",
    "y_hpo = np.load(root + \"y_hpo_CIfar.npy\" )\n",
    "\n",
    "X_valid = torch.tensor( np.load(root + \"X_val_Cifar.npy\" ) )\n",
    "y_valid = np.load(root + \"y_val_Cifar.npy\")\n",
    "\n",
    "X_hpo_tensor = torch.tensor(X_hpo, dtype=torch.long)\n",
    "y_hpo_tensor = torch.tensor(y_hpo, dtype=torch.long)\n",
    "\n",
    "X_valid_tensor = torch.tensor(X_valid, dtype=torch.long)\n",
    "y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)\n",
    "\n",
    "hpo_dataset = TensorDataset(X_hpo_tensor, y_hpo_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "\n",
    "hpo_loader = DataLoader(hpo_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SUBIC_encoder(nn.Module): \n",
    "    def __init__(self, input_size=4096, bits=48, num_classes=10, num_blocks=8, block_size=6):\n",
    "        super(SUBIC_encoder, self).__init__()\n",
    "       \n",
    "        assert bits % num_blocks == 0, \"Bits must be divisible by num_blocks\"\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.bits = bits \n",
    "        self.num_blocks = num_blocks\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        # Define the encoder structure\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, bits)\n",
    "        )  # Outputs binary feature vectors\n",
    "        \n",
    "        self.fc3 = nn.Linear(bits, num_classes)  # Logits for num_classes\n",
    "    \n",
    "    def block_softmax(self, x):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        block_size = x.shape[1] // self.num_blocks\n",
    "        \n",
    "        # Ensure that x has the expected shape\n",
    "        assert x.shape[1] == self.bits, f\"Expected shape [batch_size, {self.bits}], got {x.shape}\"\n",
    "        \n",
    "        # Reshape and apply softmax\n",
    "        x = x.view(batch_size, self.num_blocks, block_size)\n",
    "        x = F.softmax(x, dim=-1) \n",
    "        return x.view(batch_size, -1) #-1 refers to the value that will match the original elements \n",
    "    \n",
    "    def block_one_hot(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.view(batch_size, self.num_blocks, self.block_size)\n",
    "        max_indices = x.argmax(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Create one-hot encoding\n",
    "        one_hot = torch.zeros_like(x).scatter_(-1, max_indices, 1)\n",
    "\n",
    "        return one_hot.view(batch_size, self.bits)\n",
    "    \n",
    "    def forward(self, x, use_one_hot=False):\n",
    "        # Ensure x is a flat tensor before passing to encoder\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)  # Flatten if necessary\n",
    "\n",
    "        z = self.encoder(x)\n",
    "\n",
    "        if use_one_hot:\n",
    "            binary_codes = self.block_one_hot(z)\n",
    "        else:\n",
    "            binary_codes = self.block_softmax(z)\n",
    "\n",
    "        class_probs = F.softmax(self.fc3(binary_codes), dim=-1) \n",
    "\n",
    "        return class_probs, binary_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product # create cartesian products for all params\n",
    "\n",
    "bits_12_param_grid = {\n",
    "'bits':12,\n",
    "'num_blocks':\n",
    "[3, 4],\n",
    "'gamma':[0.2, 0.6, 0.8],\n",
    "'mu':[0.2, 0.6, 0.8],\n",
    "'learning_rate': [0.005, 0.01]\n",
    "}\n",
    "\n",
    "bits_24_param_grid = {\n",
    "'bits': 24,\n",
    "'num_blocks':\n",
    "[3, 6, 12],\n",
    "'gamma':[0.2, 0.6, 0.8],\n",
    "'mu':[0.2, 0.6, 0.8],\n",
    "'learning_rate': [0.005, 0.01]\n",
    "}\n",
    "\n",
    "bits_32_param_grid = {\n",
    "'bits':32,\n",
    "'num_blocks':\n",
    "[4, 8, 16],\n",
    "'gamma':[0.2, 0.6, 0.8],\n",
    "'mu':[0.2, 0.6, 0.8],\n",
    "'learning_rate': [0.005, 0.01]\n",
    "}\n",
    "\n",
    "bits_48_param_grid = {\n",
    "'bits':48,\n",
    "'num_blocks':\n",
    "[6, 12, 24],\n",
    "'gamma':[0.2, 0.6, 0.8],\n",
    "'mu':[0.2, 0.6, 0.8],\n",
    "'learning_rate': [0.005, 0.01]\n",
    "}\n",
    "\n",
    "def generate_combinations(param_grid):\n",
    "    keys = list(param_grid.keys())\n",
    "    values = [v if isinstance(v, list) else [v] for v in param_grid.values()] # make list of dicts, if value is a list then take value from the list if not then take that scalar value\n",
    "    gamma_idx = keys.index(\"gamma\")\n",
    "    mu_idx = keys.index(\"mu\")\n",
    "    gamma_mu_pairs = list(zip(values[gamma_idx], values[mu_idx]))\n",
    "    combined_values = values[:gamma_idx] + [gamma_mu_pairs] + values[mu_idx+1:]\n",
    "    combined_keys = keys[:gamma_idx] + [\"gamma_mu\"] + keys[mu_idx+1:]\n",
    "    comb = list(product(*combined_values))\n",
    "    param_combinations_dicts = [\n",
    "        {\n",
    "            **dict(zip(combined_keys, comb_item)),\n",
    "            'gamma': comb_item[combined_keys.index('gamma_mu')][0],\n",
    "            'mu': comb_item[combined_keys.index('gamma_mu')][1]\n",
    "        } for comb_item in comb\n",
    "    ]\n",
    "    for comb_dict in param_combinations_dicts:\n",
    "        del comb_dict['gamma_mu']\n",
    "    \n",
    "    return param_combinations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bits': 12,\n",
       "  'num_blocks': 3,\n",
       "  'learning_rate': 0.005,\n",
       "  'gamma': 0.2,\n",
       "  'mu': 0.2},\n",
       " {'bits': 12, 'num_blocks': 3, 'learning_rate': 0.01, 'gamma': 0.2, 'mu': 0.2},\n",
       " {'bits': 12,\n",
       "  'num_blocks': 3,\n",
       "  'learning_rate': 0.005,\n",
       "  'gamma': 0.6,\n",
       "  'mu': 0.6},\n",
       " {'bits': 12, 'num_blocks': 3, 'learning_rate': 0.01, 'gamma': 0.6, 'mu': 0.6},\n",
       " {'bits': 12,\n",
       "  'num_blocks': 3,\n",
       "  'learning_rate': 0.005,\n",
       "  'gamma': 0.8,\n",
       "  'mu': 0.8},\n",
       " {'bits': 12, 'num_blocks': 3, 'learning_rate': 0.01, 'gamma': 0.8, 'mu': 0.8},\n",
       " {'bits': 12,\n",
       "  'num_blocks': 4,\n",
       "  'learning_rate': 0.005,\n",
       "  'gamma': 0.2,\n",
       "  'mu': 0.2},\n",
       " {'bits': 12, 'num_blocks': 4, 'learning_rate': 0.01, 'gamma': 0.2, 'mu': 0.2},\n",
       " {'bits': 12,\n",
       "  'num_blocks': 4,\n",
       "  'learning_rate': 0.005,\n",
       "  'gamma': 0.6,\n",
       "  'mu': 0.6},\n",
       " {'bits': 12, 'num_blocks': 4, 'learning_rate': 0.01, 'gamma': 0.6, 'mu': 0.6},\n",
       " {'bits': 12,\n",
       "  'num_blocks': 4,\n",
       "  'learning_rate': 0.005,\n",
       "  'gamma': 0.8,\n",
       "  'mu': 0.8},\n",
       " {'bits': 12, 'num_blocks': 4, 'learning_rate': 0.01, 'gamma': 0.8, 'mu': 0.8}]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_combinations(bits_12_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(a):\n",
    "    \n",
    "    if isinstance(a, torch.Tensor):\n",
    "         a = a.cpu().numpy()\n",
    "    b = np.zeros((a.size, a.max() + 1))\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    \n",
    "    return b\n",
    "def meanAveragePrecision(test_hashes, training_hashes, test_labels, training_labels):\n",
    "    aps = []\n",
    "    if len(training_labels.shape) == 1:\n",
    "        training_labels = one_hot_encode(training_labels)\n",
    "        test_labels = one_hot_encode(test_labels)\n",
    "    for i, test_hash in enumerate(tqdm(test_hashes)):\n",
    "        label = test_labels[i]\n",
    "        distances = np.abs(training_hashes - test_hashes[i]).sum(axis=1)\n",
    "        tp = np.where((training_labels*label).sum(axis=1)>0, 1, 0)\n",
    "        hash_df = pd.DataFrame({\"distances\":distances, \"tp\":tp}).reset_index()\n",
    "        hash_df = hash_df.sort_values([\"distances\", \"index\"]).reset_index(drop=True)\n",
    "        hash_df = hash_df.drop([\"index\", \"distances\"], axis=1).reset_index()\n",
    "        hash_df = hash_df[hash_df[\"tp\"]==1]\n",
    "        hash_df[\"tp\"] = hash_df[\"tp\"].cumsum()\n",
    "        hash_df[\"index\"] = hash_df[\"index\"] +1 \n",
    "        precision = np.array(hash_df[\"tp\"]) / np.array(hash_df[\"index\"])\n",
    "        ap = precision.mean()\n",
    "        aps.append(ap)\n",
    "    \n",
    "    return np.array(aps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(epochs, bits, num_blocks, block_size, gamma, mu, learning_rate):\n",
    "    # Initialize model\n",
    "    model = SUBIC_encoder(\n",
    "        bits=bits,\n",
    "        input_size=X_hpo.shape[1],\n",
    "        num_classes=10,\n",
    "        num_blocks=num_blocks,\n",
    "        block_size=block_size\n",
    "    )\n",
    "    model.to(device)  # Move model to the specified device\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Track losses\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for images, labels in hpo_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images, labels = images.to(torch.float), labels.to(torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            class_probs, binary_codes = model(images, use_one_hot=False)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = compute_total_loss(\n",
    "                class_probs, labels, binary_codes, num_blocks, block_size, gamma, mu\n",
    "            )\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Compute average loss for the epoch\n",
    "        avg_loss = total_loss / len(hpo_loader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "def map_on_call(model):\n",
    "    \n",
    "    model.eval()\n",
    "    all_query_codes, all_query_labels = [], []\n",
    "    all_db_codes, all_db_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images, labels = images.to(torch.float), labels.to(torch.long)\n",
    "\n",
    "            _, binary_codes = model(images, use_one_hot=True)\n",
    "\n",
    "            # Ensure binary_codes is a tensor\n",
    "            if not isinstance(binary_codes, torch.Tensor):\n",
    "                raise TypeError(\"Expected binary_codes to be a tensor.\")\n",
    "            \n",
    "            all_db_codes.append(binary_codes)\n",
    "            all_db_labels.append(labels)\n",
    "            if len(all_query_codes) == 0:  \n",
    "                all_query_codes.append(binary_codes.clone())  \n",
    "                all_query_labels.append(labels.clone())\n",
    "\n",
    "    # Concatenate all tensors\n",
    "    all_query_codes = torch.cat(all_query_codes, dim=0)\n",
    "    all_query_labels = torch.cat(all_query_labels, dim=0)\n",
    "    all_db_codes = torch.cat(all_db_codes, dim=0)\n",
    "    all_db_labels = torch.cat(all_db_labels, dim=0)\n",
    "\n",
    "    # Calculate MAP Score\n",
    "    map_score = meanAveragePrecision(\n",
    "        all_query_codes,\n",
    "        all_db_codes,\n",
    "        all_query_labels,\n",
    "        all_db_labels\n",
    "        )\n",
    "\n",
    "    return map_score \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits_12_param_dicts = generate_combinations(bits_12_param_grid) \n",
    "bits_24_param_dicts = generate_combinations(bits_24_param_grid) \n",
    "bits_32_param_dicts = generate_combinations(bits_32_param_grid) \n",
    "bits_48_param_dicts = generate_combinations(bits_48_param_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "epochs = 100\n",
    "map_results = {}\n",
    "\n",
    "# iterate over each combination, train the model and evaluate its performance \n",
    "# initailize model with current hyperparameters\n",
    "\n",
    "def hyper_tuning(param_grid, epochs, hpo_train, hpo_loader, device):\n",
    "    results = {}  # To store MAP scores for each hyperparameter set\n",
    "    best_map_score = 0  # Initialize with a very low value\n",
    "    best_params = None  # To store the best parameter set\n",
    "\n",
    "    for params in param_grid:\n",
    "        # Extract parameters from the current set\n",
    "        bits = params['bits']\n",
    "        num_blocks = params['num_blocks']\n",
    "        block_size = bits // num_blocks\n",
    "        gamma = params['gamma']\n",
    "        mu = params['mu']\n",
    "        learning_rate = params['learning_rate']\n",
    "\n",
    "        print(f\"Testing hyperparameters: {params}\")\n",
    "\n",
    "        # Initialize model with the current hyperparameters\n",
    "        model = SUBIC_encoder(bits=bits, input_size= hpo_train.shape[1], num_classes=10, num_blocks=num_blocks, block_size=block_size)\n",
    "        model.to(device) \n",
    "\n",
    "        # Train the model with the current parameter set\n",
    "        trained_model, _ = loss_function(epochs, bits, num_blocks, block_size, gamma, mu, learning_rate)\n",
    "\n",
    "        # Evaluate the model using MAP score\n",
    "        map_score = map_on_call(trained_model)\n",
    "        print(f\"MAP score: {map_score:.4f}\")\n",
    "\n",
    "        # Store the MAP score for the current parameter set\n",
    "        results[tuple(params.items())] = map_score\n",
    "\n",
    "        if map_score > best_map_score:\n",
    "            best_map_score = map_score\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best Hyperparameters: {best_params}, Best MAP Score: {best_map_score:.4f}\")\n",
    "    return best_params, best_map_score, results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.8566\n",
      "Epoch 2/100, Loss: 0.7257\n",
      "Epoch 3/100, Loss: 0.6962\n",
      "Epoch 4/100, Loss: 0.6881\n",
      "Epoch 5/100, Loss: 0.6695\n",
      "Epoch 6/100, Loss: 0.6731\n",
      "Epoch 7/100, Loss: 0.6801\n",
      "Epoch 8/100, Loss: 0.6492\n",
      "Epoch 9/100, Loss: 0.6603\n",
      "Epoch 10/100, Loss: 0.6941\n",
      "Epoch 11/100, Loss: 0.6579\n",
      "Epoch 12/100, Loss: 0.6169\n",
      "Epoch 13/100, Loss: 0.6240\n",
      "Epoch 14/100, Loss: 0.6022\n",
      "Epoch 15/100, Loss: 0.6149\n",
      "Epoch 16/100, Loss: 0.5822\n",
      "Epoch 17/100, Loss: 0.6020\n",
      "Epoch 18/100, Loss: 0.5928\n",
      "Epoch 19/100, Loss: 0.5958\n",
      "Epoch 20/100, Loss: 0.5687\n",
      "Epoch 21/100, Loss: 0.6954\n",
      "Epoch 22/100, Loss: 0.5692\n",
      "Epoch 23/100, Loss: 0.5830\n",
      "Epoch 24/100, Loss: 0.5744\n",
      "Epoch 25/100, Loss: 0.5535\n",
      "Epoch 26/100, Loss: 0.6052\n",
      "Epoch 27/100, Loss: 0.5575\n",
      "Epoch 28/100, Loss: 0.6267\n",
      "Epoch 29/100, Loss: 0.6393\n",
      "Epoch 30/100, Loss: 0.5824\n",
      "Epoch 31/100, Loss: 0.5538\n",
      "Epoch 32/100, Loss: 0.5425\n",
      "Epoch 33/100, Loss: 0.5616\n",
      "Epoch 34/100, Loss: 0.5651\n",
      "Epoch 35/100, Loss: 0.5652\n",
      "Epoch 36/100, Loss: 0.5534\n",
      "Epoch 37/100, Loss: 0.5519\n",
      "Epoch 38/100, Loss: 0.5587\n",
      "Epoch 39/100, Loss: 0.5521\n",
      "Epoch 40/100, Loss: 0.5349\n",
      "Epoch 41/100, Loss: 0.5257\n",
      "Epoch 42/100, Loss: 0.5594\n",
      "Epoch 43/100, Loss: 0.5282\n",
      "Epoch 44/100, Loss: 0.5733\n",
      "Epoch 45/100, Loss: 0.6127\n",
      "Epoch 46/100, Loss: 0.5526\n",
      "Epoch 47/100, Loss: 0.5355\n",
      "Epoch 48/100, Loss: 0.5662\n",
      "Epoch 49/100, Loss: 0.5514\n",
      "Epoch 50/100, Loss: 0.5714\n",
      "Epoch 51/100, Loss: 0.5519\n",
      "Epoch 52/100, Loss: 0.5169\n",
      "Epoch 53/100, Loss: 0.5781\n",
      "Epoch 54/100, Loss: 0.5411\n",
      "Epoch 55/100, Loss: 0.5335\n",
      "Epoch 56/100, Loss: 0.5215\n",
      "Epoch 57/100, Loss: 0.5876\n",
      "Epoch 58/100, Loss: 0.5535\n",
      "Epoch 59/100, Loss: 0.5841\n",
      "Epoch 60/100, Loss: 0.5991\n",
      "Epoch 61/100, Loss: 0.5689\n",
      "Epoch 62/100, Loss: 0.5655\n",
      "Epoch 63/100, Loss: 0.5855\n",
      "Epoch 64/100, Loss: 0.5691\n",
      "Epoch 65/100, Loss: 0.5417\n",
      "Epoch 66/100, Loss: 0.5285\n",
      "Epoch 67/100, Loss: 0.5203\n",
      "Epoch 68/100, Loss: 0.5149\n",
      "Epoch 69/100, Loss: 0.5313\n",
      "Epoch 70/100, Loss: 0.4990\n",
      "Epoch 71/100, Loss: 0.4798\n",
      "Epoch 72/100, Loss: 0.5078\n",
      "Epoch 73/100, Loss: 0.5411\n",
      "Epoch 74/100, Loss: 0.5245\n",
      "Epoch 75/100, Loss: 0.5634\n",
      "Epoch 76/100, Loss: 0.5665\n",
      "Epoch 77/100, Loss: 0.5654\n",
      "Epoch 78/100, Loss: 0.6127\n",
      "Epoch 79/100, Loss: 0.6546\n",
      "Epoch 80/100, Loss: 0.7053\n",
      "Epoch 81/100, Loss: 0.6828\n",
      "Epoch 82/100, Loss: 0.6501\n",
      "Epoch 83/100, Loss: 0.6353\n",
      "Epoch 84/100, Loss: 0.6205\n",
      "Epoch 85/100, Loss: 0.6124\n",
      "Epoch 86/100, Loss: 0.6634\n",
      "Epoch 87/100, Loss: 0.6269\n",
      "Epoch 88/100, Loss: 0.5761\n",
      "Epoch 89/100, Loss: 0.5555\n",
      "Epoch 90/100, Loss: 0.5435\n",
      "Epoch 91/100, Loss: 0.5143\n",
      "Epoch 92/100, Loss: 0.5301\n",
      "Epoch 93/100, Loss: 0.5005\n",
      "Epoch 94/100, Loss: 0.5472\n",
      "Epoch 95/100, Loss: 0.5827\n",
      "Epoch 96/100, Loss: 0.5272\n",
      "Epoch 97/100, Loss: 0.4942\n",
      "Epoch 98/100, Loss: 0.4760\n",
      "Epoch 99/100, Loss: 0.4833\n",
      "Epoch 100/100, Loss: 0.4759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 98.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2907\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.8997\n",
      "Epoch 2/100, Loss: 0.8270\n",
      "Epoch 3/100, Loss: 0.7428\n",
      "Epoch 4/100, Loss: 0.7488\n",
      "Epoch 5/100, Loss: 0.7530\n",
      "Epoch 6/100, Loss: 0.7398\n",
      "Epoch 7/100, Loss: 0.7439\n",
      "Epoch 8/100, Loss: 0.7421\n",
      "Epoch 9/100, Loss: 0.7262\n",
      "Epoch 10/100, Loss: 0.7661\n",
      "Epoch 11/100, Loss: 0.7825\n",
      "Epoch 12/100, Loss: 0.7352\n",
      "Epoch 13/100, Loss: 0.7268\n",
      "Epoch 14/100, Loss: 0.7570\n",
      "Epoch 15/100, Loss: 0.7556\n",
      "Epoch 16/100, Loss: 0.7570\n",
      "Epoch 17/100, Loss: 0.7092\n",
      "Epoch 18/100, Loss: 0.8329\n",
      "Epoch 19/100, Loss: 0.8112\n",
      "Epoch 20/100, Loss: 0.7615\n",
      "Epoch 21/100, Loss: 0.7863\n",
      "Epoch 22/100, Loss: 0.7746\n",
      "Epoch 23/100, Loss: 0.7252\n",
      "Epoch 24/100, Loss: 0.7390\n",
      "Epoch 25/100, Loss: 0.7220\n",
      "Epoch 26/100, Loss: 0.7299\n",
      "Epoch 27/100, Loss: 0.7207\n",
      "Epoch 28/100, Loss: 0.7252\n",
      "Epoch 29/100, Loss: 0.7295\n",
      "Epoch 30/100, Loss: 0.7108\n",
      "Epoch 31/100, Loss: 0.7275\n",
      "Epoch 32/100, Loss: 0.7281\n",
      "Epoch 33/100, Loss: 0.7221\n",
      "Epoch 34/100, Loss: 0.7203\n",
      "Epoch 35/100, Loss: 0.7153\n",
      "Epoch 36/100, Loss: 0.7365\n",
      "Epoch 37/100, Loss: 0.7933\n",
      "Epoch 38/100, Loss: 0.7835\n",
      "Epoch 39/100, Loss: 0.7598\n",
      "Epoch 40/100, Loss: 0.7526\n",
      "Epoch 41/100, Loss: 0.7853\n",
      "Epoch 42/100, Loss: 0.7704\n",
      "Epoch 43/100, Loss: 0.7283\n",
      "Epoch 44/100, Loss: 0.7344\n",
      "Epoch 45/100, Loss: 0.7259\n",
      "Epoch 46/100, Loss: 0.7769\n",
      "Epoch 47/100, Loss: 0.7528\n",
      "Epoch 48/100, Loss: 0.7331\n",
      "Epoch 49/100, Loss: 0.7578\n",
      "Epoch 50/100, Loss: 0.7769\n",
      "Epoch 51/100, Loss: 0.7453\n",
      "Epoch 52/100, Loss: 0.7636\n",
      "Epoch 53/100, Loss: 0.7718\n",
      "Epoch 54/100, Loss: 0.7722\n",
      "Epoch 55/100, Loss: 0.7710\n",
      "Epoch 56/100, Loss: 0.7694\n",
      "Epoch 57/100, Loss: 0.7713\n",
      "Epoch 58/100, Loss: 0.7712\n",
      "Epoch 59/100, Loss: 0.7697\n",
      "Epoch 60/100, Loss: 0.7711\n",
      "Epoch 61/100, Loss: 0.7691\n",
      "Epoch 62/100, Loss: 0.7700\n",
      "Epoch 63/100, Loss: 0.7703\n",
      "Epoch 64/100, Loss: 0.7704\n",
      "Epoch 65/100, Loss: 0.7692\n",
      "Epoch 66/100, Loss: 0.7694\n",
      "Epoch 67/100, Loss: 0.7689\n",
      "Epoch 68/100, Loss: 0.7688\n",
      "Epoch 69/100, Loss: 0.7709\n",
      "Epoch 70/100, Loss: 0.7706\n",
      "Epoch 71/100, Loss: 0.7690\n",
      "Epoch 72/100, Loss: 0.7691\n",
      "Epoch 73/100, Loss: 0.7691\n",
      "Epoch 74/100, Loss: 0.7678\n",
      "Epoch 75/100, Loss: 0.7689\n",
      "Epoch 76/100, Loss: 0.7685\n",
      "Epoch 77/100, Loss: 0.7705\n",
      "Epoch 78/100, Loss: 0.7737\n",
      "Epoch 79/100, Loss: 0.7688\n",
      "Epoch 80/100, Loss: 0.7709\n",
      "Epoch 81/100, Loss: 0.7685\n",
      "Epoch 82/100, Loss: 0.7711\n",
      "Epoch 83/100, Loss: 0.7689\n",
      "Epoch 84/100, Loss: 0.7696\n",
      "Epoch 85/100, Loss: 0.7691\n",
      "Epoch 86/100, Loss: 0.7717\n",
      "Epoch 87/100, Loss: 0.7701\n",
      "Epoch 88/100, Loss: 0.7686\n",
      "Epoch 89/100, Loss: 0.7684\n",
      "Epoch 90/100, Loss: 0.7710\n",
      "Epoch 91/100, Loss: 0.7684\n",
      "Epoch 92/100, Loss: 0.7702\n",
      "Epoch 93/100, Loss: 0.7688\n",
      "Epoch 94/100, Loss: 0.7686\n",
      "Epoch 95/100, Loss: 0.7704\n",
      "Epoch 96/100, Loss: 0.7700\n",
      "Epoch 97/100, Loss: 0.7686\n",
      "Epoch 98/100, Loss: 0.7716\n",
      "Epoch 99/100, Loss: 0.7689\n",
      "Epoch 100/100, Loss: 0.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 300.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1921\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0081\n",
      "Epoch 2/100, Loss: 1.0049\n",
      "Epoch 3/100, Loss: 1.0089\n",
      "Epoch 4/100, Loss: 1.0090\n",
      "Epoch 5/100, Loss: 1.0069\n",
      "Epoch 6/100, Loss: 1.0079\n",
      "Epoch 7/100, Loss: 1.0073\n",
      "Epoch 8/100, Loss: 1.0082\n",
      "Epoch 9/100, Loss: 1.0084\n",
      "Epoch 10/100, Loss: 1.0062\n",
      "Epoch 11/100, Loss: 1.0061\n",
      "Epoch 12/100, Loss: 1.0082\n",
      "Epoch 13/100, Loss: 1.0086\n",
      "Epoch 14/100, Loss: 1.0083\n",
      "Epoch 15/100, Loss: 1.0081\n",
      "Epoch 16/100, Loss: 1.0092\n",
      "Epoch 17/100, Loss: 1.0079\n",
      "Epoch 18/100, Loss: 1.0073\n",
      "Epoch 19/100, Loss: 1.0070\n",
      "Epoch 20/100, Loss: 1.0081\n",
      "Epoch 21/100, Loss: 1.0068\n",
      "Epoch 22/100, Loss: 1.0066\n",
      "Epoch 23/100, Loss: 1.0073\n",
      "Epoch 24/100, Loss: 1.0073\n",
      "Epoch 25/100, Loss: 1.0092\n",
      "Epoch 26/100, Loss: 1.0071\n",
      "Epoch 27/100, Loss: 1.0056\n",
      "Epoch 28/100, Loss: 1.0077\n",
      "Epoch 29/100, Loss: 1.0082\n",
      "Epoch 30/100, Loss: 1.0069\n",
      "Epoch 31/100, Loss: 1.0118\n",
      "Epoch 32/100, Loss: 1.0085\n",
      "Epoch 33/100, Loss: 1.0066\n",
      "Epoch 34/100, Loss: 1.0082\n",
      "Epoch 35/100, Loss: 1.0081\n",
      "Epoch 36/100, Loss: 1.0094\n",
      "Epoch 37/100, Loss: 1.0080\n",
      "Epoch 38/100, Loss: 1.0086\n",
      "Epoch 39/100, Loss: 1.0075\n",
      "Epoch 40/100, Loss: 1.0067\n",
      "Epoch 41/100, Loss: 1.0109\n",
      "Epoch 42/100, Loss: 1.0087\n",
      "Epoch 43/100, Loss: 1.0124\n",
      "Epoch 44/100, Loss: 1.0092\n",
      "Epoch 45/100, Loss: 1.0081\n",
      "Epoch 46/100, Loss: 1.0077\n",
      "Epoch 47/100, Loss: 1.0068\n",
      "Epoch 48/100, Loss: 1.0054\n",
      "Epoch 49/100, Loss: 1.0096\n",
      "Epoch 50/100, Loss: 1.0084\n",
      "Epoch 51/100, Loss: 1.0078\n",
      "Epoch 52/100, Loss: 1.0072\n",
      "Epoch 53/100, Loss: 1.0075\n",
      "Epoch 54/100, Loss: 1.0079\n",
      "Epoch 55/100, Loss: 1.0088\n",
      "Epoch 56/100, Loss: 1.0091\n",
      "Epoch 57/100, Loss: 1.0070\n",
      "Epoch 58/100, Loss: 1.0055\n",
      "Epoch 59/100, Loss: 1.0058\n",
      "Epoch 60/100, Loss: 1.0079\n",
      "Epoch 61/100, Loss: 1.0079\n",
      "Epoch 62/100, Loss: 1.0071\n",
      "Epoch 63/100, Loss: 1.0056\n",
      "Epoch 64/100, Loss: 1.0073\n",
      "Epoch 65/100, Loss: 1.0045\n",
      "Epoch 66/100, Loss: 1.0083\n",
      "Epoch 67/100, Loss: 1.0058\n",
      "Epoch 68/100, Loss: 1.0090\n",
      "Epoch 69/100, Loss: 1.0098\n",
      "Epoch 70/100, Loss: 1.0103\n",
      "Epoch 71/100, Loss: 1.0047\n",
      "Epoch 72/100, Loss: 1.0088\n",
      "Epoch 73/100, Loss: 1.0107\n",
      "Epoch 74/100, Loss: 1.0080\n",
      "Epoch 75/100, Loss: 1.0075\n",
      "Epoch 76/100, Loss: 1.0082\n",
      "Epoch 77/100, Loss: 1.0083\n",
      "Epoch 78/100, Loss: 1.0089\n",
      "Epoch 79/100, Loss: 1.0082\n",
      "Epoch 80/100, Loss: 1.0096\n",
      "Epoch 81/100, Loss: 1.0074\n",
      "Epoch 82/100, Loss: 1.0060\n",
      "Epoch 83/100, Loss: 1.0073\n",
      "Epoch 84/100, Loss: 1.0071\n",
      "Epoch 85/100, Loss: 1.0072\n",
      "Epoch 86/100, Loss: 1.0091\n",
      "Epoch 87/100, Loss: 1.0056\n",
      "Epoch 88/100, Loss: 1.0087\n",
      "Epoch 89/100, Loss: 1.0068\n",
      "Epoch 90/100, Loss: 1.0085\n",
      "Epoch 91/100, Loss: 1.0093\n",
      "Epoch 92/100, Loss: 1.0058\n",
      "Epoch 93/100, Loss: 1.0086\n",
      "Epoch 94/100, Loss: 1.0084\n",
      "Epoch 95/100, Loss: 1.0078\n",
      "Epoch 96/100, Loss: 1.0094\n",
      "Epoch 97/100, Loss: 1.0057\n",
      "Epoch 98/100, Loss: 1.0089\n",
      "Epoch 99/100, Loss: 1.0073\n",
      "Epoch 100/100, Loss: 1.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 329.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1155\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.9968\n",
      "Epoch 2/100, Loss: 1.0011\n",
      "Epoch 3/100, Loss: 1.0006\n",
      "Epoch 4/100, Loss: 1.0010\n",
      "Epoch 5/100, Loss: 1.0008\n",
      "Epoch 6/100, Loss: 1.0004\n",
      "Epoch 7/100, Loss: 1.0006\n",
      "Epoch 8/100, Loss: 1.0005\n",
      "Epoch 9/100, Loss: 1.0006\n",
      "Epoch 10/100, Loss: 1.0006\n",
      "Epoch 11/100, Loss: 1.0008\n",
      "Epoch 12/100, Loss: 1.0008\n",
      "Epoch 13/100, Loss: 1.0007\n",
      "Epoch 14/100, Loss: 1.0008\n",
      "Epoch 15/100, Loss: 1.0008\n",
      "Epoch 16/100, Loss: 1.0005\n",
      "Epoch 17/100, Loss: 1.0009\n",
      "Epoch 18/100, Loss: 1.0004\n",
      "Epoch 19/100, Loss: 1.0010\n",
      "Epoch 20/100, Loss: 1.0004\n",
      "Epoch 21/100, Loss: 1.0007\n",
      "Epoch 22/100, Loss: 1.0007\n",
      "Epoch 23/100, Loss: 1.0006\n",
      "Epoch 24/100, Loss: 1.0008\n",
      "Epoch 25/100, Loss: 1.0013\n",
      "Epoch 26/100, Loss: 1.0004\n",
      "Epoch 27/100, Loss: 1.0007\n",
      "Epoch 28/100, Loss: 1.0008\n",
      "Epoch 29/100, Loss: 1.0010\n",
      "Epoch 30/100, Loss: 1.0007\n",
      "Epoch 31/100, Loss: 1.0011\n",
      "Epoch 32/100, Loss: 1.0011\n",
      "Epoch 33/100, Loss: 1.0007\n",
      "Epoch 34/100, Loss: 1.0009\n",
      "Epoch 35/100, Loss: 1.0007\n",
      "Epoch 36/100, Loss: 1.0004\n",
      "Epoch 37/100, Loss: 1.0007\n",
      "Epoch 38/100, Loss: 1.0008\n",
      "Epoch 39/100, Loss: 1.0006\n",
      "Epoch 40/100, Loss: 1.0004\n",
      "Epoch 41/100, Loss: 1.0007\n",
      "Epoch 42/100, Loss: 1.0007\n",
      "Epoch 43/100, Loss: 1.0009\n",
      "Epoch 44/100, Loss: 1.0005\n",
      "Epoch 45/100, Loss: 1.0009\n",
      "Epoch 46/100, Loss: 1.0004\n",
      "Epoch 47/100, Loss: 1.0010\n",
      "Epoch 48/100, Loss: 1.0005\n",
      "Epoch 49/100, Loss: 1.0005\n",
      "Epoch 50/100, Loss: 1.0006\n",
      "Epoch 51/100, Loss: 1.0007\n",
      "Epoch 52/100, Loss: 1.0006\n",
      "Epoch 53/100, Loss: 1.0007\n",
      "Epoch 54/100, Loss: 1.0004\n",
      "Epoch 55/100, Loss: 1.0004\n",
      "Epoch 56/100, Loss: 1.0004\n",
      "Epoch 57/100, Loss: 1.0006\n",
      "Epoch 58/100, Loss: 1.0010\n",
      "Epoch 59/100, Loss: 1.0007\n",
      "Epoch 60/100, Loss: 1.0006\n",
      "Epoch 61/100, Loss: 1.0005\n",
      "Epoch 62/100, Loss: 1.0006\n",
      "Epoch 63/100, Loss: 1.0009\n",
      "Epoch 64/100, Loss: 1.0013\n",
      "Epoch 65/100, Loss: 1.0007\n",
      "Epoch 66/100, Loss: 1.0008\n",
      "Epoch 67/100, Loss: 1.0008\n",
      "Epoch 68/100, Loss: 1.0005\n",
      "Epoch 69/100, Loss: 1.0003\n",
      "Epoch 70/100, Loss: 1.0005\n",
      "Epoch 71/100, Loss: 1.0010\n",
      "Epoch 72/100, Loss: 1.0006\n",
      "Epoch 73/100, Loss: 1.0004\n",
      "Epoch 74/100, Loss: 1.0006\n",
      "Epoch 75/100, Loss: 1.0008\n",
      "Epoch 76/100, Loss: 1.0008\n",
      "Epoch 77/100, Loss: 1.0010\n",
      "Epoch 78/100, Loss: 1.0007\n",
      "Epoch 79/100, Loss: 1.0008\n",
      "Epoch 80/100, Loss: 1.0009\n",
      "Epoch 81/100, Loss: 1.0008\n",
      "Epoch 82/100, Loss: 1.0010\n",
      "Epoch 83/100, Loss: 1.0007\n",
      "Epoch 84/100, Loss: 1.0005\n",
      "Epoch 85/100, Loss: 1.0008\n",
      "Epoch 86/100, Loss: 1.0005\n",
      "Epoch 87/100, Loss: 1.0010\n",
      "Epoch 88/100, Loss: 1.0009\n",
      "Epoch 89/100, Loss: 1.0005\n",
      "Epoch 90/100, Loss: 1.0011\n",
      "Epoch 91/100, Loss: 1.0005\n",
      "Epoch 92/100, Loss: 1.0006\n",
      "Epoch 93/100, Loss: 1.0007\n",
      "Epoch 94/100, Loss: 1.0010\n",
      "Epoch 95/100, Loss: 1.0003\n",
      "Epoch 96/100, Loss: 1.0004\n",
      "Epoch 97/100, Loss: 1.0007\n",
      "Epoch 98/100, Loss: 1.0004\n",
      "Epoch 99/100, Loss: 1.0004\n",
      "Epoch 100/100, Loss: 1.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1116\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.7503\n",
      "Epoch 2/100, Loss: 0.6798\n",
      "Epoch 3/100, Loss: 0.6652\n",
      "Epoch 4/100, Loss: 0.6136\n",
      "Epoch 5/100, Loss: 0.5866\n",
      "Epoch 6/100, Loss: 0.6129\n",
      "Epoch 7/100, Loss: 0.5612\n",
      "Epoch 8/100, Loss: 0.5430\n",
      "Epoch 9/100, Loss: 0.5561\n",
      "Epoch 10/100, Loss: 0.5282\n",
      "Epoch 11/100, Loss: 0.5255\n",
      "Epoch 12/100, Loss: 0.5454\n",
      "Epoch 13/100, Loss: 0.5893\n",
      "Epoch 14/100, Loss: 0.6537\n",
      "Epoch 15/100, Loss: 0.5819\n",
      "Epoch 16/100, Loss: 0.5815\n",
      "Epoch 17/100, Loss: 0.5820\n",
      "Epoch 18/100, Loss: 0.6308\n",
      "Epoch 19/100, Loss: 0.7846\n",
      "Epoch 20/100, Loss: 0.6272\n",
      "Epoch 21/100, Loss: 0.5921\n",
      "Epoch 22/100, Loss: 0.6292\n",
      "Epoch 23/100, Loss: 0.5947\n",
      "Epoch 24/100, Loss: 0.5866\n",
      "Epoch 25/100, Loss: 0.6024\n",
      "Epoch 26/100, Loss: 0.5869\n",
      "Epoch 27/100, Loss: 0.5905\n",
      "Epoch 28/100, Loss: 0.5879\n",
      "Epoch 29/100, Loss: 0.7398\n",
      "Epoch 30/100, Loss: 0.7347\n",
      "Epoch 31/100, Loss: 0.5890\n",
      "Epoch 32/100, Loss: 0.5775\n",
      "Epoch 33/100, Loss: 0.5771\n",
      "Epoch 34/100, Loss: 0.6140\n",
      "Epoch 35/100, Loss: 0.6014\n",
      "Epoch 36/100, Loss: 0.6031\n",
      "Epoch 37/100, Loss: 0.6458\n",
      "Epoch 38/100, Loss: 0.7053\n",
      "Epoch 39/100, Loss: 0.6054\n",
      "Epoch 40/100, Loss: 0.5886\n",
      "Epoch 41/100, Loss: 0.5825\n",
      "Epoch 42/100, Loss: 0.5911\n",
      "Epoch 43/100, Loss: 0.5512\n",
      "Epoch 44/100, Loss: 0.5629\n",
      "Epoch 45/100, Loss: 0.7516\n",
      "Epoch 46/100, Loss: 0.6203\n",
      "Epoch 47/100, Loss: 0.5852\n",
      "Epoch 48/100, Loss: 0.5692\n",
      "Epoch 49/100, Loss: 0.5564\n",
      "Epoch 50/100, Loss: 0.5836\n",
      "Epoch 51/100, Loss: 0.5728\n",
      "Epoch 52/100, Loss: 0.5699\n",
      "Epoch 53/100, Loss: 0.5697\n",
      "Epoch 54/100, Loss: 0.5745\n",
      "Epoch 55/100, Loss: 0.5595\n",
      "Epoch 56/100, Loss: 0.5339\n",
      "Epoch 57/100, Loss: 0.5509\n",
      "Epoch 58/100, Loss: 0.5442\n",
      "Epoch 59/100, Loss: 0.5150\n",
      "Epoch 60/100, Loss: 0.4773\n",
      "Epoch 61/100, Loss: 0.5205\n",
      "Epoch 62/100, Loss: 0.4869\n",
      "Epoch 63/100, Loss: 0.4851\n",
      "Epoch 64/100, Loss: 0.4892\n",
      "Epoch 65/100, Loss: 0.5043\n",
      "Epoch 66/100, Loss: 0.6253\n",
      "Epoch 67/100, Loss: 0.5202\n",
      "Epoch 68/100, Loss: 0.5066\n",
      "Epoch 69/100, Loss: 0.5084\n",
      "Epoch 70/100, Loss: 0.5114\n",
      "Epoch 71/100, Loss: 0.5203\n",
      "Epoch 72/100, Loss: 0.5225\n",
      "Epoch 73/100, Loss: 0.4963\n",
      "Epoch 74/100, Loss: 0.4769\n",
      "Epoch 75/100, Loss: 0.4873\n",
      "Epoch 76/100, Loss: 0.5168\n",
      "Epoch 77/100, Loss: 0.5109\n",
      "Epoch 78/100, Loss: 0.5187\n",
      "Epoch 79/100, Loss: 0.5534\n",
      "Epoch 80/100, Loss: 0.5531\n",
      "Epoch 81/100, Loss: 0.5789\n",
      "Epoch 82/100, Loss: 0.5341\n",
      "Epoch 83/100, Loss: 0.5047\n",
      "Epoch 84/100, Loss: 0.4953\n",
      "Epoch 85/100, Loss: 0.4899\n",
      "Epoch 86/100, Loss: 0.4951\n",
      "Epoch 87/100, Loss: 0.4883\n",
      "Epoch 88/100, Loss: 0.4735\n",
      "Epoch 89/100, Loss: 0.5250\n",
      "Epoch 90/100, Loss: 0.5119\n",
      "Epoch 91/100, Loss: 0.5057\n",
      "Epoch 92/100, Loss: 0.4696\n",
      "Epoch 93/100, Loss: 0.4521\n",
      "Epoch 94/100, Loss: 0.4551\n",
      "Epoch 95/100, Loss: 0.4434\n",
      "Epoch 96/100, Loss: 0.5753\n",
      "Epoch 97/100, Loss: 0.5407\n",
      "Epoch 98/100, Loss: 0.5401\n",
      "Epoch 99/100, Loss: 0.5134\n",
      "Epoch 100/100, Loss: 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 353.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2116\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0028\n",
      "Epoch 2/100, Loss: 1.0089\n",
      "Epoch 3/100, Loss: 1.0056\n",
      "Epoch 4/100, Loss: 1.0064\n",
      "Epoch 5/100, Loss: 1.0101\n",
      "Epoch 6/100, Loss: 1.0097\n",
      "Epoch 7/100, Loss: 1.0090\n",
      "Epoch 8/100, Loss: 1.0068\n",
      "Epoch 9/100, Loss: 1.0082\n",
      "Epoch 10/100, Loss: 1.0060\n",
      "Epoch 11/100, Loss: 1.0078\n",
      "Epoch 12/100, Loss: 1.0104\n",
      "Epoch 13/100, Loss: 1.0071\n",
      "Epoch 14/100, Loss: 1.0063\n",
      "Epoch 15/100, Loss: 1.0053\n",
      "Epoch 16/100, Loss: 1.0062\n",
      "Epoch 17/100, Loss: 1.0051\n",
      "Epoch 18/100, Loss: 1.0083\n",
      "Epoch 19/100, Loss: 1.0066\n",
      "Epoch 20/100, Loss: 1.0075\n",
      "Epoch 21/100, Loss: 1.0099\n",
      "Epoch 22/100, Loss: 1.0080\n",
      "Epoch 23/100, Loss: 1.0104\n",
      "Epoch 24/100, Loss: 1.0101\n",
      "Epoch 25/100, Loss: 1.0070\n",
      "Epoch 26/100, Loss: 1.0065\n",
      "Epoch 27/100, Loss: 1.0069\n",
      "Epoch 28/100, Loss: 1.0057\n",
      "Epoch 29/100, Loss: 1.0095\n",
      "Epoch 30/100, Loss: 1.0067\n",
      "Epoch 31/100, Loss: 1.0066\n",
      "Epoch 32/100, Loss: 1.0058\n",
      "Epoch 33/100, Loss: 1.0091\n",
      "Epoch 34/100, Loss: 1.0065\n",
      "Epoch 35/100, Loss: 1.0070\n",
      "Epoch 36/100, Loss: 1.0089\n",
      "Epoch 37/100, Loss: 1.0080\n",
      "Epoch 38/100, Loss: 1.0069\n",
      "Epoch 39/100, Loss: 1.0076\n",
      "Epoch 40/100, Loss: 1.0101\n",
      "Epoch 41/100, Loss: 1.0060\n",
      "Epoch 42/100, Loss: 1.0077\n",
      "Epoch 43/100, Loss: 1.0093\n",
      "Epoch 44/100, Loss: 1.0084\n",
      "Epoch 45/100, Loss: 1.0075\n",
      "Epoch 46/100, Loss: 1.0088\n",
      "Epoch 47/100, Loss: 1.0068\n",
      "Epoch 48/100, Loss: 1.0104\n",
      "Epoch 49/100, Loss: 1.0050\n",
      "Epoch 50/100, Loss: 1.0074\n",
      "Epoch 51/100, Loss: 1.0100\n",
      "Epoch 52/100, Loss: 1.0061\n",
      "Epoch 53/100, Loss: 1.0100\n",
      "Epoch 54/100, Loss: 1.0118\n",
      "Epoch 55/100, Loss: 1.0080\n",
      "Epoch 56/100, Loss: 1.0087\n",
      "Epoch 57/100, Loss: 1.0064\n",
      "Epoch 58/100, Loss: 1.0079\n",
      "Epoch 59/100, Loss: 1.0072\n",
      "Epoch 60/100, Loss: 1.0068\n",
      "Epoch 61/100, Loss: 1.0095\n",
      "Epoch 62/100, Loss: 1.0104\n",
      "Epoch 63/100, Loss: 1.0106\n",
      "Epoch 64/100, Loss: 1.0072\n",
      "Epoch 65/100, Loss: 1.0111\n",
      "Epoch 66/100, Loss: 1.0084\n",
      "Epoch 67/100, Loss: 1.0091\n",
      "Epoch 68/100, Loss: 1.0090\n",
      "Epoch 69/100, Loss: 1.0064\n",
      "Epoch 70/100, Loss: 1.0082\n",
      "Epoch 71/100, Loss: 1.0076\n",
      "Epoch 72/100, Loss: 1.0084\n",
      "Epoch 73/100, Loss: 1.0089\n",
      "Epoch 74/100, Loss: 1.0076\n",
      "Epoch 75/100, Loss: 1.0071\n",
      "Epoch 76/100, Loss: 1.0091\n",
      "Epoch 77/100, Loss: 1.0089\n",
      "Epoch 78/100, Loss: 1.0072\n",
      "Epoch 79/100, Loss: 1.0063\n",
      "Epoch 80/100, Loss: 1.0074\n",
      "Epoch 81/100, Loss: 1.0060\n",
      "Epoch 82/100, Loss: 1.0085\n",
      "Epoch 83/100, Loss: 1.0068\n",
      "Epoch 84/100, Loss: 1.0078\n",
      "Epoch 85/100, Loss: 1.0091\n",
      "Epoch 86/100, Loss: 1.0104\n",
      "Epoch 87/100, Loss: 1.0070\n",
      "Epoch 88/100, Loss: 1.0082\n",
      "Epoch 89/100, Loss: 1.0083\n",
      "Epoch 90/100, Loss: 1.0074\n",
      "Epoch 91/100, Loss: 1.0050\n",
      "Epoch 92/100, Loss: 1.0053\n",
      "Epoch 93/100, Loss: 1.0094\n",
      "Epoch 94/100, Loss: 1.0079\n",
      "Epoch 95/100, Loss: 1.0068\n",
      "Epoch 96/100, Loss: 1.0087\n",
      "Epoch 97/100, Loss: 1.0086\n",
      "Epoch 98/100, Loss: 1.0064\n",
      "Epoch 99/100, Loss: 1.0061\n",
      "Epoch 100/100, Loss: 1.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 305.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1152\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.8, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.9996\n",
      "Epoch 2/100, Loss: 1.0005\n",
      "Epoch 3/100, Loss: 1.0005\n",
      "Epoch 4/100, Loss: 1.0007\n",
      "Epoch 5/100, Loss: 1.0007\n",
      "Epoch 6/100, Loss: 1.0009\n",
      "Epoch 7/100, Loss: 1.0009\n",
      "Epoch 8/100, Loss: 1.0004\n",
      "Epoch 9/100, Loss: 1.0006\n",
      "Epoch 10/100, Loss: 1.0008\n",
      "Epoch 11/100, Loss: 1.0003\n",
      "Epoch 12/100, Loss: 1.0008\n",
      "Epoch 13/100, Loss: 1.0006\n",
      "Epoch 14/100, Loss: 1.0006\n",
      "Epoch 15/100, Loss: 1.0006\n",
      "Epoch 16/100, Loss: 1.0011\n",
      "Epoch 17/100, Loss: 1.0010\n",
      "Epoch 18/100, Loss: 1.0010\n",
      "Epoch 19/100, Loss: 1.0005\n",
      "Epoch 20/100, Loss: 1.0008\n",
      "Epoch 21/100, Loss: 1.0009\n",
      "Epoch 22/100, Loss: 1.0007\n",
      "Epoch 23/100, Loss: 1.0008\n",
      "Epoch 24/100, Loss: 1.0005\n",
      "Epoch 25/100, Loss: 1.0005\n",
      "Epoch 26/100, Loss: 1.0010\n",
      "Epoch 27/100, Loss: 1.0010\n",
      "Epoch 28/100, Loss: 1.0006\n",
      "Epoch 29/100, Loss: 1.0007\n",
      "Epoch 30/100, Loss: 1.0006\n",
      "Epoch 31/100, Loss: 1.0009\n",
      "Epoch 32/100, Loss: 1.0009\n",
      "Epoch 33/100, Loss: 1.0007\n",
      "Epoch 34/100, Loss: 1.0006\n",
      "Epoch 35/100, Loss: 1.0010\n",
      "Epoch 36/100, Loss: 1.0006\n",
      "Epoch 37/100, Loss: 1.0008\n",
      "Epoch 38/100, Loss: 1.0007\n",
      "Epoch 39/100, Loss: 1.0006\n",
      "Epoch 40/100, Loss: 1.0004\n",
      "Epoch 41/100, Loss: 1.0007\n",
      "Epoch 42/100, Loss: 1.0003\n",
      "Epoch 43/100, Loss: 1.0007\n",
      "Epoch 44/100, Loss: 1.0010\n",
      "Epoch 45/100, Loss: 1.0007\n",
      "Epoch 46/100, Loss: 1.0007\n",
      "Epoch 47/100, Loss: 1.0005\n",
      "Epoch 48/100, Loss: 1.0006\n",
      "Epoch 49/100, Loss: 1.0008\n",
      "Epoch 50/100, Loss: 1.0007\n",
      "Epoch 51/100, Loss: 1.0009\n",
      "Epoch 52/100, Loss: 1.0005\n",
      "Epoch 53/100, Loss: 1.0005\n",
      "Epoch 54/100, Loss: 1.0006\n",
      "Epoch 55/100, Loss: 1.0008\n",
      "Epoch 56/100, Loss: 1.0006\n",
      "Epoch 57/100, Loss: 1.0008\n",
      "Epoch 58/100, Loss: 1.0011\n",
      "Epoch 59/100, Loss: 1.0006\n",
      "Epoch 60/100, Loss: 1.0009\n",
      "Epoch 61/100, Loss: 1.0008\n",
      "Epoch 62/100, Loss: 1.0009\n",
      "Epoch 63/100, Loss: 1.0004\n",
      "Epoch 64/100, Loss: 1.0010\n",
      "Epoch 65/100, Loss: 1.0008\n",
      "Epoch 66/100, Loss: 1.0006\n",
      "Epoch 67/100, Loss: 1.0005\n",
      "Epoch 68/100, Loss: 1.0008\n",
      "Epoch 69/100, Loss: 1.0005\n",
      "Epoch 70/100, Loss: 1.0007\n",
      "Epoch 71/100, Loss: 1.0007\n",
      "Epoch 72/100, Loss: 1.0003\n",
      "Epoch 73/100, Loss: 1.0005\n",
      "Epoch 74/100, Loss: 1.0006\n",
      "Epoch 75/100, Loss: 1.0007\n",
      "Epoch 76/100, Loss: 1.0006\n",
      "Epoch 77/100, Loss: 1.0005\n",
      "Epoch 78/100, Loss: 1.0008\n",
      "Epoch 79/100, Loss: 1.0008\n",
      "Epoch 80/100, Loss: 1.0008\n",
      "Epoch 81/100, Loss: 1.0008\n",
      "Epoch 82/100, Loss: 1.0010\n",
      "Epoch 83/100, Loss: 1.0007\n",
      "Epoch 84/100, Loss: 1.0008\n",
      "Epoch 85/100, Loss: 1.0005\n",
      "Epoch 86/100, Loss: 1.0006\n",
      "Epoch 87/100, Loss: 1.0006\n",
      "Epoch 88/100, Loss: 1.0010\n",
      "Epoch 89/100, Loss: 1.0007\n",
      "Epoch 90/100, Loss: 1.0009\n",
      "Epoch 91/100, Loss: 1.0009\n",
      "Epoch 92/100, Loss: 1.0007\n",
      "Epoch 93/100, Loss: 1.0005\n",
      "Epoch 94/100, Loss: 1.0008\n",
      "Epoch 95/100, Loss: 1.0005\n",
      "Epoch 96/100, Loss: 1.0008\n",
      "Epoch 97/100, Loss: 1.0008\n",
      "Epoch 98/100, Loss: 1.0005\n",
      "Epoch 99/100, Loss: 1.0008\n",
      "Epoch 100/100, Loss: 1.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 316.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1170\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.8, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.9952\n",
      "Epoch 2/100, Loss: 1.0013\n",
      "Epoch 3/100, Loss: 1.0010\n",
      "Epoch 4/100, Loss: 1.0020\n",
      "Epoch 5/100, Loss: 1.0019\n",
      "Epoch 6/100, Loss: 1.0012\n",
      "Epoch 7/100, Loss: 1.0016\n",
      "Epoch 8/100, Loss: 1.0010\n",
      "Epoch 9/100, Loss: 1.0017\n",
      "Epoch 10/100, Loss: 1.0011\n",
      "Epoch 11/100, Loss: 1.0014\n",
      "Epoch 12/100, Loss: 1.0017\n",
      "Epoch 13/100, Loss: 1.0011\n",
      "Epoch 14/100, Loss: 1.0021\n",
      "Epoch 15/100, Loss: 1.0015\n",
      "Epoch 16/100, Loss: 1.0013\n",
      "Epoch 17/100, Loss: 1.0011\n",
      "Epoch 18/100, Loss: 1.0013\n",
      "Epoch 19/100, Loss: 1.0016\n",
      "Epoch 20/100, Loss: 1.0013\n",
      "Epoch 21/100, Loss: 1.0016\n",
      "Epoch 22/100, Loss: 1.0013\n",
      "Epoch 23/100, Loss: 1.0015\n",
      "Epoch 24/100, Loss: 1.0016\n",
      "Epoch 25/100, Loss: 1.0016\n",
      "Epoch 26/100, Loss: 1.0019\n",
      "Epoch 27/100, Loss: 1.0018\n",
      "Epoch 28/100, Loss: 1.0014\n",
      "Epoch 29/100, Loss: 1.0017\n",
      "Epoch 30/100, Loss: 1.0014\n",
      "Epoch 31/100, Loss: 1.0016\n",
      "Epoch 32/100, Loss: 1.0009\n",
      "Epoch 33/100, Loss: 1.0016\n",
      "Epoch 34/100, Loss: 1.0016\n",
      "Epoch 35/100, Loss: 1.0018\n",
      "Epoch 36/100, Loss: 1.0011\n",
      "Epoch 37/100, Loss: 1.0012\n",
      "Epoch 38/100, Loss: 1.0014\n",
      "Epoch 39/100, Loss: 1.0011\n",
      "Epoch 40/100, Loss: 1.0016\n",
      "Epoch 41/100, Loss: 1.0014\n",
      "Epoch 42/100, Loss: 1.0018\n",
      "Epoch 43/100, Loss: 1.0015\n",
      "Epoch 44/100, Loss: 1.0015\n",
      "Epoch 45/100, Loss: 1.0016\n",
      "Epoch 46/100, Loss: 1.0013\n",
      "Epoch 47/100, Loss: 1.0012\n",
      "Epoch 48/100, Loss: 1.0016\n",
      "Epoch 49/100, Loss: 1.0014\n",
      "Epoch 50/100, Loss: 1.0016\n",
      "Epoch 51/100, Loss: 1.0017\n",
      "Epoch 52/100, Loss: 1.0010\n",
      "Epoch 53/100, Loss: 1.0020\n",
      "Epoch 54/100, Loss: 1.0015\n",
      "Epoch 55/100, Loss: 1.0014\n",
      "Epoch 56/100, Loss: 1.0019\n",
      "Epoch 57/100, Loss: 1.0014\n",
      "Epoch 58/100, Loss: 1.0015\n",
      "Epoch 59/100, Loss: 1.0014\n",
      "Epoch 60/100, Loss: 1.0014\n",
      "Epoch 61/100, Loss: 1.0015\n",
      "Epoch 62/100, Loss: 1.0015\n",
      "Epoch 63/100, Loss: 1.0019\n",
      "Epoch 64/100, Loss: 1.0013\n",
      "Epoch 65/100, Loss: 1.0011\n",
      "Epoch 66/100, Loss: 1.0015\n",
      "Epoch 67/100, Loss: 1.0022\n",
      "Epoch 68/100, Loss: 1.0019\n",
      "Epoch 69/100, Loss: 1.0013\n",
      "Epoch 70/100, Loss: 1.0014\n",
      "Epoch 71/100, Loss: 1.0012\n",
      "Epoch 72/100, Loss: 1.0013\n",
      "Epoch 73/100, Loss: 1.0018\n",
      "Epoch 74/100, Loss: 1.0013\n",
      "Epoch 75/100, Loss: 1.0019\n",
      "Epoch 76/100, Loss: 1.0007\n",
      "Epoch 77/100, Loss: 1.0018\n",
      "Epoch 78/100, Loss: 1.0015\n",
      "Epoch 79/100, Loss: 1.0015\n",
      "Epoch 80/100, Loss: 1.0018\n",
      "Epoch 81/100, Loss: 1.0017\n",
      "Epoch 82/100, Loss: 1.0015\n",
      "Epoch 83/100, Loss: 1.0014\n",
      "Epoch 84/100, Loss: 1.0013\n",
      "Epoch 85/100, Loss: 1.0014\n",
      "Epoch 86/100, Loss: 1.0020\n",
      "Epoch 87/100, Loss: 1.0013\n",
      "Epoch 88/100, Loss: 1.0007\n",
      "Epoch 89/100, Loss: 1.0025\n",
      "Epoch 90/100, Loss: 1.0017\n",
      "Epoch 91/100, Loss: 1.0016\n",
      "Epoch 92/100, Loss: 1.0016\n",
      "Epoch 93/100, Loss: 1.0014\n",
      "Epoch 94/100, Loss: 1.0012\n",
      "Epoch 95/100, Loss: 1.0018\n",
      "Epoch 96/100, Loss: 1.0020\n",
      "Epoch 97/100, Loss: 1.0017\n",
      "Epoch 98/100, Loss: 1.0015\n",
      "Epoch 99/100, Loss: 1.0013\n",
      "Epoch 100/100, Loss: 1.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 263.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1109\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.8, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 0.9985\n",
      "Epoch 2/100, Loss: 1.0096\n",
      "Epoch 3/100, Loss: 1.0068\n",
      "Epoch 4/100, Loss: 1.0085\n",
      "Epoch 5/100, Loss: 1.0104\n",
      "Epoch 6/100, Loss: 1.0076\n",
      "Epoch 7/100, Loss: 1.0065\n",
      "Epoch 8/100, Loss: 1.0087\n",
      "Epoch 9/100, Loss: 1.0065\n",
      "Epoch 10/100, Loss: 1.0098\n",
      "Epoch 11/100, Loss: 1.0072\n",
      "Epoch 12/100, Loss: 1.0112\n",
      "Epoch 13/100, Loss: 1.0093\n",
      "Epoch 14/100, Loss: 1.0064\n",
      "Epoch 15/100, Loss: 1.0093\n",
      "Epoch 16/100, Loss: 1.0056\n",
      "Epoch 17/100, Loss: 1.0090\n",
      "Epoch 18/100, Loss: 1.0081\n",
      "Epoch 19/100, Loss: 1.0058\n",
      "Epoch 20/100, Loss: 1.0062\n",
      "Epoch 21/100, Loss: 1.0105\n",
      "Epoch 22/100, Loss: 1.0096\n",
      "Epoch 23/100, Loss: 1.0051\n",
      "Epoch 24/100, Loss: 1.0108\n",
      "Epoch 25/100, Loss: 1.0074\n",
      "Epoch 26/100, Loss: 1.0050\n",
      "Epoch 27/100, Loss: 1.0068\n",
      "Epoch 28/100, Loss: 1.0101\n",
      "Epoch 29/100, Loss: 1.0056\n",
      "Epoch 30/100, Loss: 1.0067\n",
      "Epoch 31/100, Loss: 1.0101\n",
      "Epoch 32/100, Loss: 1.0063\n",
      "Epoch 33/100, Loss: 1.0067\n",
      "Epoch 34/100, Loss: 1.0062\n",
      "Epoch 35/100, Loss: 1.0093\n",
      "Epoch 36/100, Loss: 1.0074\n",
      "Epoch 37/100, Loss: 1.0080\n",
      "Epoch 38/100, Loss: 1.0074\n",
      "Epoch 39/100, Loss: 1.0082\n",
      "Epoch 40/100, Loss: 1.0073\n",
      "Epoch 41/100, Loss: 1.0113\n",
      "Epoch 42/100, Loss: 1.0084\n",
      "Epoch 43/100, Loss: 1.0119\n",
      "Epoch 44/100, Loss: 1.0078\n",
      "Epoch 45/100, Loss: 1.0084\n",
      "Epoch 46/100, Loss: 1.0055\n",
      "Epoch 47/100, Loss: 1.0088\n",
      "Epoch 48/100, Loss: 1.0070\n",
      "Epoch 49/100, Loss: 1.0076\n",
      "Epoch 50/100, Loss: 1.0074\n",
      "Epoch 51/100, Loss: 1.0081\n",
      "Epoch 52/100, Loss: 1.0099\n",
      "Epoch 53/100, Loss: 1.0074\n",
      "Epoch 54/100, Loss: 1.0070\n",
      "Epoch 55/100, Loss: 1.0068\n",
      "Epoch 56/100, Loss: 1.0087\n",
      "Epoch 57/100, Loss: 1.0089\n",
      "Epoch 58/100, Loss: 1.0088\n",
      "Epoch 59/100, Loss: 1.0088\n",
      "Epoch 60/100, Loss: 1.0065\n",
      "Epoch 61/100, Loss: 1.0094\n",
      "Epoch 62/100, Loss: 1.0076\n",
      "Epoch 63/100, Loss: 1.0075\n",
      "Epoch 64/100, Loss: 1.0094\n",
      "Epoch 65/100, Loss: 1.0091\n",
      "Epoch 66/100, Loss: 1.0085\n",
      "Epoch 67/100, Loss: 1.0063\n",
      "Epoch 68/100, Loss: 1.0073\n",
      "Epoch 69/100, Loss: 1.0092\n",
      "Epoch 70/100, Loss: 1.0055\n",
      "Epoch 71/100, Loss: 1.0113\n",
      "Epoch 72/100, Loss: 1.0070\n",
      "Epoch 73/100, Loss: 1.0069\n",
      "Epoch 74/100, Loss: 1.0086\n",
      "Epoch 75/100, Loss: 1.0077\n",
      "Epoch 76/100, Loss: 1.0063\n",
      "Epoch 77/100, Loss: 1.0067\n",
      "Epoch 78/100, Loss: 1.0087\n",
      "Epoch 79/100, Loss: 1.0063\n",
      "Epoch 80/100, Loss: 1.0069\n",
      "Epoch 81/100, Loss: 1.0083\n",
      "Epoch 82/100, Loss: 1.0055\n",
      "Epoch 83/100, Loss: 1.0076\n",
      "Epoch 84/100, Loss: 1.0065\n",
      "Epoch 85/100, Loss: 1.0084\n",
      "Epoch 86/100, Loss: 1.0096\n",
      "Epoch 87/100, Loss: 1.0077\n",
      "Epoch 88/100, Loss: 1.0082\n",
      "Epoch 89/100, Loss: 1.0078\n",
      "Epoch 90/100, Loss: 1.0080\n",
      "Epoch 91/100, Loss: 1.0066\n",
      "Epoch 92/100, Loss: 1.0064\n",
      "Epoch 93/100, Loss: 1.0066\n",
      "Epoch 94/100, Loss: 1.0070\n",
      "Epoch 95/100, Loss: 1.0042\n",
      "Epoch 96/100, Loss: 1.0094\n",
      "Epoch 97/100, Loss: 1.0089\n",
      "Epoch 98/100, Loss: 1.0085\n",
      "Epoch 99/100, Loss: 1.0074\n",
      "Epoch 100/100, Loss: 1.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 75.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1153\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.9447\n",
      "Epoch 2/100, Loss: 0.8762\n",
      "Epoch 3/100, Loss: 0.8298\n",
      "Epoch 4/100, Loss: 0.8182\n",
      "Epoch 5/100, Loss: 0.8145\n",
      "Epoch 6/100, Loss: 0.7863\n",
      "Epoch 7/100, Loss: 0.7936\n",
      "Epoch 8/100, Loss: 0.7792\n",
      "Epoch 9/100, Loss: 0.7951\n",
      "Epoch 10/100, Loss: 0.7837\n",
      "Epoch 11/100, Loss: 0.7674\n",
      "Epoch 12/100, Loss: 0.8029\n",
      "Epoch 13/100, Loss: 0.8211\n",
      "Epoch 14/100, Loss: 0.7729\n",
      "Epoch 15/100, Loss: 0.7667\n",
      "Epoch 16/100, Loss: 0.7775\n",
      "Epoch 17/100, Loss: 0.7697\n",
      "Epoch 18/100, Loss: 0.7724\n",
      "Epoch 19/100, Loss: 0.8047\n",
      "Epoch 20/100, Loss: 0.8373\n",
      "Epoch 21/100, Loss: 0.8169\n",
      "Epoch 22/100, Loss: 0.7902\n",
      "Epoch 23/100, Loss: 0.7666\n",
      "Epoch 24/100, Loss: 0.7581\n",
      "Epoch 25/100, Loss: 0.7904\n",
      "Epoch 26/100, Loss: 0.7755\n",
      "Epoch 27/100, Loss: 0.8104\n",
      "Epoch 28/100, Loss: 0.7675\n",
      "Epoch 29/100, Loss: 0.7602\n",
      "Epoch 30/100, Loss: 0.7577\n",
      "Epoch 31/100, Loss: 0.7577\n",
      "Epoch 32/100, Loss: 0.7713\n",
      "Epoch 33/100, Loss: 0.7939\n",
      "Epoch 34/100, Loss: 0.8569\n",
      "Epoch 35/100, Loss: 0.9767\n",
      "Epoch 36/100, Loss: 0.9693\n",
      "Epoch 37/100, Loss: 0.9213\n",
      "Epoch 38/100, Loss: 0.8067\n",
      "Epoch 39/100, Loss: 0.7735\n",
      "Epoch 40/100, Loss: 0.7604\n",
      "Epoch 41/100, Loss: 0.8347\n",
      "Epoch 42/100, Loss: 0.8402\n",
      "Epoch 43/100, Loss: 0.8322\n",
      "Epoch 44/100, Loss: 0.7929\n",
      "Epoch 45/100, Loss: 0.7694\n",
      "Epoch 46/100, Loss: 0.8045\n",
      "Epoch 47/100, Loss: 0.7756\n",
      "Epoch 48/100, Loss: 0.7688\n",
      "Epoch 49/100, Loss: 0.7646\n",
      "Epoch 50/100, Loss: 0.7639\n",
      "Epoch 51/100, Loss: 0.7629\n",
      "Epoch 52/100, Loss: 0.7627\n",
      "Epoch 53/100, Loss: 0.7643\n",
      "Epoch 54/100, Loss: 0.7639\n",
      "Epoch 55/100, Loss: 0.7630\n",
      "Epoch 56/100, Loss: 0.7625\n",
      "Epoch 57/100, Loss: 0.7639\n",
      "Epoch 58/100, Loss: 0.7622\n",
      "Epoch 59/100, Loss: 0.7647\n",
      "Epoch 60/100, Loss: 0.7635\n",
      "Epoch 61/100, Loss: 0.7621\n",
      "Epoch 62/100, Loss: 0.7657\n",
      "Epoch 63/100, Loss: 0.7651\n",
      "Epoch 64/100, Loss: 0.7621\n",
      "Epoch 65/100, Loss: 0.7623\n",
      "Epoch 66/100, Loss: 0.7623\n",
      "Epoch 67/100, Loss: 0.7626\n",
      "Epoch 68/100, Loss: 0.7620\n",
      "Epoch 69/100, Loss: 0.7635\n",
      "Epoch 70/100, Loss: 0.7629\n",
      "Epoch 71/100, Loss: 0.7624\n",
      "Epoch 72/100, Loss: 0.7627\n",
      "Epoch 73/100, Loss: 0.7633\n",
      "Epoch 74/100, Loss: 0.7619\n",
      "Epoch 75/100, Loss: 0.7627\n",
      "Epoch 76/100, Loss: 0.7624\n",
      "Epoch 77/100, Loss: 0.7637\n",
      "Epoch 78/100, Loss: 0.7649\n",
      "Epoch 79/100, Loss: 0.7632\n",
      "Epoch 80/100, Loss: 0.7618\n",
      "Epoch 81/100, Loss: 0.7625\n",
      "Epoch 82/100, Loss: 0.7627\n",
      "Epoch 83/100, Loss: 0.7621\n",
      "Epoch 84/100, Loss: 0.7620\n",
      "Epoch 85/100, Loss: 0.7624\n",
      "Epoch 86/100, Loss: 0.7638\n",
      "Epoch 87/100, Loss: 0.7625\n",
      "Epoch 88/100, Loss: 0.7630\n",
      "Epoch 89/100, Loss: 0.7620\n",
      "Epoch 90/100, Loss: 0.7622\n",
      "Epoch 91/100, Loss: 0.7620\n",
      "Epoch 92/100, Loss: 0.7670\n",
      "Epoch 93/100, Loss: 0.7637\n",
      "Epoch 94/100, Loss: 0.7625\n",
      "Epoch 95/100, Loss: 0.7635\n",
      "Epoch 96/100, Loss: 0.7634\n",
      "Epoch 97/100, Loss: 0.7649\n",
      "Epoch 98/100, Loss: 0.7623\n",
      "Epoch 99/100, Loss: 0.7636\n",
      "Epoch 100/100, Loss: 0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 95.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1885\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0076\n",
      "Epoch 2/100, Loss: 1.0019\n",
      "Epoch 3/100, Loss: 1.0018\n",
      "Epoch 4/100, Loss: 1.0013\n",
      "Epoch 5/100, Loss: 1.0024\n",
      "Epoch 6/100, Loss: 1.0013\n",
      "Epoch 7/100, Loss: 1.0008\n",
      "Epoch 8/100, Loss: 1.0009\n",
      "Epoch 9/100, Loss: 1.0019\n",
      "Epoch 10/100, Loss: 1.0016\n",
      "Epoch 11/100, Loss: 1.0014\n",
      "Epoch 12/100, Loss: 1.0025\n",
      "Epoch 13/100, Loss: 1.0015\n",
      "Epoch 14/100, Loss: 1.0015\n",
      "Epoch 15/100, Loss: 1.0014\n",
      "Epoch 16/100, Loss: 1.0007\n",
      "Epoch 17/100, Loss: 1.0018\n",
      "Epoch 18/100, Loss: 1.0017\n",
      "Epoch 19/100, Loss: 1.0011\n",
      "Epoch 20/100, Loss: 1.0013\n",
      "Epoch 21/100, Loss: 1.0019\n",
      "Epoch 22/100, Loss: 1.0016\n",
      "Epoch 23/100, Loss: 1.0013\n",
      "Epoch 24/100, Loss: 1.0015\n",
      "Epoch 25/100, Loss: 1.0015\n",
      "Epoch 26/100, Loss: 1.0012\n",
      "Epoch 27/100, Loss: 1.0018\n",
      "Epoch 28/100, Loss: 1.0018\n",
      "Epoch 29/100, Loss: 1.0016\n",
      "Epoch 30/100, Loss: 1.0016\n",
      "Epoch 31/100, Loss: 1.0011\n",
      "Epoch 32/100, Loss: 1.0016\n",
      "Epoch 33/100, Loss: 1.0012\n",
      "Epoch 34/100, Loss: 1.0016\n",
      "Epoch 35/100, Loss: 1.0013\n",
      "Epoch 36/100, Loss: 1.0010\n",
      "Epoch 37/100, Loss: 1.0015\n",
      "Epoch 38/100, Loss: 1.0009\n",
      "Epoch 39/100, Loss: 1.0015\n",
      "Epoch 40/100, Loss: 1.0011\n",
      "Epoch 41/100, Loss: 1.0024\n",
      "Epoch 42/100, Loss: 1.0015\n",
      "Epoch 43/100, Loss: 1.0021\n",
      "Epoch 44/100, Loss: 1.0017\n",
      "Epoch 45/100, Loss: 1.0013\n",
      "Epoch 46/100, Loss: 1.0011\n",
      "Epoch 47/100, Loss: 1.0019\n",
      "Epoch 48/100, Loss: 1.0015\n",
      "Epoch 49/100, Loss: 1.0015\n",
      "Epoch 50/100, Loss: 1.0015\n",
      "Epoch 51/100, Loss: 1.0019\n",
      "Epoch 52/100, Loss: 1.0018\n",
      "Epoch 53/100, Loss: 1.0008\n",
      "Epoch 54/100, Loss: 1.0018\n",
      "Epoch 55/100, Loss: 1.0017\n",
      "Epoch 56/100, Loss: 1.0017\n",
      "Epoch 57/100, Loss: 1.0018\n",
      "Epoch 58/100, Loss: 1.0018\n",
      "Epoch 59/100, Loss: 1.0018\n",
      "Epoch 60/100, Loss: 1.0022\n",
      "Epoch 61/100, Loss: 1.0016\n",
      "Epoch 62/100, Loss: 1.0016\n",
      "Epoch 63/100, Loss: 1.0017\n",
      "Epoch 64/100, Loss: 1.0020\n",
      "Epoch 65/100, Loss: 1.0017\n",
      "Epoch 66/100, Loss: 1.0016\n",
      "Epoch 67/100, Loss: 1.0018\n",
      "Epoch 68/100, Loss: 1.0011\n",
      "Epoch 69/100, Loss: 1.0014\n",
      "Epoch 70/100, Loss: 1.0017\n",
      "Epoch 71/100, Loss: 1.0019\n",
      "Epoch 72/100, Loss: 1.0012\n",
      "Epoch 73/100, Loss: 1.0019\n",
      "Epoch 74/100, Loss: 1.0017\n",
      "Epoch 75/100, Loss: 1.0017\n",
      "Epoch 76/100, Loss: 1.0009\n",
      "Epoch 77/100, Loss: 1.0016\n",
      "Epoch 78/100, Loss: 1.0017\n",
      "Epoch 79/100, Loss: 1.0018\n",
      "Epoch 80/100, Loss: 1.0016\n",
      "Epoch 81/100, Loss: 1.0019\n",
      "Epoch 82/100, Loss: 1.0012\n",
      "Epoch 83/100, Loss: 1.0014\n",
      "Epoch 84/100, Loss: 1.0018\n",
      "Epoch 85/100, Loss: 1.0015\n",
      "Epoch 86/100, Loss: 1.0016\n",
      "Epoch 87/100, Loss: 1.0012\n",
      "Epoch 88/100, Loss: 1.0012\n",
      "Epoch 89/100, Loss: 1.0019\n",
      "Epoch 90/100, Loss: 1.0017\n",
      "Epoch 91/100, Loss: 1.0019\n",
      "Epoch 92/100, Loss: 1.0017\n",
      "Epoch 93/100, Loss: 1.0016\n",
      "Epoch 94/100, Loss: 1.0020\n",
      "Epoch 95/100, Loss: 1.0014\n",
      "Epoch 96/100, Loss: 1.0010\n",
      "Epoch 97/100, Loss: 1.0022\n",
      "Epoch 98/100, Loss: 1.0017\n",
      "Epoch 99/100, Loss: 1.0012\n",
      "Epoch 100/100, Loss: 1.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 289.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1296\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0121\n",
      "Epoch 2/100, Loss: 1.0059\n",
      "Epoch 3/100, Loss: 1.0059\n",
      "Epoch 4/100, Loss: 1.0112\n",
      "Epoch 5/100, Loss: 1.0098\n",
      "Epoch 6/100, Loss: 1.0068\n",
      "Epoch 7/100, Loss: 1.0066\n",
      "Epoch 8/100, Loss: 1.0069\n",
      "Epoch 9/100, Loss: 1.0078\n",
      "Epoch 10/100, Loss: 1.0100\n",
      "Epoch 11/100, Loss: 1.0061\n",
      "Epoch 12/100, Loss: 1.0079\n",
      "Epoch 13/100, Loss: 1.0092\n",
      "Epoch 14/100, Loss: 1.0076\n",
      "Epoch 15/100, Loss: 1.0065\n",
      "Epoch 16/100, Loss: 1.0079\n",
      "Epoch 17/100, Loss: 1.0093\n",
      "Epoch 18/100, Loss: 1.0052\n",
      "Epoch 19/100, Loss: 1.0093\n",
      "Epoch 20/100, Loss: 1.0064\n",
      "Epoch 21/100, Loss: 1.0081\n",
      "Epoch 22/100, Loss: 1.0092\n",
      "Epoch 23/100, Loss: 1.0058\n",
      "Epoch 24/100, Loss: 1.0077\n",
      "Epoch 25/100, Loss: 1.0076\n",
      "Epoch 26/100, Loss: 1.0039\n",
      "Epoch 27/100, Loss: 1.0091\n",
      "Epoch 28/100, Loss: 1.0068\n",
      "Epoch 29/100, Loss: 1.0073\n",
      "Epoch 30/100, Loss: 1.0089\n",
      "Epoch 31/100, Loss: 1.0083\n",
      "Epoch 32/100, Loss: 1.0080\n",
      "Epoch 33/100, Loss: 1.0089\n",
      "Epoch 34/100, Loss: 1.0079\n",
      "Epoch 35/100, Loss: 1.0062\n",
      "Epoch 36/100, Loss: 1.0069\n",
      "Epoch 37/100, Loss: 1.0086\n",
      "Epoch 38/100, Loss: 1.0080\n",
      "Epoch 39/100, Loss: 1.0070\n",
      "Epoch 40/100, Loss: 1.0071\n",
      "Epoch 41/100, Loss: 1.0107\n",
      "Epoch 42/100, Loss: 1.0079\n",
      "Epoch 43/100, Loss: 1.0106\n",
      "Epoch 44/100, Loss: 1.0067\n",
      "Epoch 45/100, Loss: 1.0090\n",
      "Epoch 46/100, Loss: 1.0061\n",
      "Epoch 47/100, Loss: 1.0092\n",
      "Epoch 48/100, Loss: 1.0062\n",
      "Epoch 49/100, Loss: 1.0081\n",
      "Epoch 50/100, Loss: 1.0058\n",
      "Epoch 51/100, Loss: 1.0111\n",
      "Epoch 52/100, Loss: 1.0069\n",
      "Epoch 53/100, Loss: 1.0072\n",
      "Epoch 54/100, Loss: 1.0061\n",
      "Epoch 55/100, Loss: 1.0088\n",
      "Epoch 56/100, Loss: 1.0094\n",
      "Epoch 57/100, Loss: 1.0068\n",
      "Epoch 58/100, Loss: 1.0088\n",
      "Epoch 59/100, Loss: 1.0065\n",
      "Epoch 60/100, Loss: 1.0073\n",
      "Epoch 61/100, Loss: 1.0063\n",
      "Epoch 62/100, Loss: 1.0098\n",
      "Epoch 63/100, Loss: 1.0059\n",
      "Epoch 64/100, Loss: 1.0088\n",
      "Epoch 65/100, Loss: 1.0073\n",
      "Epoch 66/100, Loss: 1.0088\n",
      "Epoch 67/100, Loss: 1.0063\n",
      "Epoch 68/100, Loss: 1.0077\n",
      "Epoch 69/100, Loss: 1.0090\n",
      "Epoch 70/100, Loss: 1.0083\n",
      "Epoch 71/100, Loss: 1.0088\n",
      "Epoch 72/100, Loss: 1.0097\n",
      "Epoch 73/100, Loss: 1.0099\n",
      "Epoch 74/100, Loss: 1.0092\n",
      "Epoch 75/100, Loss: 1.0071\n",
      "Epoch 76/100, Loss: 1.0074\n",
      "Epoch 77/100, Loss: 1.0102\n",
      "Epoch 78/100, Loss: 1.0074\n",
      "Epoch 79/100, Loss: 1.0102\n",
      "Epoch 80/100, Loss: 1.0086\n",
      "Epoch 81/100, Loss: 1.0070\n",
      "Epoch 82/100, Loss: 1.0074\n",
      "Epoch 83/100, Loss: 1.0089\n",
      "Epoch 84/100, Loss: 1.0064\n",
      "Epoch 85/100, Loss: 1.0084\n",
      "Epoch 86/100, Loss: 1.0061\n",
      "Epoch 87/100, Loss: 1.0081\n",
      "Epoch 88/100, Loss: 1.0071\n",
      "Epoch 89/100, Loss: 1.0109\n",
      "Epoch 90/100, Loss: 1.0091\n",
      "Epoch 91/100, Loss: 1.0068\n",
      "Epoch 92/100, Loss: 1.0089\n",
      "Epoch 93/100, Loss: 1.0079\n",
      "Epoch 94/100, Loss: 1.0080\n",
      "Epoch 95/100, Loss: 1.0110\n",
      "Epoch 96/100, Loss: 1.0089\n",
      "Epoch 97/100, Loss: 1.0105\n",
      "Epoch 98/100, Loss: 1.0089\n",
      "Epoch 99/100, Loss: 1.0090\n",
      "Epoch 100/100, Loss: 1.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 269.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1141\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.6206\n",
      "Epoch 2/100, Loss: 0.5166\n",
      "Epoch 3/100, Loss: 0.4650\n",
      "Epoch 4/100, Loss: 0.3452\n",
      "Epoch 5/100, Loss: 0.3008\n",
      "Epoch 6/100, Loss: 0.3341\n",
      "Epoch 7/100, Loss: 0.3090\n",
      "Epoch 8/100, Loss: 0.2555\n",
      "Epoch 9/100, Loss: 0.2473\n",
      "Epoch 10/100, Loss: 0.2824\n",
      "Epoch 11/100, Loss: 0.2793\n",
      "Epoch 12/100, Loss: 0.2432\n",
      "Epoch 13/100, Loss: 0.3282\n",
      "Epoch 14/100, Loss: 0.2558\n",
      "Epoch 15/100, Loss: 0.2431\n",
      "Epoch 16/100, Loss: 0.2729\n",
      "Epoch 17/100, Loss: 0.2541\n",
      "Epoch 18/100, Loss: 0.2110\n",
      "Epoch 19/100, Loss: 0.2398\n",
      "Epoch 20/100, Loss: 0.3745\n",
      "Epoch 21/100, Loss: 0.3012\n",
      "Epoch 22/100, Loss: 0.2345\n",
      "Epoch 23/100, Loss: 0.1986\n",
      "Epoch 24/100, Loss: 0.1963\n",
      "Epoch 25/100, Loss: 0.2248\n",
      "Epoch 26/100, Loss: 0.2177\n",
      "Epoch 27/100, Loss: 0.1938\n",
      "Epoch 28/100, Loss: 0.3105\n",
      "Epoch 29/100, Loss: 0.2623\n",
      "Epoch 30/100, Loss: 0.2610\n",
      "Epoch 31/100, Loss: 0.2477\n",
      "Epoch 32/100, Loss: 0.1961\n",
      "Epoch 33/100, Loss: 0.1948\n",
      "Epoch 34/100, Loss: 0.2275\n",
      "Epoch 35/100, Loss: 0.2215\n",
      "Epoch 36/100, Loss: 0.2129\n",
      "Epoch 37/100, Loss: 0.2508\n",
      "Epoch 38/100, Loss: 0.2291\n",
      "Epoch 39/100, Loss: 0.2398\n",
      "Epoch 40/100, Loss: 0.2051\n",
      "Epoch 41/100, Loss: 0.2449\n",
      "Epoch 42/100, Loss: 0.2070\n",
      "Epoch 43/100, Loss: 0.2131\n",
      "Epoch 44/100, Loss: 0.1438\n",
      "Epoch 45/100, Loss: 0.1829\n",
      "Epoch 46/100, Loss: 0.1986\n",
      "Epoch 47/100, Loss: 0.1579\n",
      "Epoch 48/100, Loss: 0.1401\n",
      "Epoch 49/100, Loss: 0.1211\n",
      "Epoch 50/100, Loss: 0.2022\n",
      "Epoch 51/100, Loss: 0.2005\n",
      "Epoch 52/100, Loss: 0.1649\n",
      "Epoch 53/100, Loss: 0.1490\n",
      "Epoch 54/100, Loss: 0.1290\n",
      "Epoch 55/100, Loss: 0.1535\n",
      "Epoch 56/100, Loss: 0.1274\n",
      "Epoch 57/100, Loss: 0.1900\n",
      "Epoch 58/100, Loss: 0.1762\n",
      "Epoch 59/100, Loss: 0.2083\n",
      "Epoch 60/100, Loss: 0.1880\n",
      "Epoch 61/100, Loss: 0.1666\n",
      "Epoch 62/100, Loss: 0.1570\n",
      "Epoch 63/100, Loss: 0.1537\n",
      "Epoch 64/100, Loss: 0.1444\n",
      "Epoch 65/100, Loss: 0.1519\n",
      "Epoch 66/100, Loss: 0.1513\n",
      "Epoch 67/100, Loss: 0.2054\n",
      "Epoch 68/100, Loss: 0.1580\n",
      "Epoch 69/100, Loss: 0.1607\n",
      "Epoch 70/100, Loss: 0.1406\n",
      "Epoch 71/100, Loss: 0.1208\n",
      "Epoch 72/100, Loss: 0.1189\n",
      "Epoch 73/100, Loss: 0.1318\n",
      "Epoch 74/100, Loss: 0.1503\n",
      "Epoch 75/100, Loss: 0.1288\n",
      "Epoch 76/100, Loss: 0.1244\n",
      "Epoch 77/100, Loss: 0.1736\n",
      "Epoch 78/100, Loss: 0.1652\n",
      "Epoch 79/100, Loss: 0.1853\n",
      "Epoch 80/100, Loss: 0.1776\n",
      "Epoch 81/100, Loss: 0.1628\n",
      "Epoch 82/100, Loss: 0.1151\n",
      "Epoch 83/100, Loss: 0.1243\n",
      "Epoch 84/100, Loss: 0.1205\n",
      "Epoch 85/100, Loss: 0.1806\n",
      "Epoch 86/100, Loss: 0.1811\n",
      "Epoch 87/100, Loss: 0.1327\n",
      "Epoch 88/100, Loss: 0.1015\n",
      "Epoch 89/100, Loss: 0.1137\n",
      "Epoch 90/100, Loss: 0.1228\n",
      "Epoch 91/100, Loss: 0.1625\n",
      "Epoch 92/100, Loss: 0.1800\n",
      "Epoch 93/100, Loss: 0.1211\n",
      "Epoch 94/100, Loss: 0.1148\n",
      "Epoch 95/100, Loss: 0.1164\n",
      "Epoch 96/100, Loss: 0.1178\n",
      "Epoch 97/100, Loss: 0.1382\n",
      "Epoch 98/100, Loss: 0.1131\n",
      "Epoch 99/100, Loss: 0.1177\n",
      "Epoch 100/100, Loss: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 164.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3470\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.7954\n",
      "Epoch 2/100, Loss: 0.6224\n",
      "Epoch 3/100, Loss: 0.6234\n",
      "Epoch 4/100, Loss: 0.6944\n",
      "Epoch 5/100, Loss: 0.9099\n",
      "Epoch 6/100, Loss: 0.6628\n",
      "Epoch 7/100, Loss: 0.5812\n",
      "Epoch 8/100, Loss: 0.6852\n",
      "Epoch 9/100, Loss: 0.7787\n",
      "Epoch 10/100, Loss: 0.7018\n",
      "Epoch 11/100, Loss: 0.7841\n",
      "Epoch 12/100, Loss: 0.7900\n",
      "Epoch 13/100, Loss: 0.6948\n",
      "Epoch 14/100, Loss: 0.7871\n",
      "Epoch 15/100, Loss: 0.7234\n",
      "Epoch 16/100, Loss: 0.7329\n",
      "Epoch 17/100, Loss: 0.5413\n",
      "Epoch 18/100, Loss: 0.5396\n",
      "Epoch 19/100, Loss: 0.6872\n",
      "Epoch 20/100, Loss: 0.7504\n",
      "Epoch 21/100, Loss: 0.6146\n",
      "Epoch 22/100, Loss: 0.5673\n",
      "Epoch 23/100, Loss: 0.6367\n",
      "Epoch 24/100, Loss: 0.5408\n",
      "Epoch 25/100, Loss: 0.6004\n",
      "Epoch 26/100, Loss: 0.5746\n",
      "Epoch 27/100, Loss: 0.5540\n",
      "Epoch 28/100, Loss: 0.5764\n",
      "Epoch 29/100, Loss: 0.5429\n",
      "Epoch 30/100, Loss: 0.6071\n",
      "Epoch 31/100, Loss: 0.5710\n",
      "Epoch 32/100, Loss: 0.5410\n",
      "Epoch 33/100, Loss: 0.5293\n",
      "Epoch 34/100, Loss: 0.5226\n",
      "Epoch 35/100, Loss: 0.5278\n",
      "Epoch 36/100, Loss: 0.5918\n",
      "Epoch 37/100, Loss: 0.5673\n",
      "Epoch 38/100, Loss: 0.5457\n",
      "Epoch 39/100, Loss: 0.5557\n",
      "Epoch 40/100, Loss: 0.5884\n",
      "Epoch 41/100, Loss: 0.5833\n",
      "Epoch 42/100, Loss: 0.5514\n",
      "Epoch 43/100, Loss: 0.5349\n",
      "Epoch 44/100, Loss: 0.5351\n",
      "Epoch 45/100, Loss: 0.5336\n",
      "Epoch 46/100, Loss: 0.5350\n",
      "Epoch 47/100, Loss: 0.5384\n",
      "Epoch 48/100, Loss: 0.5336\n",
      "Epoch 49/100, Loss: 0.5328\n",
      "Epoch 50/100, Loss: 0.5331\n",
      "Epoch 51/100, Loss: 0.5349\n",
      "Epoch 52/100, Loss: 0.5384\n",
      "Epoch 53/100, Loss: 0.5325\n",
      "Epoch 54/100, Loss: 0.5365\n",
      "Epoch 55/100, Loss: 0.5337\n",
      "Epoch 56/100, Loss: 0.5333\n",
      "Epoch 57/100, Loss: 0.5358\n",
      "Epoch 58/100, Loss: 0.5355\n",
      "Epoch 59/100, Loss: 0.5350\n",
      "Epoch 60/100, Loss: 0.5345\n",
      "Epoch 61/100, Loss: 0.5339\n",
      "Epoch 62/100, Loss: 0.5340\n",
      "Epoch 63/100, Loss: 0.5324\n",
      "Epoch 64/100, Loss: 0.5346\n",
      "Epoch 65/100, Loss: 0.5355\n",
      "Epoch 66/100, Loss: 0.5358\n",
      "Epoch 67/100, Loss: 0.5329\n",
      "Epoch 68/100, Loss: 0.5354\n",
      "Epoch 69/100, Loss: 0.5326\n",
      "Epoch 70/100, Loss: 0.5323\n",
      "Epoch 71/100, Loss: 0.5331\n",
      "Epoch 72/100, Loss: 0.5334\n",
      "Epoch 73/100, Loss: 0.5335\n",
      "Epoch 74/100, Loss: 0.5327\n",
      "Epoch 75/100, Loss: 0.5340\n",
      "Epoch 76/100, Loss: 0.5350\n",
      "Epoch 77/100, Loss: 0.5344\n",
      "Epoch 78/100, Loss: 0.5337\n",
      "Epoch 79/100, Loss: 0.5343\n",
      "Epoch 80/100, Loss: 0.5346\n",
      "Epoch 81/100, Loss: 0.5360\n",
      "Epoch 82/100, Loss: 0.5358\n",
      "Epoch 83/100, Loss: 0.5385\n",
      "Epoch 84/100, Loss: 0.5365\n",
      "Epoch 85/100, Loss: 0.5359\n",
      "Epoch 86/100, Loss: 0.5335\n",
      "Epoch 87/100, Loss: 0.5365\n",
      "Epoch 88/100, Loss: 0.5350\n",
      "Epoch 89/100, Loss: 0.5347\n",
      "Epoch 90/100, Loss: 0.5347\n",
      "Epoch 91/100, Loss: 0.5344\n",
      "Epoch 92/100, Loss: 0.5354\n",
      "Epoch 93/100, Loss: 0.5338\n",
      "Epoch 94/100, Loss: 0.5368\n",
      "Epoch 95/100, Loss: 0.5351\n",
      "Epoch 96/100, Loss: 0.5338\n",
      "Epoch 97/100, Loss: 0.5336\n",
      "Epoch 98/100, Loss: 0.5374\n",
      "Epoch 99/100, Loss: 0.5327\n",
      "Epoch 100/100, Loss: 0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 80.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2332\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0081\n",
      "Epoch 2/100, Loss: 1.0087\n",
      "Epoch 3/100, Loss: 1.0069\n",
      "Epoch 4/100, Loss: 1.0070\n",
      "Epoch 5/100, Loss: 1.0078\n",
      "Epoch 6/100, Loss: 1.0079\n",
      "Epoch 7/100, Loss: 1.0066\n",
      "Epoch 8/100, Loss: 1.0083\n",
      "Epoch 9/100, Loss: 1.0100\n",
      "Epoch 10/100, Loss: 1.0095\n",
      "Epoch 11/100, Loss: 1.0107\n",
      "Epoch 12/100, Loss: 1.0071\n",
      "Epoch 13/100, Loss: 1.0073\n",
      "Epoch 14/100, Loss: 1.0068\n",
      "Epoch 15/100, Loss: 1.0099\n",
      "Epoch 16/100, Loss: 1.0098\n",
      "Epoch 17/100, Loss: 1.0079\n",
      "Epoch 18/100, Loss: 1.0069\n",
      "Epoch 19/100, Loss: 1.0081\n",
      "Epoch 20/100, Loss: 1.0078\n",
      "Epoch 21/100, Loss: 1.0089\n",
      "Epoch 22/100, Loss: 1.0056\n",
      "Epoch 23/100, Loss: 1.0064\n",
      "Epoch 24/100, Loss: 1.0073\n",
      "Epoch 25/100, Loss: 1.0096\n",
      "Epoch 26/100, Loss: 1.0092\n",
      "Epoch 27/100, Loss: 1.0064\n",
      "Epoch 28/100, Loss: 1.0065\n",
      "Epoch 29/100, Loss: 1.0100\n",
      "Epoch 30/100, Loss: 1.0066\n",
      "Epoch 31/100, Loss: 1.0075\n",
      "Epoch 32/100, Loss: 1.0087\n",
      "Epoch 33/100, Loss: 1.0071\n",
      "Epoch 34/100, Loss: 1.0059\n",
      "Epoch 35/100, Loss: 1.0079\n",
      "Epoch 36/100, Loss: 1.0074\n",
      "Epoch 37/100, Loss: 1.0082\n",
      "Epoch 38/100, Loss: 1.0069\n",
      "Epoch 39/100, Loss: 1.0090\n",
      "Epoch 40/100, Loss: 1.0085\n",
      "Epoch 41/100, Loss: 1.0096\n",
      "Epoch 42/100, Loss: 1.0081\n",
      "Epoch 43/100, Loss: 1.0069\n",
      "Epoch 44/100, Loss: 1.0074\n",
      "Epoch 45/100, Loss: 1.0058\n",
      "Epoch 46/100, Loss: 1.0061\n",
      "Epoch 47/100, Loss: 1.0079\n",
      "Epoch 48/100, Loss: 1.0058\n",
      "Epoch 49/100, Loss: 1.0063\n",
      "Epoch 50/100, Loss: 1.0088\n",
      "Epoch 51/100, Loss: 1.0083\n",
      "Epoch 52/100, Loss: 1.0073\n",
      "Epoch 53/100, Loss: 1.0074\n",
      "Epoch 54/100, Loss: 1.0079\n",
      "Epoch 55/100, Loss: 1.0068\n",
      "Epoch 56/100, Loss: 1.0065\n",
      "Epoch 57/100, Loss: 1.0064\n",
      "Epoch 58/100, Loss: 1.0075\n",
      "Epoch 59/100, Loss: 1.0089\n",
      "Epoch 60/100, Loss: 1.0073\n",
      "Epoch 61/100, Loss: 1.0109\n",
      "Epoch 62/100, Loss: 1.0079\n",
      "Epoch 63/100, Loss: 1.0102\n",
      "Epoch 64/100, Loss: 1.0091\n",
      "Epoch 65/100, Loss: 1.0074\n",
      "Epoch 66/100, Loss: 1.0079\n",
      "Epoch 67/100, Loss: 1.0088\n",
      "Epoch 68/100, Loss: 1.0085\n",
      "Epoch 69/100, Loss: 1.0074\n",
      "Epoch 70/100, Loss: 1.0090\n",
      "Epoch 71/100, Loss: 1.0091\n",
      "Epoch 72/100, Loss: 1.0077\n",
      "Epoch 73/100, Loss: 1.0066\n",
      "Epoch 74/100, Loss: 1.0054\n",
      "Epoch 75/100, Loss: 1.0078\n",
      "Epoch 76/100, Loss: 1.0093\n",
      "Epoch 77/100, Loss: 1.0055\n",
      "Epoch 78/100, Loss: 1.0074\n",
      "Epoch 79/100, Loss: 1.0070\n",
      "Epoch 80/100, Loss: 1.0064\n",
      "Epoch 81/100, Loss: 1.0084\n",
      "Epoch 82/100, Loss: 1.0083\n",
      "Epoch 83/100, Loss: 1.0082\n",
      "Epoch 84/100, Loss: 1.0087\n",
      "Epoch 85/100, Loss: 1.0065\n",
      "Epoch 86/100, Loss: 1.0063\n",
      "Epoch 87/100, Loss: 1.0081\n",
      "Epoch 88/100, Loss: 1.0074\n",
      "Epoch 89/100, Loss: 1.0082\n",
      "Epoch 90/100, Loss: 1.0071\n",
      "Epoch 91/100, Loss: 1.0057\n",
      "Epoch 92/100, Loss: 1.0065\n",
      "Epoch 93/100, Loss: 1.0069\n",
      "Epoch 94/100, Loss: 1.0067\n",
      "Epoch 95/100, Loss: 1.0082\n",
      "Epoch 96/100, Loss: 1.0071\n",
      "Epoch 97/100, Loss: 1.0066\n",
      "Epoch 98/100, Loss: 1.0083\n",
      "Epoch 99/100, Loss: 1.0064\n",
      "Epoch 100/100, Loss: 1.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 131.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1114\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.5607\n",
      "Epoch 2/100, Loss: 0.3877\n",
      "Epoch 3/100, Loss: 0.3445\n",
      "Epoch 4/100, Loss: 0.2698\n",
      "Epoch 5/100, Loss: 0.2556\n",
      "Epoch 6/100, Loss: 0.2412\n",
      "Epoch 7/100, Loss: 0.2186\n",
      "Epoch 8/100, Loss: 0.2190\n",
      "Epoch 9/100, Loss: 0.1927\n",
      "Epoch 10/100, Loss: 0.1966\n",
      "Epoch 11/100, Loss: 0.1428\n",
      "Epoch 12/100, Loss: 0.1042\n",
      "Epoch 13/100, Loss: 0.0923\n",
      "Epoch 14/100, Loss: 0.0765\n",
      "Epoch 15/100, Loss: -0.0693\n",
      "Epoch 16/100, Loss: -0.1305\n",
      "Epoch 17/100, Loss: -0.1699\n",
      "Epoch 18/100, Loss: -0.1407\n",
      "Epoch 19/100, Loss: -0.1360\n",
      "Epoch 20/100, Loss: -0.1766\n",
      "Epoch 21/100, Loss: -0.1899\n",
      "Epoch 22/100, Loss: -0.1892\n",
      "Epoch 23/100, Loss: -0.1846\n",
      "Epoch 24/100, Loss: -0.1911\n",
      "Epoch 25/100, Loss: -0.1715\n",
      "Epoch 26/100, Loss: -0.2422\n",
      "Epoch 27/100, Loss: -0.2409\n",
      "Epoch 28/100, Loss: -0.2645\n",
      "Epoch 29/100, Loss: -0.1885\n",
      "Epoch 30/100, Loss: -0.2541\n",
      "Epoch 31/100, Loss: -0.2645\n",
      "Epoch 32/100, Loss: -0.2463\n",
      "Epoch 33/100, Loss: -0.2339\n",
      "Epoch 34/100, Loss: -0.2897\n",
      "Epoch 35/100, Loss: -0.2629\n",
      "Epoch 36/100, Loss: -0.2624\n",
      "Epoch 37/100, Loss: -0.2299\n",
      "Epoch 38/100, Loss: -0.1977\n",
      "Epoch 39/100, Loss: -0.2391\n",
      "Epoch 40/100, Loss: -0.2536\n",
      "Epoch 41/100, Loss: -0.1536\n",
      "Epoch 42/100, Loss: -0.2182\n",
      "Epoch 43/100, Loss: -0.2057\n",
      "Epoch 44/100, Loss: -0.2552\n",
      "Epoch 45/100, Loss: -0.2491\n",
      "Epoch 46/100, Loss: -0.2702\n",
      "Epoch 47/100, Loss: -0.2791\n",
      "Epoch 48/100, Loss: -0.2614\n",
      "Epoch 49/100, Loss: -0.2444\n",
      "Epoch 50/100, Loss: -0.2688\n",
      "Epoch 51/100, Loss: -0.2472\n",
      "Epoch 52/100, Loss: -0.2616\n",
      "Epoch 53/100, Loss: -0.2704\n",
      "Epoch 54/100, Loss: -0.2909\n",
      "Epoch 55/100, Loss: -0.2813\n",
      "Epoch 56/100, Loss: -0.2424\n",
      "Epoch 57/100, Loss: -0.2686\n",
      "Epoch 58/100, Loss: -0.2691\n",
      "Epoch 59/100, Loss: -0.2684\n",
      "Epoch 60/100, Loss: -0.2873\n",
      "Epoch 61/100, Loss: -0.2902\n",
      "Epoch 62/100, Loss: -0.2263\n",
      "Epoch 63/100, Loss: -0.2572\n",
      "Epoch 64/100, Loss: -0.1889\n",
      "Epoch 65/100, Loss: -0.2684\n",
      "Epoch 66/100, Loss: -0.2097\n",
      "Epoch 67/100, Loss: -0.2497\n",
      "Epoch 68/100, Loss: -0.3052\n",
      "Epoch 69/100, Loss: -0.2308\n",
      "Epoch 70/100, Loss: -0.2123\n",
      "Epoch 71/100, Loss: -0.2407\n",
      "Epoch 72/100, Loss: -0.2559\n",
      "Epoch 73/100, Loss: -0.3011\n",
      "Epoch 74/100, Loss: -0.2932\n",
      "Epoch 75/100, Loss: -0.3084\n",
      "Epoch 76/100, Loss: -0.3127\n",
      "Epoch 77/100, Loss: -0.3000\n",
      "Epoch 78/100, Loss: -0.3111\n",
      "Epoch 79/100, Loss: -0.3000\n",
      "Epoch 80/100, Loss: -0.3270\n",
      "Epoch 81/100, Loss: -0.2815\n",
      "Epoch 82/100, Loss: -0.2951\n",
      "Epoch 83/100, Loss: -0.2703\n",
      "Epoch 84/100, Loss: -0.2592\n",
      "Epoch 85/100, Loss: -0.2645\n",
      "Epoch 86/100, Loss: -0.2589\n",
      "Epoch 87/100, Loss: -0.2563\n",
      "Epoch 88/100, Loss: -0.2822\n",
      "Epoch 89/100, Loss: -0.2886\n",
      "Epoch 90/100, Loss: -0.3189\n",
      "Epoch 91/100, Loss: -0.3051\n",
      "Epoch 92/100, Loss: -0.2630\n",
      "Epoch 93/100, Loss: -0.2563\n",
      "Epoch 94/100, Loss: -0.2956\n",
      "Epoch 95/100, Loss: -0.3090\n",
      "Epoch 96/100, Loss: -0.3194\n",
      "Epoch 97/100, Loss: -0.3137\n",
      "Epoch 98/100, Loss: -0.3119\n",
      "Epoch 99/100, Loss: -0.3128\n",
      "Epoch 100/100, Loss: -0.3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 174.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.4685\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.9172\n",
      "Epoch 2/100, Loss: 1.0014\n",
      "Epoch 3/100, Loss: 1.0021\n",
      "Epoch 4/100, Loss: 1.0020\n",
      "Epoch 5/100, Loss: 1.0014\n",
      "Epoch 6/100, Loss: 1.0020\n",
      "Epoch 7/100, Loss: 1.0018\n",
      "Epoch 8/100, Loss: 1.0011\n",
      "Epoch 9/100, Loss: 1.0021\n",
      "Epoch 10/100, Loss: 1.0011\n",
      "Epoch 11/100, Loss: 1.0019\n",
      "Epoch 12/100, Loss: 1.0021\n",
      "Epoch 13/100, Loss: 1.0011\n",
      "Epoch 14/100, Loss: 1.0018\n",
      "Epoch 15/100, Loss: 1.0008\n",
      "Epoch 16/100, Loss: 1.0019\n",
      "Epoch 17/100, Loss: 1.0013\n",
      "Epoch 18/100, Loss: 1.0013\n",
      "Epoch 19/100, Loss: 1.0010\n",
      "Epoch 20/100, Loss: 1.0015\n",
      "Epoch 21/100, Loss: 1.0012\n",
      "Epoch 22/100, Loss: 1.0016\n",
      "Epoch 23/100, Loss: 1.0016\n",
      "Epoch 24/100, Loss: 1.0013\n",
      "Epoch 25/100, Loss: 1.0023\n",
      "Epoch 26/100, Loss: 1.0016\n",
      "Epoch 27/100, Loss: 1.0022\n",
      "Epoch 28/100, Loss: 1.0016\n",
      "Epoch 29/100, Loss: 1.0019\n",
      "Epoch 30/100, Loss: 1.0016\n",
      "Epoch 31/100, Loss: 1.0009\n",
      "Epoch 32/100, Loss: 1.0016\n",
      "Epoch 33/100, Loss: 1.0020\n",
      "Epoch 34/100, Loss: 1.0015\n",
      "Epoch 35/100, Loss: 1.0009\n",
      "Epoch 36/100, Loss: 1.0018\n",
      "Epoch 37/100, Loss: 1.0020\n",
      "Epoch 38/100, Loss: 1.0020\n",
      "Epoch 39/100, Loss: 1.0019\n",
      "Epoch 40/100, Loss: 1.0021\n",
      "Epoch 41/100, Loss: 1.0017\n",
      "Epoch 42/100, Loss: 1.0025\n",
      "Epoch 43/100, Loss: 1.0017\n",
      "Epoch 44/100, Loss: 1.0011\n",
      "Epoch 45/100, Loss: 1.0022\n",
      "Epoch 46/100, Loss: 1.0014\n",
      "Epoch 47/100, Loss: 1.0010\n",
      "Epoch 48/100, Loss: 1.0025\n",
      "Epoch 49/100, Loss: 1.0021\n",
      "Epoch 50/100, Loss: 1.0020\n",
      "Epoch 51/100, Loss: 1.0018\n",
      "Epoch 52/100, Loss: 1.0014\n",
      "Epoch 53/100, Loss: 1.0011\n",
      "Epoch 54/100, Loss: 1.0013\n",
      "Epoch 55/100, Loss: 1.0014\n",
      "Epoch 56/100, Loss: 1.0015\n",
      "Epoch 57/100, Loss: 1.0015\n",
      "Epoch 58/100, Loss: 1.0014\n",
      "Epoch 59/100, Loss: 1.0013\n",
      "Epoch 60/100, Loss: 1.0011\n",
      "Epoch 61/100, Loss: 1.0024\n",
      "Epoch 62/100, Loss: 1.0020\n",
      "Epoch 63/100, Loss: 1.0021\n",
      "Epoch 64/100, Loss: 1.0019\n",
      "Epoch 65/100, Loss: 1.0022\n",
      "Epoch 66/100, Loss: 1.0017\n",
      "Epoch 67/100, Loss: 1.0014\n",
      "Epoch 68/100, Loss: 1.0013\n",
      "Epoch 69/100, Loss: 1.0018\n",
      "Epoch 70/100, Loss: 1.0030\n",
      "Epoch 71/100, Loss: 1.0019\n",
      "Epoch 72/100, Loss: 1.0016\n",
      "Epoch 73/100, Loss: 1.0019\n",
      "Epoch 74/100, Loss: 1.0014\n",
      "Epoch 75/100, Loss: 1.0014\n",
      "Epoch 76/100, Loss: 1.0017\n",
      "Epoch 77/100, Loss: 1.0012\n",
      "Epoch 78/100, Loss: 1.0016\n",
      "Epoch 79/100, Loss: 1.0016\n",
      "Epoch 80/100, Loss: 1.0011\n",
      "Epoch 81/100, Loss: 1.0012\n",
      "Epoch 82/100, Loss: 1.0012\n",
      "Epoch 83/100, Loss: 1.0022\n",
      "Epoch 84/100, Loss: 1.0017\n",
      "Epoch 85/100, Loss: 1.0016\n",
      "Epoch 86/100, Loss: 1.0011\n",
      "Epoch 87/100, Loss: 1.0023\n",
      "Epoch 88/100, Loss: 1.0011\n",
      "Epoch 89/100, Loss: 1.0016\n",
      "Epoch 90/100, Loss: 1.0012\n",
      "Epoch 91/100, Loss: 1.0015\n",
      "Epoch 92/100, Loss: 1.0018\n",
      "Epoch 93/100, Loss: 1.0015\n",
      "Epoch 94/100, Loss: 1.0013\n",
      "Epoch 95/100, Loss: 1.0016\n",
      "Epoch 96/100, Loss: 1.0011\n",
      "Epoch 97/100, Loss: 1.0018\n",
      "Epoch 98/100, Loss: 1.0014\n",
      "Epoch 99/100, Loss: 1.0015\n",
      "Epoch 100/100, Loss: 1.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 164.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1151\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0028\n",
      "Epoch 2/100, Loss: 1.0083\n",
      "Epoch 3/100, Loss: 1.0097\n",
      "Epoch 4/100, Loss: 1.0055\n",
      "Epoch 5/100, Loss: 1.0077\n",
      "Epoch 6/100, Loss: 1.0095\n",
      "Epoch 7/100, Loss: 1.0066\n",
      "Epoch 8/100, Loss: 1.0063\n",
      "Epoch 9/100, Loss: 1.0092\n",
      "Epoch 10/100, Loss: 1.0057\n",
      "Epoch 11/100, Loss: 1.0081\n",
      "Epoch 12/100, Loss: 1.0082\n",
      "Epoch 13/100, Loss: 1.0071\n",
      "Epoch 14/100, Loss: 1.0078\n",
      "Epoch 15/100, Loss: 1.0078\n",
      "Epoch 16/100, Loss: 1.0069\n",
      "Epoch 17/100, Loss: 1.0064\n",
      "Epoch 18/100, Loss: 1.0084\n",
      "Epoch 19/100, Loss: 1.0102\n",
      "Epoch 20/100, Loss: 1.0076\n",
      "Epoch 21/100, Loss: 1.0082\n",
      "Epoch 22/100, Loss: 1.0060\n",
      "Epoch 23/100, Loss: 1.0079\n",
      "Epoch 24/100, Loss: 1.0075\n",
      "Epoch 25/100, Loss: 1.0101\n",
      "Epoch 26/100, Loss: 1.0060\n",
      "Epoch 27/100, Loss: 1.0091\n",
      "Epoch 28/100, Loss: 1.0063\n",
      "Epoch 29/100, Loss: 1.0087\n",
      "Epoch 30/100, Loss: 1.0087\n",
      "Epoch 31/100, Loss: 1.0060\n",
      "Epoch 32/100, Loss: 1.0070\n",
      "Epoch 33/100, Loss: 1.0067\n",
      "Epoch 34/100, Loss: 1.0080\n",
      "Epoch 35/100, Loss: 1.0080\n",
      "Epoch 36/100, Loss: 1.0081\n",
      "Epoch 37/100, Loss: 1.0090\n",
      "Epoch 38/100, Loss: 1.0097\n",
      "Epoch 39/100, Loss: 1.0113\n",
      "Epoch 40/100, Loss: 1.0086\n",
      "Epoch 41/100, Loss: 1.0063\n",
      "Epoch 42/100, Loss: 1.0090\n",
      "Epoch 43/100, Loss: 1.0070\n",
      "Epoch 44/100, Loss: 1.0082\n",
      "Epoch 45/100, Loss: 1.0069\n",
      "Epoch 46/100, Loss: 1.0078\n",
      "Epoch 47/100, Loss: 1.0091\n",
      "Epoch 48/100, Loss: 1.0056\n",
      "Epoch 49/100, Loss: 1.0062\n",
      "Epoch 50/100, Loss: 1.0067\n",
      "Epoch 51/100, Loss: 1.0061\n",
      "Epoch 52/100, Loss: 1.0070\n",
      "Epoch 53/100, Loss: 1.0067\n",
      "Epoch 54/100, Loss: 1.0058\n",
      "Epoch 55/100, Loss: 1.0088\n",
      "Epoch 56/100, Loss: 1.0115\n",
      "Epoch 57/100, Loss: 1.0080\n",
      "Epoch 58/100, Loss: 1.0068\n",
      "Epoch 59/100, Loss: 1.0074\n",
      "Epoch 60/100, Loss: 1.0087\n",
      "Epoch 61/100, Loss: 1.0068\n",
      "Epoch 62/100, Loss: 1.0097\n",
      "Epoch 63/100, Loss: 1.0078\n",
      "Epoch 64/100, Loss: 1.0077\n",
      "Epoch 65/100, Loss: 1.0085\n",
      "Epoch 66/100, Loss: 1.0090\n",
      "Epoch 67/100, Loss: 1.0057\n",
      "Epoch 68/100, Loss: 1.0065\n",
      "Epoch 69/100, Loss: 1.0094\n",
      "Epoch 70/100, Loss: 1.0063\n",
      "Epoch 71/100, Loss: 1.0091\n",
      "Epoch 72/100, Loss: 1.0074\n",
      "Epoch 73/100, Loss: 1.0088\n",
      "Epoch 74/100, Loss: 1.0090\n",
      "Epoch 75/100, Loss: 1.0078\n",
      "Epoch 76/100, Loss: 1.0084\n",
      "Epoch 77/100, Loss: 1.0069\n",
      "Epoch 78/100, Loss: 1.0075\n",
      "Epoch 79/100, Loss: 1.0078\n",
      "Epoch 80/100, Loss: 1.0074\n",
      "Epoch 81/100, Loss: 1.0069\n",
      "Epoch 82/100, Loss: 1.0063\n",
      "Epoch 83/100, Loss: 1.0090\n",
      "Epoch 84/100, Loss: 1.0092\n",
      "Epoch 85/100, Loss: 1.0070\n",
      "Epoch 86/100, Loss: 1.0077\n",
      "Epoch 87/100, Loss: 1.0078\n",
      "Epoch 88/100, Loss: 1.0088\n",
      "Epoch 89/100, Loss: 1.0073\n",
      "Epoch 90/100, Loss: 1.0097\n",
      "Epoch 91/100, Loss: 1.0100\n",
      "Epoch 92/100, Loss: 1.0063\n",
      "Epoch 93/100, Loss: 1.0081\n",
      "Epoch 94/100, Loss: 1.0085\n",
      "Epoch 95/100, Loss: 1.0101\n",
      "Epoch 96/100, Loss: 1.0054\n",
      "Epoch 97/100, Loss: 1.0050\n",
      "Epoch 98/100, Loss: 1.0073\n",
      "Epoch 99/100, Loss: 1.0080\n",
      "Epoch 100/100, Loss: 1.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 254.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1134\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 1.0094\n",
      "Epoch 2/100, Loss: 1.0006\n",
      "Epoch 3/100, Loss: 1.0007\n",
      "Epoch 4/100, Loss: 1.0004\n",
      "Epoch 5/100, Loss: 1.0010\n",
      "Epoch 6/100, Loss: 1.0003\n",
      "Epoch 7/100, Loss: 1.0005\n",
      "Epoch 8/100, Loss: 1.0011\n",
      "Epoch 9/100, Loss: 1.0006\n",
      "Epoch 10/100, Loss: 1.0006\n",
      "Epoch 11/100, Loss: 1.0002\n",
      "Epoch 12/100, Loss: 1.0009\n",
      "Epoch 13/100, Loss: 1.0009\n",
      "Epoch 14/100, Loss: 1.0008\n",
      "Epoch 15/100, Loss: 1.0005\n",
      "Epoch 16/100, Loss: 1.0005\n",
      "Epoch 17/100, Loss: 1.0005\n",
      "Epoch 18/100, Loss: 1.0005\n",
      "Epoch 19/100, Loss: 1.0006\n",
      "Epoch 20/100, Loss: 1.0007\n",
      "Epoch 21/100, Loss: 1.0008\n",
      "Epoch 22/100, Loss: 1.0006\n",
      "Epoch 23/100, Loss: 1.0009\n",
      "Epoch 24/100, Loss: 1.0005\n",
      "Epoch 25/100, Loss: 1.0005\n",
      "Epoch 26/100, Loss: 1.0006\n",
      "Epoch 27/100, Loss: 1.0008\n",
      "Epoch 28/100, Loss: 1.0006\n",
      "Epoch 29/100, Loss: 1.0004\n",
      "Epoch 30/100, Loss: 1.0009\n",
      "Epoch 31/100, Loss: 1.0006\n",
      "Epoch 32/100, Loss: 1.0006\n",
      "Epoch 33/100, Loss: 1.0005\n",
      "Epoch 34/100, Loss: 1.0006\n",
      "Epoch 35/100, Loss: 1.0007\n",
      "Epoch 36/100, Loss: 1.0006\n",
      "Epoch 37/100, Loss: 1.0007\n",
      "Epoch 38/100, Loss: 1.0010\n",
      "Epoch 39/100, Loss: 1.0005\n",
      "Epoch 40/100, Loss: 1.0004\n",
      "Epoch 41/100, Loss: 1.0008\n",
      "Epoch 42/100, Loss: 1.0007\n",
      "Epoch 43/100, Loss: 1.0005\n",
      "Epoch 44/100, Loss: 1.0006\n",
      "Epoch 45/100, Loss: 1.0005\n",
      "Epoch 46/100, Loss: 1.0011\n",
      "Epoch 47/100, Loss: 1.0007\n",
      "Epoch 48/100, Loss: 1.0006\n",
      "Epoch 49/100, Loss: 1.0007\n",
      "Epoch 50/100, Loss: 1.0007\n",
      "Epoch 51/100, Loss: 1.0007\n",
      "Epoch 52/100, Loss: 1.0006\n",
      "Epoch 53/100, Loss: 1.0007\n",
      "Epoch 54/100, Loss: 1.0006\n",
      "Epoch 55/100, Loss: 1.0008\n",
      "Epoch 56/100, Loss: 1.0008\n",
      "Epoch 57/100, Loss: 1.0005\n",
      "Epoch 58/100, Loss: 1.0006\n",
      "Epoch 59/100, Loss: 1.0009\n",
      "Epoch 60/100, Loss: 1.0006\n",
      "Epoch 61/100, Loss: 1.0008\n",
      "Epoch 62/100, Loss: 1.0008\n",
      "Epoch 63/100, Loss: 1.0005\n",
      "Epoch 64/100, Loss: 1.0011\n",
      "Epoch 65/100, Loss: 1.0005\n",
      "Epoch 66/100, Loss: 1.0010\n",
      "Epoch 67/100, Loss: 1.0006\n",
      "Epoch 68/100, Loss: 1.0012\n",
      "Epoch 69/100, Loss: 1.0013\n",
      "Epoch 70/100, Loss: 1.0008\n",
      "Epoch 71/100, Loss: 1.0010\n",
      "Epoch 72/100, Loss: 1.0007\n",
      "Epoch 73/100, Loss: 1.0008\n",
      "Epoch 74/100, Loss: 1.0007\n",
      "Epoch 75/100, Loss: 1.0007\n",
      "Epoch 76/100, Loss: 1.0007\n",
      "Epoch 77/100, Loss: 1.0009\n",
      "Epoch 78/100, Loss: 1.0005\n",
      "Epoch 79/100, Loss: 1.0011\n",
      "Epoch 80/100, Loss: 1.0010\n",
      "Epoch 81/100, Loss: 1.0007\n",
      "Epoch 82/100, Loss: 1.0005\n",
      "Epoch 83/100, Loss: 1.0007\n",
      "Epoch 84/100, Loss: 1.0008\n",
      "Epoch 85/100, Loss: 1.0009\n",
      "Epoch 86/100, Loss: 1.0005\n",
      "Epoch 87/100, Loss: 1.0006\n",
      "Epoch 88/100, Loss: 1.0006\n",
      "Epoch 89/100, Loss: 1.0005\n",
      "Epoch 90/100, Loss: 1.0006\n",
      "Epoch 91/100, Loss: 1.0006\n",
      "Epoch 92/100, Loss: 1.0011\n",
      "Epoch 93/100, Loss: 1.0004\n",
      "Epoch 94/100, Loss: 1.0010\n",
      "Epoch 95/100, Loss: 1.0007\n",
      "Epoch 96/100, Loss: 1.0007\n",
      "Epoch 97/100, Loss: 1.0011\n",
      "Epoch 98/100, Loss: 1.0008\n",
      "Epoch 99/100, Loss: 1.0010\n",
      "Epoch 100/100, Loss: 1.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 136.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1133\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0101\n",
      "Epoch 2/100, Loss: 1.0013\n",
      "Epoch 3/100, Loss: 1.0014\n",
      "Epoch 4/100, Loss: 1.0017\n",
      "Epoch 5/100, Loss: 1.0016\n",
      "Epoch 6/100, Loss: 1.0016\n",
      "Epoch 7/100, Loss: 1.0026\n",
      "Epoch 8/100, Loss: 1.0015\n",
      "Epoch 9/100, Loss: 1.0013\n",
      "Epoch 10/100, Loss: 1.0018\n",
      "Epoch 11/100, Loss: 1.0017\n",
      "Epoch 12/100, Loss: 1.0015\n",
      "Epoch 13/100, Loss: 1.0017\n",
      "Epoch 14/100, Loss: 1.0011\n",
      "Epoch 15/100, Loss: 1.0016\n",
      "Epoch 16/100, Loss: 1.0017\n",
      "Epoch 17/100, Loss: 1.0009\n",
      "Epoch 18/100, Loss: 1.0018\n",
      "Epoch 19/100, Loss: 1.0020\n",
      "Epoch 20/100, Loss: 1.0012\n",
      "Epoch 21/100, Loss: 1.0015\n",
      "Epoch 22/100, Loss: 1.0021\n",
      "Epoch 23/100, Loss: 1.0008\n",
      "Epoch 24/100, Loss: 1.0020\n",
      "Epoch 25/100, Loss: 1.0014\n",
      "Epoch 26/100, Loss: 1.0013\n",
      "Epoch 27/100, Loss: 1.0013\n",
      "Epoch 28/100, Loss: 1.0012\n",
      "Epoch 29/100, Loss: 1.0021\n",
      "Epoch 30/100, Loss: 1.0018\n",
      "Epoch 31/100, Loss: 1.0016\n",
      "Epoch 32/100, Loss: 1.0015\n",
      "Epoch 33/100, Loss: 1.0019\n",
      "Epoch 34/100, Loss: 1.0019\n",
      "Epoch 35/100, Loss: 1.0015\n",
      "Epoch 36/100, Loss: 1.0015\n",
      "Epoch 37/100, Loss: 1.0017\n",
      "Epoch 38/100, Loss: 1.0015\n",
      "Epoch 39/100, Loss: 1.0014\n",
      "Epoch 40/100, Loss: 1.0012\n",
      "Epoch 41/100, Loss: 1.0015\n",
      "Epoch 42/100, Loss: 1.0022\n",
      "Epoch 43/100, Loss: 1.0015\n",
      "Epoch 44/100, Loss: 1.0010\n",
      "Epoch 45/100, Loss: 1.0016\n",
      "Epoch 46/100, Loss: 1.0018\n",
      "Epoch 47/100, Loss: 1.0016\n",
      "Epoch 48/100, Loss: 1.0018\n",
      "Epoch 49/100, Loss: 1.0019\n",
      "Epoch 50/100, Loss: 1.0011\n",
      "Epoch 51/100, Loss: 1.0015\n",
      "Epoch 52/100, Loss: 1.0014\n",
      "Epoch 53/100, Loss: 1.0014\n",
      "Epoch 54/100, Loss: 1.0015\n",
      "Epoch 55/100, Loss: 1.0015\n",
      "Epoch 56/100, Loss: 1.0013\n",
      "Epoch 57/100, Loss: 1.0016\n",
      "Epoch 58/100, Loss: 1.0016\n",
      "Epoch 59/100, Loss: 1.0014\n",
      "Epoch 60/100, Loss: 1.0015\n",
      "Epoch 61/100, Loss: 1.0014\n",
      "Epoch 62/100, Loss: 1.0013\n",
      "Epoch 63/100, Loss: 1.0019\n",
      "Epoch 64/100, Loss: 1.0009\n",
      "Epoch 65/100, Loss: 1.0018\n",
      "Epoch 66/100, Loss: 1.0016\n",
      "Epoch 67/100, Loss: 1.0009\n",
      "Epoch 68/100, Loss: 1.0020\n",
      "Epoch 69/100, Loss: 1.0015\n",
      "Epoch 70/100, Loss: 1.0021\n",
      "Epoch 71/100, Loss: 1.0011\n",
      "Epoch 72/100, Loss: 1.0013\n",
      "Epoch 73/100, Loss: 1.0014\n",
      "Epoch 74/100, Loss: 1.0013\n",
      "Epoch 75/100, Loss: 1.0011\n",
      "Epoch 76/100, Loss: 1.0017\n",
      "Epoch 77/100, Loss: 1.0011\n",
      "Epoch 78/100, Loss: 1.0019\n",
      "Epoch 79/100, Loss: 1.0012\n",
      "Epoch 80/100, Loss: 1.0014\n",
      "Epoch 81/100, Loss: 1.0013\n",
      "Epoch 82/100, Loss: 1.0017\n",
      "Epoch 83/100, Loss: 1.0015\n",
      "Epoch 84/100, Loss: 1.0017\n",
      "Epoch 85/100, Loss: 1.0009\n",
      "Epoch 86/100, Loss: 1.0021\n",
      "Epoch 87/100, Loss: 1.0008\n",
      "Epoch 88/100, Loss: 1.0016\n",
      "Epoch 89/100, Loss: 1.0013\n",
      "Epoch 90/100, Loss: 1.0016\n",
      "Epoch 91/100, Loss: 1.0011\n",
      "Epoch 92/100, Loss: 1.0015\n",
      "Epoch 93/100, Loss: 1.0016\n",
      "Epoch 94/100, Loss: 1.0017\n",
      "Epoch 95/100, Loss: 1.0016\n",
      "Epoch 96/100, Loss: 1.0015\n",
      "Epoch 97/100, Loss: 1.0018\n",
      "Epoch 98/100, Loss: 1.0013\n",
      "Epoch 99/100, Loss: 1.0012\n",
      "Epoch 100/100, Loss: 1.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 157.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1207\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0138\n",
      "Epoch 2/100, Loss: 1.0070\n",
      "Epoch 3/100, Loss: 1.0071\n",
      "Epoch 4/100, Loss: 1.0071\n",
      "Epoch 5/100, Loss: 1.0116\n",
      "Epoch 6/100, Loss: 1.0086\n",
      "Epoch 7/100, Loss: 1.0071\n",
      "Epoch 8/100, Loss: 1.0063\n",
      "Epoch 9/100, Loss: 1.0098\n",
      "Epoch 10/100, Loss: 1.0074\n",
      "Epoch 11/100, Loss: 1.0076\n",
      "Epoch 12/100, Loss: 1.0086\n",
      "Epoch 13/100, Loss: 1.0095\n",
      "Epoch 14/100, Loss: 1.0108\n",
      "Epoch 15/100, Loss: 1.0056\n",
      "Epoch 16/100, Loss: 1.0095\n",
      "Epoch 17/100, Loss: 1.0086\n",
      "Epoch 18/100, Loss: 1.0066\n",
      "Epoch 19/100, Loss: 1.0074\n",
      "Epoch 20/100, Loss: 1.0069\n",
      "Epoch 21/100, Loss: 1.0096\n",
      "Epoch 22/100, Loss: 1.0076\n",
      "Epoch 23/100, Loss: 1.0074\n",
      "Epoch 24/100, Loss: 1.0069\n",
      "Epoch 25/100, Loss: 1.0078\n",
      "Epoch 26/100, Loss: 1.0099\n",
      "Epoch 27/100, Loss: 1.0058\n",
      "Epoch 28/100, Loss: 1.0098\n",
      "Epoch 29/100, Loss: 1.0068\n",
      "Epoch 30/100, Loss: 1.0076\n",
      "Epoch 31/100, Loss: 1.0093\n",
      "Epoch 32/100, Loss: 1.0072\n",
      "Epoch 33/100, Loss: 1.0075\n",
      "Epoch 34/100, Loss: 1.0084\n",
      "Epoch 35/100, Loss: 1.0086\n",
      "Epoch 36/100, Loss: 1.0074\n",
      "Epoch 37/100, Loss: 1.0076\n",
      "Epoch 38/100, Loss: 1.0089\n",
      "Epoch 39/100, Loss: 1.0088\n",
      "Epoch 40/100, Loss: 1.0094\n",
      "Epoch 41/100, Loss: 1.0068\n",
      "Epoch 42/100, Loss: 1.0086\n",
      "Epoch 43/100, Loss: 1.0061\n",
      "Epoch 44/100, Loss: 1.0100\n",
      "Epoch 45/100, Loss: 1.0094\n",
      "Epoch 46/100, Loss: 1.0083\n",
      "Epoch 47/100, Loss: 1.0058\n",
      "Epoch 48/100, Loss: 1.0066\n",
      "Epoch 49/100, Loss: 1.0086\n",
      "Epoch 50/100, Loss: 1.0076\n",
      "Epoch 51/100, Loss: 1.0078\n",
      "Epoch 52/100, Loss: 1.0066\n",
      "Epoch 53/100, Loss: 1.0082\n",
      "Epoch 54/100, Loss: 1.0090\n",
      "Epoch 55/100, Loss: 1.0080\n",
      "Epoch 56/100, Loss: 1.0083\n",
      "Epoch 57/100, Loss: 1.0053\n",
      "Epoch 58/100, Loss: 1.0073\n",
      "Epoch 59/100, Loss: 1.0060\n",
      "Epoch 60/100, Loss: 1.0074\n",
      "Epoch 61/100, Loss: 1.0082\n",
      "Epoch 62/100, Loss: 1.0075\n",
      "Epoch 63/100, Loss: 1.0064\n",
      "Epoch 64/100, Loss: 1.0091\n",
      "Epoch 65/100, Loss: 1.0077\n",
      "Epoch 66/100, Loss: 1.0071\n",
      "Epoch 67/100, Loss: 1.0096\n",
      "Epoch 68/100, Loss: 1.0067\n",
      "Epoch 69/100, Loss: 1.0075\n",
      "Epoch 70/100, Loss: 1.0058\n",
      "Epoch 71/100, Loss: 1.0091\n",
      "Epoch 72/100, Loss: 1.0090\n",
      "Epoch 73/100, Loss: 1.0073\n",
      "Epoch 74/100, Loss: 1.0097\n",
      "Epoch 75/100, Loss: 1.0088\n",
      "Epoch 76/100, Loss: 1.0073\n",
      "Epoch 77/100, Loss: 1.0067\n",
      "Epoch 78/100, Loss: 1.0075\n",
      "Epoch 79/100, Loss: 1.0086\n",
      "Epoch 80/100, Loss: 1.0086\n",
      "Epoch 81/100, Loss: 1.0069\n",
      "Epoch 82/100, Loss: 1.0091\n",
      "Epoch 83/100, Loss: 1.0088\n",
      "Epoch 84/100, Loss: 1.0095\n",
      "Epoch 85/100, Loss: 1.0080\n",
      "Epoch 86/100, Loss: 1.0083\n",
      "Epoch 87/100, Loss: 1.0073\n",
      "Epoch 88/100, Loss: 1.0075\n",
      "Epoch 89/100, Loss: 1.0066\n",
      "Epoch 90/100, Loss: 1.0065\n",
      "Epoch 91/100, Loss: 1.0070\n",
      "Epoch 92/100, Loss: 1.0093\n",
      "Epoch 93/100, Loss: 1.0095\n",
      "Epoch 94/100, Loss: 1.0093\n",
      "Epoch 95/100, Loss: 1.0093\n",
      "Epoch 96/100, Loss: 1.0067\n",
      "Epoch 97/100, Loss: 1.0072\n",
      "Epoch 98/100, Loss: 1.0049\n",
      "Epoch 99/100, Loss: 1.0103\n",
      "Epoch 100/100, Loss: 1.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 146.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1181\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.7482\n",
      "Epoch 2/100, Loss: 0.6341\n",
      "Epoch 3/100, Loss: 0.5974\n",
      "Epoch 4/100, Loss: 0.5395\n",
      "Epoch 5/100, Loss: 0.5602\n",
      "Epoch 6/100, Loss: 0.5531\n",
      "Epoch 7/100, Loss: 0.5474\n",
      "Epoch 8/100, Loss: 0.5244\n",
      "Epoch 9/100, Loss: 0.5130\n",
      "Epoch 10/100, Loss: 0.5203\n",
      "Epoch 11/100, Loss: 0.4839\n",
      "Epoch 12/100, Loss: 0.5103\n",
      "Epoch 13/100, Loss: 0.5009\n",
      "Epoch 14/100, Loss: 0.5627\n",
      "Epoch 15/100, Loss: 0.5416\n",
      "Epoch 16/100, Loss: 0.5184\n",
      "Epoch 17/100, Loss: 0.5229\n",
      "Epoch 18/100, Loss: 0.5881\n",
      "Epoch 19/100, Loss: 0.5110\n",
      "Epoch 20/100, Loss: 0.5530\n",
      "Epoch 21/100, Loss: 0.5652\n",
      "Epoch 22/100, Loss: 0.4628\n",
      "Epoch 23/100, Loss: 0.4208\n",
      "Epoch 24/100, Loss: 0.4297\n",
      "Epoch 25/100, Loss: 0.4179\n",
      "Epoch 26/100, Loss: 0.4565\n",
      "Epoch 27/100, Loss: 0.4794\n",
      "Epoch 28/100, Loss: 0.4500\n",
      "Epoch 29/100, Loss: 0.4157\n",
      "Epoch 30/100, Loss: 0.4742\n",
      "Epoch 31/100, Loss: 0.4759\n",
      "Epoch 32/100, Loss: 0.4674\n",
      "Epoch 33/100, Loss: 0.4598\n",
      "Epoch 34/100, Loss: 0.4061\n",
      "Epoch 35/100, Loss: 0.4191\n",
      "Epoch 36/100, Loss: 0.4064\n",
      "Epoch 37/100, Loss: 0.4704\n",
      "Epoch 38/100, Loss: 0.4362\n",
      "Epoch 39/100, Loss: 0.4140\n",
      "Epoch 40/100, Loss: 0.4418\n",
      "Epoch 41/100, Loss: 0.4108\n",
      "Epoch 42/100, Loss: 0.3863\n",
      "Epoch 43/100, Loss: 0.4087\n",
      "Epoch 44/100, Loss: 0.4045\n",
      "Epoch 45/100, Loss: 0.4727\n",
      "Epoch 46/100, Loss: 0.4274\n",
      "Epoch 47/100, Loss: 0.3900\n",
      "Epoch 48/100, Loss: 0.4230\n",
      "Epoch 49/100, Loss: 0.4074\n",
      "Epoch 50/100, Loss: 0.4187\n",
      "Epoch 51/100, Loss: 0.4715\n",
      "Epoch 52/100, Loss: 0.4034\n",
      "Epoch 53/100, Loss: 0.4199\n",
      "Epoch 54/100, Loss: 0.4699\n",
      "Epoch 55/100, Loss: 0.4017\n",
      "Epoch 56/100, Loss: 0.4331\n",
      "Epoch 57/100, Loss: 0.4491\n",
      "Epoch 58/100, Loss: 0.4282\n",
      "Epoch 59/100, Loss: 0.4242\n",
      "Epoch 60/100, Loss: 0.4178\n",
      "Epoch 61/100, Loss: 0.4011\n",
      "Epoch 62/100, Loss: 0.4114\n",
      "Epoch 63/100, Loss: 0.4253\n",
      "Epoch 64/100, Loss: 0.3895\n",
      "Epoch 65/100, Loss: 0.3812\n",
      "Epoch 66/100, Loss: 0.5365\n",
      "Epoch 67/100, Loss: 0.3994\n",
      "Epoch 68/100, Loss: 0.3823\n",
      "Epoch 69/100, Loss: 0.3911\n",
      "Epoch 70/100, Loss: 0.3809\n",
      "Epoch 71/100, Loss: 0.3729\n",
      "Epoch 72/100, Loss: 0.3654\n",
      "Epoch 73/100, Loss: 0.3658\n",
      "Epoch 74/100, Loss: 0.4003\n",
      "Epoch 75/100, Loss: 0.4316\n",
      "Epoch 76/100, Loss: 0.5701\n",
      "Epoch 77/100, Loss: 0.4969\n",
      "Epoch 78/100, Loss: 0.4617\n",
      "Epoch 79/100, Loss: 0.4461\n",
      "Epoch 80/100, Loss: 0.4175\n",
      "Epoch 81/100, Loss: 0.4160\n",
      "Epoch 82/100, Loss: 0.3951\n",
      "Epoch 83/100, Loss: 0.4167\n",
      "Epoch 84/100, Loss: 0.3879\n",
      "Epoch 85/100, Loss: 0.3935\n",
      "Epoch 86/100, Loss: 0.4221\n",
      "Epoch 87/100, Loss: 0.4457\n",
      "Epoch 88/100, Loss: 0.4479\n",
      "Epoch 89/100, Loss: 0.4150\n",
      "Epoch 90/100, Loss: 0.5044\n",
      "Epoch 91/100, Loss: 0.4783\n",
      "Epoch 92/100, Loss: 0.5203\n",
      "Epoch 93/100, Loss: 0.4863\n",
      "Epoch 94/100, Loss: 0.4467\n",
      "Epoch 95/100, Loss: 0.4660\n",
      "Epoch 96/100, Loss: 0.4705\n",
      "Epoch 97/100, Loss: 0.4668\n",
      "Epoch 98/100, Loss: 0.4349\n",
      "Epoch 99/100, Loss: 0.4861\n",
      "Epoch 100/100, Loss: 0.4581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 247.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3443\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.6, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0040\n",
      "Epoch 2/100, Loss: 1.0013\n",
      "Epoch 3/100, Loss: 1.0018\n",
      "Epoch 4/100, Loss: 1.0019\n",
      "Epoch 5/100, Loss: 1.0010\n",
      "Epoch 6/100, Loss: 1.0018\n",
      "Epoch 7/100, Loss: 1.0009\n",
      "Epoch 8/100, Loss: 1.0020\n",
      "Epoch 9/100, Loss: 1.0016\n",
      "Epoch 10/100, Loss: 1.0012\n",
      "Epoch 11/100, Loss: 1.0021\n",
      "Epoch 12/100, Loss: 1.0013\n",
      "Epoch 13/100, Loss: 1.0019\n",
      "Epoch 14/100, Loss: 1.0011\n",
      "Epoch 15/100, Loss: 1.0012\n",
      "Epoch 16/100, Loss: 1.0022\n",
      "Epoch 17/100, Loss: 1.0023\n",
      "Epoch 18/100, Loss: 1.0012\n",
      "Epoch 19/100, Loss: 1.0010\n",
      "Epoch 20/100, Loss: 1.0017\n",
      "Epoch 21/100, Loss: 1.0021\n",
      "Epoch 22/100, Loss: 1.0018\n",
      "Epoch 23/100, Loss: 1.0018\n",
      "Epoch 24/100, Loss: 1.0015\n",
      "Epoch 25/100, Loss: 1.0014\n",
      "Epoch 26/100, Loss: 1.0007\n",
      "Epoch 27/100, Loss: 1.0013\n",
      "Epoch 28/100, Loss: 1.0017\n",
      "Epoch 29/100, Loss: 1.0015\n",
      "Epoch 30/100, Loss: 1.0012\n",
      "Epoch 31/100, Loss: 1.0025\n",
      "Epoch 32/100, Loss: 1.0009\n",
      "Epoch 33/100, Loss: 1.0016\n",
      "Epoch 34/100, Loss: 1.0015\n",
      "Epoch 35/100, Loss: 1.0018\n",
      "Epoch 36/100, Loss: 1.0015\n",
      "Epoch 37/100, Loss: 1.0017\n",
      "Epoch 38/100, Loss: 1.0013\n",
      "Epoch 39/100, Loss: 1.0017\n",
      "Epoch 40/100, Loss: 1.0016\n",
      "Epoch 41/100, Loss: 1.0019\n",
      "Epoch 42/100, Loss: 1.0017\n",
      "Epoch 43/100, Loss: 1.0017\n",
      "Epoch 44/100, Loss: 1.0010\n",
      "Epoch 45/100, Loss: 1.0016\n",
      "Epoch 46/100, Loss: 1.0012\n",
      "Epoch 47/100, Loss: 1.0018\n",
      "Epoch 48/100, Loss: 1.0013\n",
      "Epoch 49/100, Loss: 1.0012\n",
      "Epoch 50/100, Loss: 1.0018\n",
      "Epoch 51/100, Loss: 1.0013\n",
      "Epoch 52/100, Loss: 1.0015\n",
      "Epoch 53/100, Loss: 1.0020\n",
      "Epoch 54/100, Loss: 1.0009\n",
      "Epoch 55/100, Loss: 1.0015\n",
      "Epoch 56/100, Loss: 1.0018\n",
      "Epoch 57/100, Loss: 1.0019\n",
      "Epoch 58/100, Loss: 1.0016\n",
      "Epoch 59/100, Loss: 1.0017\n",
      "Epoch 60/100, Loss: 1.0017\n",
      "Epoch 61/100, Loss: 1.0009\n",
      "Epoch 62/100, Loss: 1.0019\n",
      "Epoch 63/100, Loss: 1.0021\n",
      "Epoch 64/100, Loss: 1.0014\n",
      "Epoch 65/100, Loss: 1.0015\n",
      "Epoch 66/100, Loss: 1.0014\n",
      "Epoch 67/100, Loss: 1.0017\n",
      "Epoch 68/100, Loss: 1.0023\n",
      "Epoch 69/100, Loss: 1.0007\n",
      "Epoch 70/100, Loss: 1.0015\n",
      "Epoch 71/100, Loss: 1.0014\n",
      "Epoch 72/100, Loss: 1.0018\n",
      "Epoch 73/100, Loss: 1.0018\n",
      "Epoch 74/100, Loss: 1.0015\n",
      "Epoch 75/100, Loss: 1.0009\n",
      "Epoch 76/100, Loss: 1.0017\n",
      "Epoch 77/100, Loss: 1.0009\n",
      "Epoch 78/100, Loss: 1.0012\n",
      "Epoch 79/100, Loss: 1.0020\n",
      "Epoch 80/100, Loss: 1.0013\n",
      "Epoch 81/100, Loss: 1.0017\n",
      "Epoch 82/100, Loss: 1.0013\n",
      "Epoch 83/100, Loss: 1.0014\n",
      "Epoch 84/100, Loss: 1.0020\n",
      "Epoch 85/100, Loss: 1.0019\n",
      "Epoch 86/100, Loss: 1.0019\n",
      "Epoch 87/100, Loss: 1.0011\n",
      "Epoch 88/100, Loss: 1.0008\n",
      "Epoch 89/100, Loss: 1.0017\n",
      "Epoch 90/100, Loss: 1.0011\n",
      "Epoch 91/100, Loss: 1.0015\n",
      "Epoch 92/100, Loss: 1.0020\n",
      "Epoch 93/100, Loss: 1.0018\n",
      "Epoch 94/100, Loss: 1.0013\n",
      "Epoch 95/100, Loss: 1.0014\n",
      "Epoch 96/100, Loss: 1.0012\n",
      "Epoch 97/100, Loss: 1.0023\n",
      "Epoch 98/100, Loss: 1.0016\n",
      "Epoch 99/100, Loss: 1.0013\n",
      "Epoch 100/100, Loss: 1.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 185.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1102\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.6, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0109\n",
      "Epoch 2/100, Loss: 1.0064\n",
      "Epoch 3/100, Loss: 1.0078\n",
      "Epoch 4/100, Loss: 1.0084\n",
      "Epoch 5/100, Loss: 1.0091\n",
      "Epoch 6/100, Loss: 1.0058\n",
      "Epoch 7/100, Loss: 1.0058\n",
      "Epoch 8/100, Loss: 1.0078\n",
      "Epoch 9/100, Loss: 1.0085\n",
      "Epoch 10/100, Loss: 1.0072\n",
      "Epoch 11/100, Loss: 1.0097\n",
      "Epoch 12/100, Loss: 1.0071\n",
      "Epoch 13/100, Loss: 1.0080\n",
      "Epoch 14/100, Loss: 1.0072\n",
      "Epoch 15/100, Loss: 1.0069\n",
      "Epoch 16/100, Loss: 1.0082\n",
      "Epoch 17/100, Loss: 1.0053\n",
      "Epoch 18/100, Loss: 1.0078\n",
      "Epoch 19/100, Loss: 1.0081\n",
      "Epoch 20/100, Loss: 1.0083\n",
      "Epoch 21/100, Loss: 1.0075\n",
      "Epoch 22/100, Loss: 1.0095\n",
      "Epoch 23/100, Loss: 1.0076\n",
      "Epoch 24/100, Loss: 1.0083\n",
      "Epoch 25/100, Loss: 1.0070\n",
      "Epoch 26/100, Loss: 1.0079\n",
      "Epoch 27/100, Loss: 1.0075\n",
      "Epoch 28/100, Loss: 1.0060\n",
      "Epoch 29/100, Loss: 1.0076\n",
      "Epoch 30/100, Loss: 1.0077\n",
      "Epoch 31/100, Loss: 1.0063\n",
      "Epoch 32/100, Loss: 1.0065\n",
      "Epoch 33/100, Loss: 1.0069\n",
      "Epoch 34/100, Loss: 1.0096\n",
      "Epoch 35/100, Loss: 1.0100\n",
      "Epoch 36/100, Loss: 1.0085\n",
      "Epoch 37/100, Loss: 1.0080\n",
      "Epoch 38/100, Loss: 1.0042\n",
      "Epoch 39/100, Loss: 1.0097\n",
      "Epoch 40/100, Loss: 1.0101\n",
      "Epoch 41/100, Loss: 1.0098\n",
      "Epoch 42/100, Loss: 1.0085\n",
      "Epoch 43/100, Loss: 1.0082\n",
      "Epoch 44/100, Loss: 1.0109\n",
      "Epoch 45/100, Loss: 1.0099\n",
      "Epoch 46/100, Loss: 1.0080\n",
      "Epoch 47/100, Loss: 1.0082\n",
      "Epoch 48/100, Loss: 1.0072\n",
      "Epoch 49/100, Loss: 1.0066\n",
      "Epoch 50/100, Loss: 1.0072\n",
      "Epoch 51/100, Loss: 1.0094\n",
      "Epoch 52/100, Loss: 1.0069\n",
      "Epoch 53/100, Loss: 1.0074\n",
      "Epoch 54/100, Loss: 1.0083\n",
      "Epoch 55/100, Loss: 1.0076\n",
      "Epoch 56/100, Loss: 1.0076\n",
      "Epoch 57/100, Loss: 1.0064\n",
      "Epoch 58/100, Loss: 1.0094\n",
      "Epoch 59/100, Loss: 1.0062\n",
      "Epoch 60/100, Loss: 1.0072\n",
      "Epoch 61/100, Loss: 1.0068\n",
      "Epoch 62/100, Loss: 1.0084\n",
      "Epoch 63/100, Loss: 1.0073\n",
      "Epoch 64/100, Loss: 1.0055\n",
      "Epoch 65/100, Loss: 1.0063\n",
      "Epoch 66/100, Loss: 1.0064\n",
      "Epoch 67/100, Loss: 1.0086\n",
      "Epoch 68/100, Loss: 1.0083\n",
      "Epoch 69/100, Loss: 1.0077\n",
      "Epoch 70/100, Loss: 1.0085\n",
      "Epoch 71/100, Loss: 1.0075\n",
      "Epoch 72/100, Loss: 1.0056\n",
      "Epoch 73/100, Loss: 1.0077\n",
      "Epoch 74/100, Loss: 1.0081\n",
      "Epoch 75/100, Loss: 1.0079\n",
      "Epoch 76/100, Loss: 1.0091\n",
      "Epoch 77/100, Loss: 1.0069\n",
      "Epoch 78/100, Loss: 1.0087\n",
      "Epoch 79/100, Loss: 1.0089\n",
      "Epoch 80/100, Loss: 1.0074\n",
      "Epoch 81/100, Loss: 1.0055\n",
      "Epoch 82/100, Loss: 1.0080\n",
      "Epoch 83/100, Loss: 1.0051\n",
      "Epoch 84/100, Loss: 1.0109\n",
      "Epoch 85/100, Loss: 1.0079\n",
      "Epoch 86/100, Loss: 1.0058\n",
      "Epoch 87/100, Loss: 1.0080\n",
      "Epoch 88/100, Loss: 1.0071\n",
      "Epoch 89/100, Loss: 1.0106\n",
      "Epoch 90/100, Loss: 1.0055\n",
      "Epoch 91/100, Loss: 1.0051\n",
      "Epoch 92/100, Loss: 1.0091\n",
      "Epoch 93/100, Loss: 1.0075\n",
      "Epoch 94/100, Loss: 1.0085\n",
      "Epoch 95/100, Loss: 1.0069\n",
      "Epoch 96/100, Loss: 1.0087\n",
      "Epoch 97/100, Loss: 1.0078\n",
      "Epoch 98/100, Loss: 1.0057\n",
      "Epoch 99/100, Loss: 1.0062\n",
      "Epoch 100/100, Loss: 1.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 158.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1152\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.8, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.5746\n",
      "Epoch 2/100, Loss: 0.4346\n",
      "Epoch 3/100, Loss: 0.4156\n",
      "Epoch 4/100, Loss: 0.4017\n",
      "Epoch 5/100, Loss: 0.4043\n",
      "Epoch 6/100, Loss: 0.4270\n",
      "Epoch 7/100, Loss: 0.3772\n",
      "Epoch 8/100, Loss: 0.3064\n",
      "Epoch 9/100, Loss: 0.2665\n",
      "Epoch 10/100, Loss: 0.2729\n",
      "Epoch 11/100, Loss: 0.2686\n",
      "Epoch 12/100, Loss: 0.2558\n",
      "Epoch 13/100, Loss: 0.2320\n",
      "Epoch 14/100, Loss: 0.1918\n",
      "Epoch 15/100, Loss: 0.1891\n",
      "Epoch 16/100, Loss: 0.1791\n",
      "Epoch 17/100, Loss: 0.1967\n",
      "Epoch 18/100, Loss: 0.1547\n",
      "Epoch 19/100, Loss: 0.1725\n",
      "Epoch 20/100, Loss: 0.1519\n",
      "Epoch 21/100, Loss: 0.1521\n",
      "Epoch 22/100, Loss: 0.1497\n",
      "Epoch 23/100, Loss: 0.1574\n",
      "Epoch 24/100, Loss: 0.1462\n",
      "Epoch 25/100, Loss: 0.1582\n",
      "Epoch 26/100, Loss: 0.1500\n",
      "Epoch 27/100, Loss: 0.1856\n",
      "Epoch 28/100, Loss: 0.1505\n",
      "Epoch 29/100, Loss: 0.1766\n",
      "Epoch 30/100, Loss: 0.1447\n",
      "Epoch 31/100, Loss: 0.2080\n",
      "Epoch 32/100, Loss: 0.1191\n",
      "Epoch 33/100, Loss: 0.1149\n",
      "Epoch 34/100, Loss: 0.1257\n",
      "Epoch 35/100, Loss: 0.2169\n",
      "Epoch 36/100, Loss: 0.1563\n",
      "Epoch 37/100, Loss: 0.1615\n",
      "Epoch 38/100, Loss: 0.0331\n",
      "Epoch 39/100, Loss: -0.0033\n",
      "Epoch 40/100, Loss: -0.0074\n",
      "Epoch 41/100, Loss: -0.0058\n",
      "Epoch 42/100, Loss: 0.0316\n",
      "Epoch 43/100, Loss: 0.0761\n",
      "Epoch 44/100, Loss: 0.0402\n",
      "Epoch 45/100, Loss: 0.0021\n",
      "Epoch 46/100, Loss: 0.0473\n",
      "Epoch 47/100, Loss: 0.0971\n",
      "Epoch 48/100, Loss: 0.0316\n",
      "Epoch 49/100, Loss: 0.0035\n",
      "Epoch 50/100, Loss: 0.0181\n",
      "Epoch 51/100, Loss: 0.0142\n",
      "Epoch 52/100, Loss: 0.0376\n",
      "Epoch 53/100, Loss: 0.0524\n",
      "Epoch 54/100, Loss: 0.0636\n",
      "Epoch 55/100, Loss: 0.0085\n",
      "Epoch 56/100, Loss: 0.0508\n",
      "Epoch 57/100, Loss: 0.0781\n",
      "Epoch 58/100, Loss: 0.0728\n",
      "Epoch 59/100, Loss: 0.0486\n",
      "Epoch 60/100, Loss: 0.0369\n",
      "Epoch 61/100, Loss: 0.0040\n",
      "Epoch 62/100, Loss: 0.0008\n",
      "Epoch 63/100, Loss: -0.0017\n",
      "Epoch 64/100, Loss: 0.0220\n",
      "Epoch 65/100, Loss: 0.0054\n",
      "Epoch 66/100, Loss: -0.0243\n",
      "Epoch 67/100, Loss: -0.0097\n",
      "Epoch 68/100, Loss: 0.0011\n",
      "Epoch 69/100, Loss: 0.0065\n",
      "Epoch 70/100, Loss: -0.0127\n",
      "Epoch 71/100, Loss: 0.0173\n",
      "Epoch 72/100, Loss: 0.0071\n",
      "Epoch 73/100, Loss: -0.0185\n",
      "Epoch 74/100, Loss: 0.0272\n",
      "Epoch 75/100, Loss: 0.0139\n",
      "Epoch 76/100, Loss: 0.0040\n",
      "Epoch 77/100, Loss: -0.0019\n",
      "Epoch 78/100, Loss: -0.0021\n",
      "Epoch 79/100, Loss: 0.0201\n",
      "Epoch 80/100, Loss: -0.0118\n",
      "Epoch 81/100, Loss: 0.0259\n",
      "Epoch 82/100, Loss: 0.0354\n",
      "Epoch 83/100, Loss: 0.0079\n",
      "Epoch 84/100, Loss: 0.0179\n",
      "Epoch 85/100, Loss: 0.0064\n",
      "Epoch 86/100, Loss: -0.0112\n",
      "Epoch 87/100, Loss: -0.0295\n",
      "Epoch 88/100, Loss: -0.0352\n",
      "Epoch 89/100, Loss: -0.0104\n",
      "Epoch 90/100, Loss: -0.0234\n",
      "Epoch 91/100, Loss: -0.0330\n",
      "Epoch 92/100, Loss: -0.0352\n",
      "Epoch 93/100, Loss: -0.0203\n",
      "Epoch 94/100, Loss: 0.0249\n",
      "Epoch 95/100, Loss: 0.0258\n",
      "Epoch 96/100, Loss: -0.0479\n",
      "Epoch 97/100, Loss: -0.0143\n",
      "Epoch 98/100, Loss: -0.0752\n",
      "Epoch 99/100, Loss: -0.0520\n",
      "Epoch 100/100, Loss: -0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 186.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3551\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.8, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.8198\n",
      "Epoch 2/100, Loss: 0.7131\n",
      "Epoch 3/100, Loss: 0.5881\n",
      "Epoch 4/100, Loss: 0.5753\n",
      "Epoch 5/100, Loss: 0.6083\n",
      "Epoch 6/100, Loss: 0.5728\n",
      "Epoch 7/100, Loss: 0.5514\n",
      "Epoch 8/100, Loss: 0.5382\n",
      "Epoch 9/100, Loss: 0.5723\n",
      "Epoch 10/100, Loss: 0.6355\n",
      "Epoch 11/100, Loss: 0.5442\n",
      "Epoch 12/100, Loss: 0.5509\n",
      "Epoch 13/100, Loss: 0.5638\n",
      "Epoch 14/100, Loss: 0.5533\n",
      "Epoch 15/100, Loss: 0.5848\n",
      "Epoch 16/100, Loss: 0.5813\n",
      "Epoch 17/100, Loss: 0.5512\n",
      "Epoch 18/100, Loss: 0.5685\n",
      "Epoch 19/100, Loss: 0.6188\n",
      "Epoch 20/100, Loss: 0.5203\n",
      "Epoch 21/100, Loss: 0.5622\n",
      "Epoch 22/100, Loss: 0.5569\n",
      "Epoch 23/100, Loss: 0.5492\n",
      "Epoch 24/100, Loss: 0.5700\n",
      "Epoch 25/100, Loss: 0.5438\n",
      "Epoch 26/100, Loss: 0.6755\n",
      "Epoch 27/100, Loss: 0.7644\n",
      "Epoch 28/100, Loss: 0.6901\n",
      "Epoch 29/100, Loss: 0.6280\n",
      "Epoch 30/100, Loss: 0.5382\n",
      "Epoch 31/100, Loss: 0.6437\n",
      "Epoch 32/100, Loss: 0.6570\n",
      "Epoch 33/100, Loss: 0.5931\n",
      "Epoch 34/100, Loss: 0.5514\n",
      "Epoch 35/100, Loss: 0.5268\n",
      "Epoch 36/100, Loss: 0.6074\n",
      "Epoch 37/100, Loss: 0.6795\n",
      "Epoch 38/100, Loss: 0.6753\n",
      "Epoch 39/100, Loss: 0.6915\n",
      "Epoch 40/100, Loss: 0.6869\n",
      "Epoch 41/100, Loss: 0.6771\n",
      "Epoch 42/100, Loss: 0.6509\n",
      "Epoch 43/100, Loss: 0.6569\n",
      "Epoch 44/100, Loss: 0.5626\n",
      "Epoch 45/100, Loss: 0.5597\n",
      "Epoch 46/100, Loss: 0.5409\n",
      "Epoch 47/100, Loss: 0.5307\n",
      "Epoch 48/100, Loss: 0.5295\n",
      "Epoch 49/100, Loss: 0.5299\n",
      "Epoch 50/100, Loss: 0.5286\n",
      "Epoch 51/100, Loss: 0.5293\n",
      "Epoch 52/100, Loss: 0.5325\n",
      "Epoch 53/100, Loss: 0.5287\n",
      "Epoch 54/100, Loss: 0.5299\n",
      "Epoch 55/100, Loss: 0.5343\n",
      "Epoch 56/100, Loss: 0.5284\n",
      "Epoch 57/100, Loss: 0.5304\n",
      "Epoch 58/100, Loss: 0.5315\n",
      "Epoch 59/100, Loss: 0.5318\n",
      "Epoch 60/100, Loss: 0.5300\n",
      "Epoch 61/100, Loss: 0.5313\n",
      "Epoch 62/100, Loss: 0.5302\n",
      "Epoch 63/100, Loss: 0.5302\n",
      "Epoch 64/100, Loss: 0.5304\n",
      "Epoch 65/100, Loss: 0.5281\n",
      "Epoch 66/100, Loss: 0.5298\n",
      "Epoch 67/100, Loss: 0.5315\n",
      "Epoch 68/100, Loss: 0.5320\n",
      "Epoch 69/100, Loss: 0.5305\n",
      "Epoch 70/100, Loss: 0.5295\n",
      "Epoch 71/100, Loss: 0.5337\n",
      "Epoch 72/100, Loss: 0.5292\n",
      "Epoch 73/100, Loss: 0.5304\n",
      "Epoch 74/100, Loss: 0.5319\n",
      "Epoch 75/100, Loss: 0.5285\n",
      "Epoch 76/100, Loss: 0.5303\n",
      "Epoch 77/100, Loss: 0.5310\n",
      "Epoch 78/100, Loss: 0.5312\n",
      "Epoch 79/100, Loss: 0.5301\n",
      "Epoch 80/100, Loss: 0.5294\n",
      "Epoch 81/100, Loss: 0.5301\n",
      "Epoch 82/100, Loss: 0.5300\n",
      "Epoch 83/100, Loss: 0.5314\n",
      "Epoch 84/100, Loss: 0.5298\n",
      "Epoch 85/100, Loss: 0.5320\n",
      "Epoch 86/100, Loss: 0.5297\n",
      "Epoch 87/100, Loss: 0.5297\n",
      "Epoch 88/100, Loss: 0.5295\n",
      "Epoch 89/100, Loss: 0.5314\n",
      "Epoch 90/100, Loss: 0.5291\n",
      "Epoch 91/100, Loss: 0.5308\n",
      "Epoch 92/100, Loss: 0.5322\n",
      "Epoch 93/100, Loss: 0.5300\n",
      "Epoch 94/100, Loss: 0.5293\n",
      "Epoch 95/100, Loss: 0.5301\n",
      "Epoch 96/100, Loss: 0.5335\n",
      "Epoch 97/100, Loss: 0.5311\n",
      "Epoch 98/100, Loss: 0.5326\n",
      "Epoch 99/100, Loss: 0.5339\n",
      "Epoch 100/100, Loss: 0.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 231.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1976\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.8, 'mu': 0.8, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0081\n",
      "Epoch 2/100, Loss: 1.0103\n",
      "Epoch 3/100, Loss: 1.0093\n",
      "Epoch 4/100, Loss: 1.0068\n",
      "Epoch 5/100, Loss: 1.0088\n",
      "Epoch 6/100, Loss: 1.0078\n",
      "Epoch 7/100, Loss: 1.0082\n",
      "Epoch 8/100, Loss: 1.0065\n",
      "Epoch 9/100, Loss: 1.0066\n",
      "Epoch 10/100, Loss: 1.0081\n",
      "Epoch 11/100, Loss: 1.0094\n",
      "Epoch 12/100, Loss: 1.0086\n",
      "Epoch 13/100, Loss: 1.0061\n",
      "Epoch 14/100, Loss: 1.0078\n",
      "Epoch 15/100, Loss: 1.0066\n",
      "Epoch 16/100, Loss: 1.0082\n",
      "Epoch 17/100, Loss: 1.0074\n",
      "Epoch 18/100, Loss: 1.0057\n",
      "Epoch 19/100, Loss: 1.0082\n",
      "Epoch 20/100, Loss: 1.0086\n",
      "Epoch 21/100, Loss: 1.0102\n",
      "Epoch 22/100, Loss: 1.0067\n",
      "Epoch 23/100, Loss: 1.0102\n",
      "Epoch 24/100, Loss: 1.0061\n",
      "Epoch 25/100, Loss: 1.0075\n",
      "Epoch 26/100, Loss: 1.0053\n",
      "Epoch 27/100, Loss: 1.0067\n",
      "Epoch 28/100, Loss: 1.0101\n",
      "Epoch 29/100, Loss: 1.0063\n",
      "Epoch 30/100, Loss: 1.0084\n",
      "Epoch 31/100, Loss: 1.0085\n",
      "Epoch 32/100, Loss: 1.0062\n",
      "Epoch 33/100, Loss: 1.0087\n",
      "Epoch 34/100, Loss: 1.0082\n",
      "Epoch 35/100, Loss: 1.0070\n",
      "Epoch 36/100, Loss: 1.0092\n",
      "Epoch 37/100, Loss: 1.0067\n",
      "Epoch 38/100, Loss: 1.0090\n",
      "Epoch 39/100, Loss: 1.0089\n",
      "Epoch 40/100, Loss: 1.0064\n",
      "Epoch 41/100, Loss: 1.0062\n",
      "Epoch 42/100, Loss: 1.0070\n",
      "Epoch 43/100, Loss: 1.0120\n",
      "Epoch 44/100, Loss: 1.0127\n",
      "Epoch 45/100, Loss: 1.0092\n",
      "Epoch 46/100, Loss: 1.0117\n",
      "Epoch 47/100, Loss: 1.0081\n",
      "Epoch 48/100, Loss: 1.0063\n",
      "Epoch 49/100, Loss: 1.0076\n",
      "Epoch 50/100, Loss: 1.0082\n",
      "Epoch 51/100, Loss: 1.0087\n",
      "Epoch 52/100, Loss: 1.0073\n",
      "Epoch 53/100, Loss: 1.0085\n",
      "Epoch 54/100, Loss: 1.0118\n",
      "Epoch 55/100, Loss: 1.0088\n",
      "Epoch 56/100, Loss: 1.0082\n",
      "Epoch 57/100, Loss: 1.0051\n",
      "Epoch 58/100, Loss: 1.0084\n",
      "Epoch 59/100, Loss: 1.0085\n",
      "Epoch 60/100, Loss: 1.0100\n",
      "Epoch 61/100, Loss: 1.0058\n",
      "Epoch 62/100, Loss: 1.0088\n",
      "Epoch 63/100, Loss: 1.0065\n",
      "Epoch 64/100, Loss: 1.0081\n",
      "Epoch 65/100, Loss: 1.0056\n",
      "Epoch 66/100, Loss: 1.0091\n",
      "Epoch 67/100, Loss: 1.0071\n",
      "Epoch 68/100, Loss: 1.0050\n",
      "Epoch 69/100, Loss: 1.0072\n",
      "Epoch 70/100, Loss: 1.0081\n",
      "Epoch 71/100, Loss: 1.0079\n",
      "Epoch 72/100, Loss: 1.0084\n",
      "Epoch 73/100, Loss: 1.0090\n",
      "Epoch 74/100, Loss: 1.0070\n",
      "Epoch 75/100, Loss: 1.0078\n",
      "Epoch 76/100, Loss: 1.0090\n",
      "Epoch 77/100, Loss: 1.0090\n",
      "Epoch 78/100, Loss: 1.0062\n",
      "Epoch 79/100, Loss: 1.0085\n",
      "Epoch 80/100, Loss: 1.0108\n",
      "Epoch 81/100, Loss: 1.0089\n",
      "Epoch 82/100, Loss: 1.0053\n",
      "Epoch 83/100, Loss: 1.0091\n",
      "Epoch 84/100, Loss: 1.0058\n",
      "Epoch 85/100, Loss: 1.0070\n",
      "Epoch 86/100, Loss: 1.0069\n",
      "Epoch 87/100, Loss: 1.0066\n",
      "Epoch 88/100, Loss: 1.0097\n",
      "Epoch 89/100, Loss: 1.0053\n",
      "Epoch 90/100, Loss: 1.0082\n",
      "Epoch 91/100, Loss: 1.0062\n",
      "Epoch 92/100, Loss: 1.0085\n",
      "Epoch 93/100, Loss: 1.0088\n",
      "Epoch 94/100, Loss: 1.0093\n",
      "Epoch 95/100, Loss: 1.0102\n",
      "Epoch 96/100, Loss: 1.0086\n",
      "Epoch 97/100, Loss: 1.0082\n",
      "Epoch 98/100, Loss: 1.0066\n",
      "Epoch 99/100, Loss: 1.0077\n",
      "Epoch 100/100, Loss: 1.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 146.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1129\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.8388\n",
      "Epoch 2/100, Loss: 0.7319\n",
      "Epoch 3/100, Loss: 0.7193\n",
      "Epoch 4/100, Loss: 0.6681\n",
      "Epoch 5/100, Loss: 0.6531\n",
      "Epoch 6/100, Loss: 0.6659\n",
      "Epoch 7/100, Loss: 0.6646\n",
      "Epoch 8/100, Loss: 0.6260\n",
      "Epoch 9/100, Loss: 0.6182\n",
      "Epoch 10/100, Loss: 0.6132\n",
      "Epoch 11/100, Loss: 0.6183\n",
      "Epoch 12/100, Loss: 0.6327\n",
      "Epoch 13/100, Loss: 0.6092\n",
      "Epoch 14/100, Loss: 0.6526\n",
      "Epoch 15/100, Loss: 0.6786\n",
      "Epoch 16/100, Loss: 0.6391\n",
      "Epoch 17/100, Loss: 0.6146\n",
      "Epoch 18/100, Loss: 0.5991\n",
      "Epoch 19/100, Loss: 0.6398\n",
      "Epoch 20/100, Loss: 0.6441\n",
      "Epoch 21/100, Loss: 0.6827\n",
      "Epoch 22/100, Loss: 0.6617\n",
      "Epoch 23/100, Loss: 0.7082\n",
      "Epoch 24/100, Loss: 0.6109\n",
      "Epoch 25/100, Loss: 0.6404\n",
      "Epoch 26/100, Loss: 0.7162\n",
      "Epoch 27/100, Loss: 0.6839\n",
      "Epoch 28/100, Loss: 0.6615\n",
      "Epoch 29/100, Loss: 0.6099\n",
      "Epoch 30/100, Loss: 0.5842\n",
      "Epoch 31/100, Loss: 0.5821\n",
      "Epoch 32/100, Loss: 0.6355\n",
      "Epoch 33/100, Loss: 0.6238\n",
      "Epoch 34/100, Loss: 0.5956\n",
      "Epoch 35/100, Loss: 0.5863\n",
      "Epoch 36/100, Loss: 0.5751\n",
      "Epoch 37/100, Loss: 0.5932\n",
      "Epoch 38/100, Loss: 0.7054\n",
      "Epoch 39/100, Loss: 0.6775\n",
      "Epoch 40/100, Loss: 0.6458\n",
      "Epoch 41/100, Loss: 0.6014\n",
      "Epoch 42/100, Loss: 0.5724\n",
      "Epoch 43/100, Loss: 0.5607\n",
      "Epoch 44/100, Loss: 0.5668\n",
      "Epoch 45/100, Loss: 0.5544\n",
      "Epoch 46/100, Loss: 0.5811\n",
      "Epoch 47/100, Loss: 0.6201\n",
      "Epoch 48/100, Loss: 0.6088\n",
      "Epoch 49/100, Loss: 0.6450\n",
      "Epoch 50/100, Loss: 0.6527\n",
      "Epoch 51/100, Loss: 0.5899\n",
      "Epoch 52/100, Loss: 0.5707\n",
      "Epoch 53/100, Loss: 0.5965\n",
      "Epoch 54/100, Loss: 0.5843\n",
      "Epoch 55/100, Loss: 0.5794\n",
      "Epoch 56/100, Loss: 0.6658\n",
      "Epoch 57/100, Loss: 0.5880\n",
      "Epoch 58/100, Loss: 0.5496\n",
      "Epoch 59/100, Loss: 0.5503\n",
      "Epoch 60/100, Loss: 0.5602\n",
      "Epoch 61/100, Loss: 0.5963\n",
      "Epoch 62/100, Loss: 0.6374\n",
      "Epoch 63/100, Loss: 0.5943\n",
      "Epoch 64/100, Loss: 0.5817\n",
      "Epoch 65/100, Loss: 0.6038\n",
      "Epoch 66/100, Loss: 0.6871\n",
      "Epoch 67/100, Loss: 0.6772\n",
      "Epoch 68/100, Loss: 0.6307\n",
      "Epoch 69/100, Loss: 0.6173\n",
      "Epoch 70/100, Loss: 0.6123\n",
      "Epoch 71/100, Loss: 0.5674\n",
      "Epoch 72/100, Loss: 0.5551\n",
      "Epoch 73/100, Loss: 0.5531\n",
      "Epoch 74/100, Loss: 0.5636\n",
      "Epoch 75/100, Loss: 0.5682\n",
      "Epoch 76/100, Loss: 0.6250\n",
      "Epoch 77/100, Loss: 0.5969\n",
      "Epoch 78/100, Loss: 0.5773\n",
      "Epoch 79/100, Loss: 0.5721\n",
      "Epoch 80/100, Loss: 0.6364\n",
      "Epoch 81/100, Loss: 0.6011\n",
      "Epoch 82/100, Loss: 0.5739\n",
      "Epoch 83/100, Loss: 0.5707\n",
      "Epoch 84/100, Loss: 0.5650\n",
      "Epoch 85/100, Loss: 0.5614\n",
      "Epoch 86/100, Loss: 0.5627\n",
      "Epoch 87/100, Loss: 0.5880\n",
      "Epoch 88/100, Loss: 0.5897\n",
      "Epoch 89/100, Loss: 0.5776\n",
      "Epoch 90/100, Loss: 0.5816\n",
      "Epoch 91/100, Loss: 0.5791\n",
      "Epoch 92/100, Loss: 0.5682\n",
      "Epoch 93/100, Loss: 0.5675\n",
      "Epoch 94/100, Loss: 0.6158\n",
      "Epoch 95/100, Loss: 0.5857\n",
      "Epoch 96/100, Loss: 0.5779\n",
      "Epoch 97/100, Loss: 0.5819\n",
      "Epoch 98/100, Loss: 0.5757\n",
      "Epoch 99/100, Loss: 0.5763\n",
      "Epoch 100/100, Loss: 0.5832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 141.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2722\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0026\n",
      "Epoch 2/100, Loss: 1.0023\n",
      "Epoch 3/100, Loss: 1.0022\n",
      "Epoch 4/100, Loss: 1.0017\n",
      "Epoch 5/100, Loss: 1.0010\n",
      "Epoch 6/100, Loss: 1.0016\n",
      "Epoch 7/100, Loss: 1.0027\n",
      "Epoch 8/100, Loss: 1.0020\n",
      "Epoch 9/100, Loss: 1.0018\n",
      "Epoch 10/100, Loss: 1.0015\n",
      "Epoch 11/100, Loss: 1.0013\n",
      "Epoch 12/100, Loss: 1.0023\n",
      "Epoch 13/100, Loss: 1.0016\n",
      "Epoch 14/100, Loss: 1.0024\n",
      "Epoch 15/100, Loss: 1.0013\n",
      "Epoch 16/100, Loss: 1.0015\n",
      "Epoch 17/100, Loss: 1.0021\n",
      "Epoch 18/100, Loss: 1.0015\n",
      "Epoch 19/100, Loss: 1.0022\n",
      "Epoch 20/100, Loss: 1.0022\n",
      "Epoch 21/100, Loss: 1.0015\n",
      "Epoch 22/100, Loss: 1.0017\n",
      "Epoch 23/100, Loss: 1.0018\n",
      "Epoch 24/100, Loss: 1.0018\n",
      "Epoch 25/100, Loss: 1.0020\n",
      "Epoch 26/100, Loss: 1.0022\n",
      "Epoch 27/100, Loss: 1.0016\n",
      "Epoch 28/100, Loss: 1.0016\n",
      "Epoch 29/100, Loss: 1.0024\n",
      "Epoch 30/100, Loss: 1.0018\n",
      "Epoch 31/100, Loss: 1.0027\n",
      "Epoch 32/100, Loss: 1.0013\n",
      "Epoch 33/100, Loss: 1.0024\n",
      "Epoch 34/100, Loss: 1.0020\n",
      "Epoch 35/100, Loss: 1.0024\n",
      "Epoch 36/100, Loss: 1.0020\n",
      "Epoch 37/100, Loss: 1.0021\n",
      "Epoch 38/100, Loss: 1.0012\n",
      "Epoch 39/100, Loss: 1.0020\n",
      "Epoch 40/100, Loss: 1.0023\n",
      "Epoch 41/100, Loss: 1.0020\n",
      "Epoch 42/100, Loss: 1.0021\n",
      "Epoch 43/100, Loss: 1.0025\n",
      "Epoch 44/100, Loss: 1.0022\n",
      "Epoch 45/100, Loss: 1.0026\n",
      "Epoch 46/100, Loss: 1.0019\n",
      "Epoch 47/100, Loss: 1.0020\n",
      "Epoch 48/100, Loss: 1.0017\n",
      "Epoch 49/100, Loss: 1.0017\n",
      "Epoch 50/100, Loss: 1.0023\n",
      "Epoch 51/100, Loss: 1.0029\n",
      "Epoch 52/100, Loss: 1.0022\n",
      "Epoch 53/100, Loss: 1.0024\n",
      "Epoch 54/100, Loss: 1.0009\n",
      "Epoch 55/100, Loss: 1.0021\n",
      "Epoch 56/100, Loss: 1.0019\n",
      "Epoch 57/100, Loss: 1.0017\n",
      "Epoch 58/100, Loss: 1.0019\n",
      "Epoch 59/100, Loss: 1.0023\n",
      "Epoch 60/100, Loss: 1.0018\n",
      "Epoch 61/100, Loss: 1.0020\n",
      "Epoch 62/100, Loss: 1.0015\n",
      "Epoch 63/100, Loss: 1.0025\n",
      "Epoch 64/100, Loss: 1.0020\n",
      "Epoch 65/100, Loss: 1.0021\n",
      "Epoch 66/100, Loss: 1.0018\n",
      "Epoch 67/100, Loss: 1.0020\n",
      "Epoch 68/100, Loss: 1.0018\n",
      "Epoch 69/100, Loss: 1.0020\n",
      "Epoch 70/100, Loss: 1.0019\n",
      "Epoch 71/100, Loss: 1.0032\n",
      "Epoch 72/100, Loss: 1.0021\n",
      "Epoch 73/100, Loss: 1.0021\n",
      "Epoch 74/100, Loss: 1.0021\n",
      "Epoch 75/100, Loss: 1.0022\n",
      "Epoch 76/100, Loss: 1.0025\n",
      "Epoch 77/100, Loss: 1.0013\n",
      "Epoch 78/100, Loss: 1.0028\n",
      "Epoch 79/100, Loss: 1.0022\n",
      "Epoch 80/100, Loss: 1.0020\n",
      "Epoch 81/100, Loss: 1.0030\n",
      "Epoch 82/100, Loss: 1.0018\n",
      "Epoch 83/100, Loss: 1.0014\n",
      "Epoch 84/100, Loss: 1.0021\n",
      "Epoch 85/100, Loss: 1.0026\n",
      "Epoch 86/100, Loss: 1.0015\n",
      "Epoch 87/100, Loss: 1.0021\n",
      "Epoch 88/100, Loss: 1.0022\n",
      "Epoch 89/100, Loss: 1.0020\n",
      "Epoch 90/100, Loss: 1.0031\n",
      "Epoch 91/100, Loss: 1.0020\n",
      "Epoch 92/100, Loss: 1.0033\n",
      "Epoch 93/100, Loss: 1.0020\n",
      "Epoch 94/100, Loss: 1.0016\n",
      "Epoch 95/100, Loss: 1.0018\n",
      "Epoch 96/100, Loss: 1.0017\n",
      "Epoch 97/100, Loss: 1.0029\n",
      "Epoch 98/100, Loss: 1.0022\n",
      "Epoch 99/100, Loss: 1.0017\n",
      "Epoch 100/100, Loss: 1.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 131.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1154\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0098\n",
      "Epoch 2/100, Loss: 1.0110\n",
      "Epoch 3/100, Loss: 1.0099\n",
      "Epoch 4/100, Loss: 1.0086\n",
      "Epoch 5/100, Loss: 1.0086\n",
      "Epoch 6/100, Loss: 1.0073\n",
      "Epoch 7/100, Loss: 1.0109\n",
      "Epoch 8/100, Loss: 1.0113\n",
      "Epoch 9/100, Loss: 1.0086\n",
      "Epoch 10/100, Loss: 1.0086\n",
      "Epoch 11/100, Loss: 1.0079\n",
      "Epoch 12/100, Loss: 1.0087\n",
      "Epoch 13/100, Loss: 1.0077\n",
      "Epoch 14/100, Loss: 1.0101\n",
      "Epoch 15/100, Loss: 1.0105\n",
      "Epoch 16/100, Loss: 1.0104\n",
      "Epoch 17/100, Loss: 1.0087\n",
      "Epoch 18/100, Loss: 1.0114\n",
      "Epoch 19/100, Loss: 1.0081\n",
      "Epoch 20/100, Loss: 1.0097\n",
      "Epoch 21/100, Loss: 1.0062\n",
      "Epoch 22/100, Loss: 1.0096\n",
      "Epoch 23/100, Loss: 1.0076\n",
      "Epoch 24/100, Loss: 1.0085\n",
      "Epoch 25/100, Loss: 1.0100\n",
      "Epoch 26/100, Loss: 1.0091\n",
      "Epoch 27/100, Loss: 1.0093\n",
      "Epoch 28/100, Loss: 1.0068\n",
      "Epoch 29/100, Loss: 1.0083\n",
      "Epoch 30/100, Loss: 1.0120\n",
      "Epoch 31/100, Loss: 1.0100\n",
      "Epoch 32/100, Loss: 1.0094\n",
      "Epoch 33/100, Loss: 1.0112\n",
      "Epoch 34/100, Loss: 1.0102\n",
      "Epoch 35/100, Loss: 1.0085\n",
      "Epoch 36/100, Loss: 1.0106\n",
      "Epoch 37/100, Loss: 1.0080\n",
      "Epoch 38/100, Loss: 1.0101\n",
      "Epoch 39/100, Loss: 1.0089\n",
      "Epoch 40/100, Loss: 1.0083\n",
      "Epoch 41/100, Loss: 1.0097\n",
      "Epoch 42/100, Loss: 1.0062\n",
      "Epoch 43/100, Loss: 1.0087\n",
      "Epoch 44/100, Loss: 1.0114\n",
      "Epoch 45/100, Loss: 1.0076\n",
      "Epoch 46/100, Loss: 1.0084\n",
      "Epoch 47/100, Loss: 1.0084\n",
      "Epoch 48/100, Loss: 1.0095\n",
      "Epoch 49/100, Loss: 1.0111\n",
      "Epoch 50/100, Loss: 1.0075\n",
      "Epoch 51/100, Loss: 1.0101\n",
      "Epoch 52/100, Loss: 1.0079\n",
      "Epoch 53/100, Loss: 1.0088\n",
      "Epoch 54/100, Loss: 1.0126\n",
      "Epoch 55/100, Loss: 1.0088\n",
      "Epoch 56/100, Loss: 1.0102\n",
      "Epoch 57/100, Loss: 1.0111\n",
      "Epoch 58/100, Loss: 1.0081\n",
      "Epoch 59/100, Loss: 1.0092\n",
      "Epoch 60/100, Loss: 1.0080\n",
      "Epoch 61/100, Loss: 1.0085\n",
      "Epoch 62/100, Loss: 1.0068\n",
      "Epoch 63/100, Loss: 1.0092\n",
      "Epoch 64/100, Loss: 1.0091\n",
      "Epoch 65/100, Loss: 1.0097\n",
      "Epoch 66/100, Loss: 1.0095\n",
      "Epoch 67/100, Loss: 1.0136\n",
      "Epoch 68/100, Loss: 1.0081\n",
      "Epoch 69/100, Loss: 1.0123\n",
      "Epoch 70/100, Loss: 1.0095\n",
      "Epoch 71/100, Loss: 1.0089\n",
      "Epoch 72/100, Loss: 1.0091\n",
      "Epoch 73/100, Loss: 1.0142\n",
      "Epoch 74/100, Loss: 1.0104\n",
      "Epoch 75/100, Loss: 1.0101\n",
      "Epoch 76/100, Loss: 1.0138\n",
      "Epoch 77/100, Loss: 1.0087\n",
      "Epoch 78/100, Loss: 1.0128\n",
      "Epoch 79/100, Loss: 1.0085\n",
      "Epoch 80/100, Loss: 1.0111\n",
      "Epoch 81/100, Loss: 1.0084\n",
      "Epoch 82/100, Loss: 1.0130\n",
      "Epoch 83/100, Loss: 1.0091\n",
      "Epoch 84/100, Loss: 1.0094\n",
      "Epoch 85/100, Loss: 1.0076\n",
      "Epoch 86/100, Loss: 1.0120\n",
      "Epoch 87/100, Loss: 1.0108\n",
      "Epoch 88/100, Loss: 1.0087\n",
      "Epoch 89/100, Loss: 1.0101\n",
      "Epoch 90/100, Loss: 1.0103\n",
      "Epoch 91/100, Loss: 1.0081\n",
      "Epoch 92/100, Loss: 1.0073\n",
      "Epoch 93/100, Loss: 1.0111\n",
      "Epoch 94/100, Loss: 1.0073\n",
      "Epoch 95/100, Loss: 1.0117\n",
      "Epoch 96/100, Loss: 1.0104\n",
      "Epoch 97/100, Loss: 1.0084\n",
      "Epoch 98/100, Loss: 1.0092\n",
      "Epoch 99/100, Loss: 1.0101\n",
      "Epoch 100/100, Loss: 1.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 174.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1168\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.7439\n",
      "Epoch 2/100, Loss: 0.6850\n",
      "Epoch 3/100, Loss: 0.6510\n",
      "Epoch 4/100, Loss: 0.6272\n",
      "Epoch 5/100, Loss: 0.6206\n",
      "Epoch 6/100, Loss: 0.5897\n",
      "Epoch 7/100, Loss: 0.5376\n",
      "Epoch 8/100, Loss: 0.5296\n",
      "Epoch 9/100, Loss: 0.5222\n",
      "Epoch 10/100, Loss: 0.4584\n",
      "Epoch 11/100, Loss: 0.4077\n",
      "Epoch 12/100, Loss: 0.4118\n",
      "Epoch 13/100, Loss: 0.3934\n",
      "Epoch 14/100, Loss: 0.4010\n",
      "Epoch 15/100, Loss: 0.3633\n",
      "Epoch 16/100, Loss: 0.3750\n",
      "Epoch 17/100, Loss: 0.3134\n",
      "Epoch 18/100, Loss: 0.3137\n",
      "Epoch 19/100, Loss: 0.4693\n",
      "Epoch 20/100, Loss: 0.3796\n",
      "Epoch 21/100, Loss: 0.3498\n",
      "Epoch 22/100, Loss: 0.3155\n",
      "Epoch 23/100, Loss: 0.2948\n",
      "Epoch 24/100, Loss: 0.3116\n",
      "Epoch 25/100, Loss: 0.3097\n",
      "Epoch 26/100, Loss: 0.3056\n",
      "Epoch 27/100, Loss: 0.3258\n",
      "Epoch 28/100, Loss: 0.3160\n",
      "Epoch 29/100, Loss: 0.3236\n",
      "Epoch 30/100, Loss: 0.2984\n",
      "Epoch 31/100, Loss: 0.2935\n",
      "Epoch 32/100, Loss: 0.3126\n",
      "Epoch 33/100, Loss: 0.3171\n",
      "Epoch 34/100, Loss: 0.2983\n",
      "Epoch 35/100, Loss: 0.2823\n",
      "Epoch 36/100, Loss: 0.2877\n",
      "Epoch 37/100, Loss: 0.2915\n",
      "Epoch 38/100, Loss: 0.3493\n",
      "Epoch 39/100, Loss: 0.3538\n",
      "Epoch 40/100, Loss: 0.3068\n",
      "Epoch 41/100, Loss: 0.2752\n",
      "Epoch 42/100, Loss: 0.3104\n",
      "Epoch 43/100, Loss: 0.2798\n",
      "Epoch 44/100, Loss: 0.3052\n",
      "Epoch 45/100, Loss: 0.3054\n",
      "Epoch 46/100, Loss: 0.3195\n",
      "Epoch 47/100, Loss: 0.3487\n",
      "Epoch 48/100, Loss: 0.3016\n",
      "Epoch 49/100, Loss: 0.2928\n",
      "Epoch 50/100, Loss: 0.2893\n",
      "Epoch 51/100, Loss: 0.2852\n",
      "Epoch 52/100, Loss: 0.2823\n",
      "Epoch 53/100, Loss: 0.2625\n",
      "Epoch 54/100, Loss: 0.2619\n",
      "Epoch 55/100, Loss: 0.2514\n",
      "Epoch 56/100, Loss: 0.2824\n",
      "Epoch 57/100, Loss: 0.2565\n",
      "Epoch 58/100, Loss: 0.3057\n",
      "Epoch 59/100, Loss: 0.2774\n",
      "Epoch 60/100, Loss: 0.2675\n",
      "Epoch 61/100, Loss: 0.2739\n",
      "Epoch 62/100, Loss: 0.2888\n",
      "Epoch 63/100, Loss: 0.3415\n",
      "Epoch 64/100, Loss: 0.3355\n",
      "Epoch 65/100, Loss: 0.2936\n",
      "Epoch 66/100, Loss: 0.3128\n",
      "Epoch 67/100, Loss: 0.2666\n",
      "Epoch 68/100, Loss: 0.2459\n",
      "Epoch 69/100, Loss: 0.2321\n",
      "Epoch 70/100, Loss: 0.2281\n",
      "Epoch 71/100, Loss: 0.2322\n",
      "Epoch 72/100, Loss: 0.2204\n",
      "Epoch 73/100, Loss: 0.2215\n",
      "Epoch 74/100, Loss: 0.2244\n",
      "Epoch 75/100, Loss: 0.2182\n",
      "Epoch 76/100, Loss: 0.2399\n",
      "Epoch 77/100, Loss: 0.2241\n",
      "Epoch 78/100, Loss: 0.2296\n",
      "Epoch 79/100, Loss: 0.2462\n",
      "Epoch 80/100, Loss: 0.2397\n",
      "Epoch 81/100, Loss: 0.2406\n",
      "Epoch 82/100, Loss: 0.2354\n",
      "Epoch 83/100, Loss: 0.2430\n",
      "Epoch 84/100, Loss: 0.2760\n",
      "Epoch 85/100, Loss: 0.4053\n",
      "Epoch 86/100, Loss: 0.2916\n",
      "Epoch 87/100, Loss: 0.2635\n",
      "Epoch 88/100, Loss: 0.2723\n",
      "Epoch 89/100, Loss: 0.2535\n",
      "Epoch 90/100, Loss: 0.2285\n",
      "Epoch 91/100, Loss: 0.2237\n",
      "Epoch 92/100, Loss: 0.2257\n",
      "Epoch 93/100, Loss: 0.2525\n",
      "Epoch 94/100, Loss: 0.2555\n",
      "Epoch 95/100, Loss: 0.2542\n",
      "Epoch 96/100, Loss: 0.2756\n",
      "Epoch 97/100, Loss: 0.5513\n",
      "Epoch 98/100, Loss: 0.3125\n",
      "Epoch 99/100, Loss: 0.2834\n",
      "Epoch 100/100, Loss: 0.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 200.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3884\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0007\n",
      "Epoch 2/100, Loss: 1.0022\n",
      "Epoch 3/100, Loss: 1.0016\n",
      "Epoch 4/100, Loss: 1.0023\n",
      "Epoch 5/100, Loss: 1.0023\n",
      "Epoch 6/100, Loss: 1.0016\n",
      "Epoch 7/100, Loss: 1.0016\n",
      "Epoch 8/100, Loss: 1.0020\n",
      "Epoch 9/100, Loss: 1.0021\n",
      "Epoch 10/100, Loss: 1.0022\n",
      "Epoch 11/100, Loss: 1.0019\n",
      "Epoch 12/100, Loss: 1.0018\n",
      "Epoch 13/100, Loss: 1.0023\n",
      "Epoch 14/100, Loss: 1.0018\n",
      "Epoch 15/100, Loss: 1.0015\n",
      "Epoch 16/100, Loss: 1.0017\n",
      "Epoch 17/100, Loss: 1.0023\n",
      "Epoch 18/100, Loss: 1.0011\n",
      "Epoch 19/100, Loss: 1.0025\n",
      "Epoch 20/100, Loss: 1.0016\n",
      "Epoch 21/100, Loss: 1.0021\n",
      "Epoch 22/100, Loss: 1.0025\n",
      "Epoch 23/100, Loss: 1.0013\n",
      "Epoch 24/100, Loss: 1.0024\n",
      "Epoch 25/100, Loss: 1.0013\n",
      "Epoch 26/100, Loss: 1.0023\n",
      "Epoch 27/100, Loss: 1.0020\n",
      "Epoch 28/100, Loss: 1.0017\n",
      "Epoch 29/100, Loss: 1.0013\n",
      "Epoch 30/100, Loss: 1.0027\n",
      "Epoch 31/100, Loss: 1.0019\n",
      "Epoch 32/100, Loss: 1.0021\n",
      "Epoch 33/100, Loss: 1.0020\n",
      "Epoch 34/100, Loss: 1.0024\n",
      "Epoch 35/100, Loss: 1.0019\n",
      "Epoch 36/100, Loss: 1.0019\n",
      "Epoch 37/100, Loss: 1.0019\n",
      "Epoch 38/100, Loss: 1.0021\n",
      "Epoch 39/100, Loss: 1.0013\n",
      "Epoch 40/100, Loss: 1.0022\n",
      "Epoch 41/100, Loss: 1.0017\n",
      "Epoch 42/100, Loss: 1.0020\n",
      "Epoch 43/100, Loss: 1.0019\n",
      "Epoch 44/100, Loss: 1.0017\n",
      "Epoch 45/100, Loss: 1.0024\n",
      "Epoch 46/100, Loss: 1.0020\n",
      "Epoch 47/100, Loss: 1.0020\n",
      "Epoch 48/100, Loss: 1.0015\n",
      "Epoch 49/100, Loss: 1.0023\n",
      "Epoch 50/100, Loss: 1.0028\n",
      "Epoch 51/100, Loss: 1.0018\n",
      "Epoch 52/100, Loss: 1.0018\n",
      "Epoch 53/100, Loss: 1.0019\n",
      "Epoch 54/100, Loss: 1.0023\n",
      "Epoch 55/100, Loss: 1.0020\n",
      "Epoch 56/100, Loss: 1.0023\n",
      "Epoch 57/100, Loss: 1.0021\n",
      "Epoch 58/100, Loss: 1.0014\n",
      "Epoch 59/100, Loss: 1.0024\n",
      "Epoch 60/100, Loss: 1.0018\n",
      "Epoch 61/100, Loss: 1.0016\n",
      "Epoch 62/100, Loss: 1.0022\n",
      "Epoch 63/100, Loss: 1.0017\n",
      "Epoch 64/100, Loss: 1.0017\n",
      "Epoch 65/100, Loss: 1.0024\n",
      "Epoch 66/100, Loss: 1.0023\n",
      "Epoch 67/100, Loss: 1.0018\n",
      "Epoch 68/100, Loss: 1.0036\n",
      "Epoch 69/100, Loss: 1.0013\n",
      "Epoch 70/100, Loss: 1.0014\n",
      "Epoch 71/100, Loss: 1.0026\n",
      "Epoch 72/100, Loss: 1.0021\n",
      "Epoch 73/100, Loss: 1.0025\n",
      "Epoch 74/100, Loss: 1.0017\n",
      "Epoch 75/100, Loss: 1.0018\n",
      "Epoch 76/100, Loss: 1.0018\n",
      "Epoch 77/100, Loss: 1.0015\n",
      "Epoch 78/100, Loss: 1.0011\n",
      "Epoch 79/100, Loss: 1.0016\n",
      "Epoch 80/100, Loss: 1.0018\n",
      "Epoch 81/100, Loss: 1.0021\n",
      "Epoch 82/100, Loss: 1.0014\n",
      "Epoch 83/100, Loss: 1.0023\n",
      "Epoch 84/100, Loss: 1.0032\n",
      "Epoch 85/100, Loss: 1.0026\n",
      "Epoch 86/100, Loss: 1.0013\n",
      "Epoch 87/100, Loss: 1.0023\n",
      "Epoch 88/100, Loss: 1.0018\n",
      "Epoch 89/100, Loss: 1.0025\n",
      "Epoch 90/100, Loss: 1.0022\n",
      "Epoch 91/100, Loss: 1.0015\n",
      "Epoch 92/100, Loss: 1.0022\n",
      "Epoch 93/100, Loss: 1.0023\n",
      "Epoch 94/100, Loss: 1.0031\n",
      "Epoch 95/100, Loss: 1.0016\n",
      "Epoch 96/100, Loss: 1.0028\n",
      "Epoch 97/100, Loss: 1.0018\n",
      "Epoch 98/100, Loss: 1.0017\n",
      "Epoch 99/100, Loss: 1.0018\n",
      "Epoch 100/100, Loss: 1.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 275.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1139\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0046\n",
      "Epoch 2/100, Loss: 1.0103\n",
      "Epoch 3/100, Loss: 1.0126\n",
      "Epoch 4/100, Loss: 1.0084\n",
      "Epoch 5/100, Loss: 1.0083\n",
      "Epoch 6/100, Loss: 1.0100\n",
      "Epoch 7/100, Loss: 1.0116\n",
      "Epoch 8/100, Loss: 1.0093\n",
      "Epoch 9/100, Loss: 1.0075\n",
      "Epoch 10/100, Loss: 1.0102\n",
      "Epoch 11/100, Loss: 1.0085\n",
      "Epoch 12/100, Loss: 1.0112\n",
      "Epoch 13/100, Loss: 1.0101\n",
      "Epoch 14/100, Loss: 1.0099\n",
      "Epoch 15/100, Loss: 1.0122\n",
      "Epoch 16/100, Loss: 1.0083\n",
      "Epoch 17/100, Loss: 1.0083\n",
      "Epoch 18/100, Loss: 1.0105\n",
      "Epoch 19/100, Loss: 1.0066\n",
      "Epoch 20/100, Loss: 1.0095\n",
      "Epoch 21/100, Loss: 1.0092\n",
      "Epoch 22/100, Loss: 1.0122\n",
      "Epoch 23/100, Loss: 1.0099\n",
      "Epoch 24/100, Loss: 1.0126\n",
      "Epoch 25/100, Loss: 1.0118\n",
      "Epoch 26/100, Loss: 1.0072\n",
      "Epoch 27/100, Loss: 1.0076\n",
      "Epoch 28/100, Loss: 1.0074\n",
      "Epoch 29/100, Loss: 1.0073\n",
      "Epoch 30/100, Loss: 1.0102\n",
      "Epoch 31/100, Loss: 1.0088\n",
      "Epoch 32/100, Loss: 1.0112\n",
      "Epoch 33/100, Loss: 1.0085\n",
      "Epoch 34/100, Loss: 1.0081\n",
      "Epoch 35/100, Loss: 1.0092\n",
      "Epoch 36/100, Loss: 1.0098\n",
      "Epoch 37/100, Loss: 1.0086\n",
      "Epoch 38/100, Loss: 1.0081\n",
      "Epoch 39/100, Loss: 1.0105\n",
      "Epoch 40/100, Loss: 1.0098\n",
      "Epoch 41/100, Loss: 1.0073\n",
      "Epoch 42/100, Loss: 1.0093\n",
      "Epoch 43/100, Loss: 1.0131\n",
      "Epoch 44/100, Loss: 1.0093\n",
      "Epoch 45/100, Loss: 1.0108\n",
      "Epoch 46/100, Loss: 1.0098\n",
      "Epoch 47/100, Loss: 1.0127\n",
      "Epoch 48/100, Loss: 1.0102\n",
      "Epoch 49/100, Loss: 1.0090\n",
      "Epoch 50/100, Loss: 1.0071\n",
      "Epoch 51/100, Loss: 1.0145\n",
      "Epoch 52/100, Loss: 1.0123\n",
      "Epoch 53/100, Loss: 1.0092\n",
      "Epoch 54/100, Loss: 1.0098\n",
      "Epoch 55/100, Loss: 1.0080\n",
      "Epoch 56/100, Loss: 1.0089\n",
      "Epoch 57/100, Loss: 1.0067\n",
      "Epoch 58/100, Loss: 1.0101\n",
      "Epoch 59/100, Loss: 1.0070\n",
      "Epoch 60/100, Loss: 1.0114\n",
      "Epoch 61/100, Loss: 1.0090\n",
      "Epoch 62/100, Loss: 1.0074\n",
      "Epoch 63/100, Loss: 1.0119\n",
      "Epoch 64/100, Loss: 1.0099\n",
      "Epoch 65/100, Loss: 1.0128\n",
      "Epoch 66/100, Loss: 1.0095\n",
      "Epoch 67/100, Loss: 1.0091\n",
      "Epoch 68/100, Loss: 1.0100\n",
      "Epoch 69/100, Loss: 1.0107\n",
      "Epoch 70/100, Loss: 1.0165\n",
      "Epoch 71/100, Loss: 1.0069\n",
      "Epoch 72/100, Loss: 1.0101\n",
      "Epoch 73/100, Loss: 1.0096\n",
      "Epoch 74/100, Loss: 1.0104\n",
      "Epoch 75/100, Loss: 1.0092\n",
      "Epoch 76/100, Loss: 1.0098\n",
      "Epoch 77/100, Loss: 1.0098\n",
      "Epoch 78/100, Loss: 1.0082\n",
      "Epoch 79/100, Loss: 1.0093\n",
      "Epoch 80/100, Loss: 1.0108\n",
      "Epoch 81/100, Loss: 1.0098\n",
      "Epoch 82/100, Loss: 1.0089\n",
      "Epoch 83/100, Loss: 1.0115\n",
      "Epoch 84/100, Loss: 1.0111\n",
      "Epoch 85/100, Loss: 1.0115\n",
      "Epoch 86/100, Loss: 1.0092\n",
      "Epoch 87/100, Loss: 1.0122\n",
      "Epoch 88/100, Loss: 1.0121\n",
      "Epoch 89/100, Loss: 1.0091\n",
      "Epoch 90/100, Loss: 1.0079\n",
      "Epoch 91/100, Loss: 1.0077\n",
      "Epoch 92/100, Loss: 1.0098\n",
      "Epoch 93/100, Loss: 1.0111\n",
      "Epoch 94/100, Loss: 1.0086\n",
      "Epoch 95/100, Loss: 1.0121\n",
      "Epoch 96/100, Loss: 1.0101\n",
      "Epoch 97/100, Loss: 1.0109\n",
      "Epoch 98/100, Loss: 1.0108\n",
      "Epoch 99/100, Loss: 1.0099\n",
      "Epoch 100/100, Loss: 1.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 176.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1127\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.8, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.6777\n",
      "Epoch 2/100, Loss: 0.5774\n",
      "Epoch 3/100, Loss: 0.5584\n",
      "Epoch 4/100, Loss: 0.5163\n",
      "Epoch 5/100, Loss: 0.5215\n",
      "Epoch 6/100, Loss: 0.4953\n",
      "Epoch 7/100, Loss: 0.4868\n",
      "Epoch 8/100, Loss: 0.4984\n",
      "Epoch 9/100, Loss: 0.5030\n",
      "Epoch 10/100, Loss: 0.4946\n",
      "Epoch 11/100, Loss: 0.4411\n",
      "Epoch 12/100, Loss: 0.3621\n",
      "Epoch 13/100, Loss: 0.3738\n",
      "Epoch 14/100, Loss: 0.3502\n",
      "Epoch 15/100, Loss: 0.3357\n",
      "Epoch 16/100, Loss: 0.3371\n",
      "Epoch 17/100, Loss: 0.2740\n",
      "Epoch 18/100, Loss: 0.2472\n",
      "Epoch 19/100, Loss: 0.2386\n",
      "Epoch 20/100, Loss: 0.2368\n",
      "Epoch 21/100, Loss: 0.2565\n",
      "Epoch 22/100, Loss: 0.2507\n",
      "Epoch 23/100, Loss: 0.2622\n",
      "Epoch 24/100, Loss: 0.2189\n",
      "Epoch 25/100, Loss: 0.2180\n",
      "Epoch 26/100, Loss: 0.2117\n",
      "Epoch 27/100, Loss: 0.2519\n",
      "Epoch 28/100, Loss: 0.2469\n",
      "Epoch 29/100, Loss: 0.2302\n",
      "Epoch 30/100, Loss: 0.1878\n",
      "Epoch 31/100, Loss: 0.2044\n",
      "Epoch 32/100, Loss: 0.2217\n",
      "Epoch 33/100, Loss: 0.2107\n",
      "Epoch 34/100, Loss: 0.1795\n",
      "Epoch 35/100, Loss: 0.1837\n",
      "Epoch 36/100, Loss: 0.2044\n",
      "Epoch 37/100, Loss: 0.1866\n",
      "Epoch 38/100, Loss: 0.1872\n",
      "Epoch 39/100, Loss: 0.1732\n",
      "Epoch 40/100, Loss: 0.2271\n",
      "Epoch 41/100, Loss: 0.1793\n",
      "Epoch 42/100, Loss: 0.1733\n",
      "Epoch 43/100, Loss: 0.1824\n",
      "Epoch 44/100, Loss: 0.1594\n",
      "Epoch 45/100, Loss: 0.1509\n",
      "Epoch 46/100, Loss: 0.1582\n",
      "Epoch 47/100, Loss: 0.1767\n",
      "Epoch 48/100, Loss: 0.1398\n",
      "Epoch 49/100, Loss: 0.1319\n",
      "Epoch 50/100, Loss: 0.1438\n",
      "Epoch 51/100, Loss: 0.1440\n",
      "Epoch 52/100, Loss: 0.1355\n",
      "Epoch 53/100, Loss: 0.1342\n",
      "Epoch 54/100, Loss: 0.1344\n",
      "Epoch 55/100, Loss: 0.1507\n",
      "Epoch 56/100, Loss: 0.1620\n",
      "Epoch 57/100, Loss: 0.1427\n",
      "Epoch 58/100, Loss: 0.1334\n",
      "Epoch 59/100, Loss: 0.1330\n",
      "Epoch 60/100, Loss: 0.1508\n",
      "Epoch 61/100, Loss: 0.1355\n",
      "Epoch 62/100, Loss: 0.1313\n",
      "Epoch 63/100, Loss: 0.1108\n",
      "Epoch 64/100, Loss: 0.1454\n",
      "Epoch 65/100, Loss: 0.1412\n",
      "Epoch 66/100, Loss: 0.0951\n",
      "Epoch 67/100, Loss: 0.1448\n",
      "Epoch 68/100, Loss: 0.1461\n",
      "Epoch 69/100, Loss: 0.1428\n",
      "Epoch 70/100, Loss: 0.1172\n",
      "Epoch 71/100, Loss: 0.1231\n",
      "Epoch 72/100, Loss: 0.1739\n",
      "Epoch 73/100, Loss: 0.1488\n",
      "Epoch 74/100, Loss: 0.1473\n",
      "Epoch 75/100, Loss: 0.1421\n",
      "Epoch 76/100, Loss: 0.1058\n",
      "Epoch 77/100, Loss: 0.1054\n",
      "Epoch 78/100, Loss: 0.1387\n",
      "Epoch 79/100, Loss: 0.1182\n",
      "Epoch 80/100, Loss: 0.1622\n",
      "Epoch 81/100, Loss: 0.1546\n",
      "Epoch 82/100, Loss: 0.1217\n",
      "Epoch 83/100, Loss: 0.1743\n",
      "Epoch 84/100, Loss: 0.1830\n",
      "Epoch 85/100, Loss: 0.1407\n",
      "Epoch 86/100, Loss: 0.1194\n",
      "Epoch 87/100, Loss: 0.1454\n",
      "Epoch 88/100, Loss: 0.1316\n",
      "Epoch 89/100, Loss: 0.1485\n",
      "Epoch 90/100, Loss: 0.1255\n",
      "Epoch 91/100, Loss: 0.1235\n",
      "Epoch 92/100, Loss: 0.1278\n",
      "Epoch 93/100, Loss: 0.1716\n",
      "Epoch 94/100, Loss: 0.1446\n",
      "Epoch 95/100, Loss: 0.1345\n",
      "Epoch 96/100, Loss: 0.1390\n",
      "Epoch 97/100, Loss: 0.1103\n",
      "Epoch 98/100, Loss: 0.1299\n",
      "Epoch 99/100, Loss: 0.1110\n",
      "Epoch 100/100, Loss: 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 185.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3645\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.8, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.9951\n",
      "Epoch 2/100, Loss: 1.0019\n",
      "Epoch 3/100, Loss: 1.0020\n",
      "Epoch 4/100, Loss: 1.0018\n",
      "Epoch 5/100, Loss: 1.0018\n",
      "Epoch 6/100, Loss: 1.0019\n",
      "Epoch 7/100, Loss: 1.0014\n",
      "Epoch 8/100, Loss: 1.0024\n",
      "Epoch 9/100, Loss: 1.0011\n",
      "Epoch 10/100, Loss: 1.0019\n",
      "Epoch 11/100, Loss: 1.0027\n",
      "Epoch 12/100, Loss: 1.0014\n",
      "Epoch 13/100, Loss: 1.0020\n",
      "Epoch 14/100, Loss: 1.0021\n",
      "Epoch 15/100, Loss: 1.0020\n",
      "Epoch 16/100, Loss: 1.0019\n",
      "Epoch 17/100, Loss: 1.0025\n",
      "Epoch 18/100, Loss: 1.0023\n",
      "Epoch 19/100, Loss: 1.0014\n",
      "Epoch 20/100, Loss: 1.0026\n",
      "Epoch 21/100, Loss: 1.0013\n",
      "Epoch 22/100, Loss: 1.0017\n",
      "Epoch 23/100, Loss: 1.0024\n",
      "Epoch 24/100, Loss: 1.0015\n",
      "Epoch 25/100, Loss: 1.0017\n",
      "Epoch 26/100, Loss: 1.0023\n",
      "Epoch 27/100, Loss: 1.0016\n",
      "Epoch 28/100, Loss: 1.0020\n",
      "Epoch 29/100, Loss: 1.0016\n",
      "Epoch 30/100, Loss: 1.0019\n",
      "Epoch 31/100, Loss: 1.0023\n",
      "Epoch 32/100, Loss: 1.0023\n",
      "Epoch 33/100, Loss: 1.0016\n",
      "Epoch 34/100, Loss: 1.0018\n",
      "Epoch 35/100, Loss: 1.0027\n",
      "Epoch 36/100, Loss: 1.0018\n",
      "Epoch 37/100, Loss: 1.0023\n",
      "Epoch 38/100, Loss: 1.0020\n",
      "Epoch 39/100, Loss: 1.0025\n",
      "Epoch 40/100, Loss: 1.0028\n",
      "Epoch 41/100, Loss: 1.0019\n",
      "Epoch 42/100, Loss: 1.0013\n",
      "Epoch 43/100, Loss: 1.0017\n",
      "Epoch 44/100, Loss: 1.0019\n",
      "Epoch 45/100, Loss: 1.0021\n",
      "Epoch 46/100, Loss: 1.0019\n",
      "Epoch 47/100, Loss: 1.0018\n",
      "Epoch 48/100, Loss: 1.0018\n",
      "Epoch 49/100, Loss: 1.0028\n",
      "Epoch 50/100, Loss: 1.0025\n",
      "Epoch 51/100, Loss: 1.0024\n",
      "Epoch 52/100, Loss: 1.0008\n",
      "Epoch 53/100, Loss: 1.0021\n",
      "Epoch 54/100, Loss: 1.0021\n",
      "Epoch 55/100, Loss: 1.0016\n",
      "Epoch 56/100, Loss: 1.0025\n",
      "Epoch 57/100, Loss: 1.0022\n",
      "Epoch 58/100, Loss: 1.0017\n",
      "Epoch 59/100, Loss: 1.0017\n",
      "Epoch 60/100, Loss: 1.0023\n",
      "Epoch 61/100, Loss: 1.0029\n",
      "Epoch 62/100, Loss: 1.0025\n",
      "Epoch 63/100, Loss: 1.0024\n",
      "Epoch 64/100, Loss: 1.0016\n",
      "Epoch 65/100, Loss: 1.0020\n",
      "Epoch 66/100, Loss: 1.0018\n",
      "Epoch 67/100, Loss: 1.0018\n",
      "Epoch 68/100, Loss: 1.0026\n",
      "Epoch 69/100, Loss: 1.0023\n",
      "Epoch 70/100, Loss: 1.0023\n",
      "Epoch 71/100, Loss: 1.0014\n",
      "Epoch 72/100, Loss: 1.0017\n",
      "Epoch 73/100, Loss: 1.0015\n",
      "Epoch 74/100, Loss: 1.0016\n",
      "Epoch 75/100, Loss: 1.0021\n",
      "Epoch 76/100, Loss: 1.0019\n",
      "Epoch 77/100, Loss: 1.0017\n",
      "Epoch 78/100, Loss: 1.0021\n",
      "Epoch 79/100, Loss: 1.0009\n",
      "Epoch 80/100, Loss: 1.0023\n",
      "Epoch 81/100, Loss: 1.0018\n",
      "Epoch 82/100, Loss: 1.0021\n",
      "Epoch 83/100, Loss: 1.0016\n",
      "Epoch 84/100, Loss: 1.0016\n",
      "Epoch 85/100, Loss: 1.0040\n",
      "Epoch 86/100, Loss: 1.0024\n",
      "Epoch 87/100, Loss: 1.0027\n",
      "Epoch 88/100, Loss: 1.0019\n",
      "Epoch 89/100, Loss: 1.0022\n",
      "Epoch 90/100, Loss: 1.0012\n",
      "Epoch 91/100, Loss: 1.0021\n",
      "Epoch 92/100, Loss: 1.0026\n",
      "Epoch 93/100, Loss: 1.0017\n",
      "Epoch 94/100, Loss: 1.0017\n",
      "Epoch 95/100, Loss: 1.0016\n",
      "Epoch 96/100, Loss: 1.0024\n",
      "Epoch 97/100, Loss: 1.0017\n",
      "Epoch 98/100, Loss: 1.0023\n",
      "Epoch 99/100, Loss: 1.0026\n",
      "Epoch 100/100, Loss: 1.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 201.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1149\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.2, 'mu': 0.8, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0032\n",
      "Epoch 2/100, Loss: 1.0099\n",
      "Epoch 3/100, Loss: 1.0094\n",
      "Epoch 4/100, Loss: 1.0084\n",
      "Epoch 5/100, Loss: 1.0087\n",
      "Epoch 6/100, Loss: 1.0127\n",
      "Epoch 7/100, Loss: 1.0103\n",
      "Epoch 8/100, Loss: 1.0118\n",
      "Epoch 9/100, Loss: 1.0094\n",
      "Epoch 10/100, Loss: 1.0127\n",
      "Epoch 11/100, Loss: 1.0064\n",
      "Epoch 12/100, Loss: 1.0082\n",
      "Epoch 13/100, Loss: 1.0080\n",
      "Epoch 14/100, Loss: 1.0111\n",
      "Epoch 15/100, Loss: 1.0095\n",
      "Epoch 16/100, Loss: 1.0091\n",
      "Epoch 17/100, Loss: 1.0100\n",
      "Epoch 18/100, Loss: 1.0106\n",
      "Epoch 19/100, Loss: 1.0077\n",
      "Epoch 20/100, Loss: 1.0107\n",
      "Epoch 21/100, Loss: 1.0096\n",
      "Epoch 22/100, Loss: 1.0108\n",
      "Epoch 23/100, Loss: 1.0084\n",
      "Epoch 24/100, Loss: 1.0109\n",
      "Epoch 25/100, Loss: 1.0078\n",
      "Epoch 26/100, Loss: 1.0081\n",
      "Epoch 27/100, Loss: 1.0108\n",
      "Epoch 28/100, Loss: 1.0098\n",
      "Epoch 29/100, Loss: 1.0127\n",
      "Epoch 30/100, Loss: 1.0096\n",
      "Epoch 31/100, Loss: 1.0087\n",
      "Epoch 32/100, Loss: 1.0098\n",
      "Epoch 33/100, Loss: 1.0087\n",
      "Epoch 34/100, Loss: 1.0080\n",
      "Epoch 35/100, Loss: 1.0084\n",
      "Epoch 36/100, Loss: 1.0126\n",
      "Epoch 37/100, Loss: 1.0114\n",
      "Epoch 38/100, Loss: 1.0076\n",
      "Epoch 39/100, Loss: 1.0082\n",
      "Epoch 40/100, Loss: 1.0082\n",
      "Epoch 41/100, Loss: 1.0102\n",
      "Epoch 42/100, Loss: 1.0092\n",
      "Epoch 43/100, Loss: 1.0084\n",
      "Epoch 44/100, Loss: 1.0088\n",
      "Epoch 45/100, Loss: 1.0086\n",
      "Epoch 46/100, Loss: 1.0089\n",
      "Epoch 47/100, Loss: 1.0099\n",
      "Epoch 48/100, Loss: 1.0070\n",
      "Epoch 49/100, Loss: 1.0102\n",
      "Epoch 50/100, Loss: 1.0106\n",
      "Epoch 51/100, Loss: 1.0078\n",
      "Epoch 52/100, Loss: 1.0084\n",
      "Epoch 53/100, Loss: 1.0092\n",
      "Epoch 54/100, Loss: 1.0073\n",
      "Epoch 55/100, Loss: 1.0085\n",
      "Epoch 56/100, Loss: 1.0112\n",
      "Epoch 57/100, Loss: 1.0098\n",
      "Epoch 58/100, Loss: 1.0093\n",
      "Epoch 59/100, Loss: 1.0154\n",
      "Epoch 60/100, Loss: 1.0100\n",
      "Epoch 61/100, Loss: 1.0072\n",
      "Epoch 62/100, Loss: 1.0076\n",
      "Epoch 63/100, Loss: 1.0087\n",
      "Epoch 64/100, Loss: 1.0099\n",
      "Epoch 65/100, Loss: 1.0084\n",
      "Epoch 66/100, Loss: 1.0135\n",
      "Epoch 67/100, Loss: 1.0112\n",
      "Epoch 68/100, Loss: 1.0127\n",
      "Epoch 69/100, Loss: 1.0085\n",
      "Epoch 70/100, Loss: 1.0108\n",
      "Epoch 71/100, Loss: 1.0093\n",
      "Epoch 72/100, Loss: 1.0075\n",
      "Epoch 73/100, Loss: 1.0073\n",
      "Epoch 74/100, Loss: 1.0114\n",
      "Epoch 75/100, Loss: 1.0095\n",
      "Epoch 76/100, Loss: 1.0098\n",
      "Epoch 77/100, Loss: 1.0070\n",
      "Epoch 78/100, Loss: 1.0087\n",
      "Epoch 79/100, Loss: 1.0084\n",
      "Epoch 80/100, Loss: 1.0091\n",
      "Epoch 81/100, Loss: 1.0082\n",
      "Epoch 82/100, Loss: 1.0092\n",
      "Epoch 83/100, Loss: 1.0094\n",
      "Epoch 84/100, Loss: 1.0104\n",
      "Epoch 85/100, Loss: 1.0081\n",
      "Epoch 86/100, Loss: 1.0101\n",
      "Epoch 87/100, Loss: 1.0096\n",
      "Epoch 88/100, Loss: 1.0105\n",
      "Epoch 89/100, Loss: 1.0082\n",
      "Epoch 90/100, Loss: 1.0087\n",
      "Epoch 91/100, Loss: 1.0084\n",
      "Epoch 92/100, Loss: 1.0095\n",
      "Epoch 93/100, Loss: 1.0084\n",
      "Epoch 94/100, Loss: 1.0091\n",
      "Epoch 95/100, Loss: 1.0110\n",
      "Epoch 96/100, Loss: 1.0081\n",
      "Epoch 97/100, Loss: 1.0085\n",
      "Epoch 98/100, Loss: 1.0075\n",
      "Epoch 99/100, Loss: 1.0100\n",
      "Epoch 100/100, Loss: 1.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 114.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1150\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.9065\n",
      "Epoch 2/100, Loss: 0.8192\n",
      "Epoch 3/100, Loss: 0.7687\n",
      "Epoch 4/100, Loss: 0.7553\n",
      "Epoch 5/100, Loss: 0.7467\n",
      "Epoch 6/100, Loss: 0.7294\n",
      "Epoch 7/100, Loss: 0.7467\n",
      "Epoch 8/100, Loss: 0.7459\n",
      "Epoch 9/100, Loss: 0.7295\n",
      "Epoch 10/100, Loss: 0.8614\n",
      "Epoch 11/100, Loss: 0.8223\n",
      "Epoch 12/100, Loss: 0.8121\n",
      "Epoch 13/100, Loss: 0.7968\n",
      "Epoch 14/100, Loss: 0.7816\n",
      "Epoch 15/100, Loss: 0.7296\n",
      "Epoch 16/100, Loss: 0.7190\n",
      "Epoch 17/100, Loss: 0.7201\n",
      "Epoch 18/100, Loss: 0.7363\n",
      "Epoch 19/100, Loss: 0.7650\n",
      "Epoch 20/100, Loss: 0.7474\n",
      "Epoch 21/100, Loss: 0.7336\n",
      "Epoch 22/100, Loss: 0.7246\n",
      "Epoch 23/100, Loss: 0.7212\n",
      "Epoch 24/100, Loss: 0.7294\n",
      "Epoch 25/100, Loss: 0.7209\n",
      "Epoch 26/100, Loss: 0.7204\n",
      "Epoch 27/100, Loss: 0.7149\n",
      "Epoch 28/100, Loss: 0.7249\n",
      "Epoch 29/100, Loss: 0.7351\n",
      "Epoch 30/100, Loss: 0.7136\n",
      "Epoch 31/100, Loss: 0.7185\n",
      "Epoch 32/100, Loss: 0.7158\n",
      "Epoch 33/100, Loss: 0.7178\n",
      "Epoch 34/100, Loss: 0.7144\n",
      "Epoch 35/100, Loss: 0.7110\n",
      "Epoch 36/100, Loss: 0.7159\n",
      "Epoch 37/100, Loss: 0.7433\n",
      "Epoch 38/100, Loss: 0.7344\n",
      "Epoch 39/100, Loss: 0.7208\n",
      "Epoch 40/100, Loss: 0.7502\n",
      "Epoch 41/100, Loss: 0.7415\n",
      "Epoch 42/100, Loss: 0.7337\n",
      "Epoch 43/100, Loss: 0.7383\n",
      "Epoch 44/100, Loss: 0.7186\n",
      "Epoch 45/100, Loss: 0.7191\n",
      "Epoch 46/100, Loss: 0.7571\n",
      "Epoch 47/100, Loss: 0.7429\n",
      "Epoch 48/100, Loss: 0.7140\n",
      "Epoch 49/100, Loss: 0.7484\n",
      "Epoch 50/100, Loss: 0.7408\n",
      "Epoch 51/100, Loss: 0.7609\n",
      "Epoch 52/100, Loss: 0.8334\n",
      "Epoch 53/100, Loss: 0.7410\n",
      "Epoch 54/100, Loss: 0.7245\n",
      "Epoch 55/100, Loss: 0.7191\n",
      "Epoch 56/100, Loss: 0.7174\n",
      "Epoch 57/100, Loss: 0.7202\n",
      "Epoch 58/100, Loss: 0.7277\n",
      "Epoch 59/100, Loss: 0.7428\n",
      "Epoch 60/100, Loss: 0.7278\n",
      "Epoch 61/100, Loss: 0.7191\n",
      "Epoch 62/100, Loss: 0.7174\n",
      "Epoch 63/100, Loss: 0.7465\n",
      "Epoch 64/100, Loss: 0.7457\n",
      "Epoch 65/100, Loss: 0.7246\n",
      "Epoch 66/100, Loss: 0.7111\n",
      "Epoch 67/100, Loss: 0.7068\n",
      "Epoch 68/100, Loss: 0.7129\n",
      "Epoch 69/100, Loss: 0.7038\n",
      "Epoch 70/100, Loss: 0.7037\n",
      "Epoch 71/100, Loss: 0.7043\n",
      "Epoch 72/100, Loss: 0.7047\n",
      "Epoch 73/100, Loss: 0.7103\n",
      "Epoch 74/100, Loss: 0.7102\n",
      "Epoch 75/100, Loss: 0.7097\n",
      "Epoch 76/100, Loss: 0.7109\n",
      "Epoch 77/100, Loss: 0.7104\n",
      "Epoch 78/100, Loss: 0.7092\n",
      "Epoch 79/100, Loss: 0.7093\n",
      "Epoch 80/100, Loss: 0.7125\n",
      "Epoch 81/100, Loss: 0.7119\n",
      "Epoch 82/100, Loss: 0.7138\n",
      "Epoch 83/100, Loss: 0.7108\n",
      "Epoch 84/100, Loss: 0.7107\n",
      "Epoch 85/100, Loss: 0.7099\n",
      "Epoch 86/100, Loss: 0.7097\n",
      "Epoch 87/100, Loss: 0.7095\n",
      "Epoch 88/100, Loss: 0.7103\n",
      "Epoch 89/100, Loss: 0.7142\n",
      "Epoch 90/100, Loss: 0.7119\n",
      "Epoch 91/100, Loss: 0.7100\n",
      "Epoch 92/100, Loss: 0.7101\n",
      "Epoch 93/100, Loss: 0.7102\n",
      "Epoch 94/100, Loss: 0.7108\n",
      "Epoch 95/100, Loss: 0.7095\n",
      "Epoch 96/100, Loss: 0.7118\n",
      "Epoch 97/100, Loss: 0.7110\n",
      "Epoch 98/100, Loss: 0.7098\n",
      "Epoch 99/100, Loss: 0.7103\n",
      "Epoch 100/100, Loss: 0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 89.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2035\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0083\n",
      "Epoch 2/100, Loss: 1.0022\n",
      "Epoch 3/100, Loss: 1.0020\n",
      "Epoch 4/100, Loss: 1.0018\n",
      "Epoch 5/100, Loss: 1.0017\n",
      "Epoch 6/100, Loss: 1.0020\n",
      "Epoch 7/100, Loss: 1.0018\n",
      "Epoch 8/100, Loss: 1.0015\n",
      "Epoch 9/100, Loss: 1.0020\n",
      "Epoch 10/100, Loss: 1.0012\n",
      "Epoch 11/100, Loss: 1.0019\n",
      "Epoch 12/100, Loss: 1.0017\n",
      "Epoch 13/100, Loss: 1.0014\n",
      "Epoch 14/100, Loss: 1.0016\n",
      "Epoch 15/100, Loss: 1.0017\n",
      "Epoch 16/100, Loss: 1.0015\n",
      "Epoch 17/100, Loss: 1.0013\n",
      "Epoch 18/100, Loss: 1.0016\n",
      "Epoch 19/100, Loss: 1.0020\n",
      "Epoch 20/100, Loss: 1.0015\n",
      "Epoch 21/100, Loss: 1.0017\n",
      "Epoch 22/100, Loss: 1.0019\n",
      "Epoch 23/100, Loss: 1.0013\n",
      "Epoch 24/100, Loss: 1.0011\n",
      "Epoch 25/100, Loss: 1.0015\n",
      "Epoch 26/100, Loss: 1.0021\n",
      "Epoch 27/100, Loss: 1.0026\n",
      "Epoch 28/100, Loss: 1.0029\n",
      "Epoch 29/100, Loss: 1.0019\n",
      "Epoch 30/100, Loss: 1.0022\n",
      "Epoch 31/100, Loss: 1.0014\n",
      "Epoch 32/100, Loss: 1.0025\n",
      "Epoch 33/100, Loss: 1.0017\n",
      "Epoch 34/100, Loss: 1.0022\n",
      "Epoch 35/100, Loss: 1.0016\n",
      "Epoch 36/100, Loss: 1.0020\n",
      "Epoch 37/100, Loss: 1.0020\n",
      "Epoch 38/100, Loss: 1.0020\n",
      "Epoch 39/100, Loss: 1.0031\n",
      "Epoch 40/100, Loss: 1.0026\n",
      "Epoch 41/100, Loss: 1.0026\n",
      "Epoch 42/100, Loss: 1.0020\n",
      "Epoch 43/100, Loss: 1.0021\n",
      "Epoch 44/100, Loss: 1.0014\n",
      "Epoch 45/100, Loss: 1.0022\n",
      "Epoch 46/100, Loss: 1.0024\n",
      "Epoch 47/100, Loss: 1.0013\n",
      "Epoch 48/100, Loss: 1.0021\n",
      "Epoch 49/100, Loss: 1.0019\n",
      "Epoch 50/100, Loss: 1.0019\n",
      "Epoch 51/100, Loss: 1.0019\n",
      "Epoch 52/100, Loss: 1.0020\n",
      "Epoch 53/100, Loss: 1.0024\n",
      "Epoch 54/100, Loss: 1.0025\n",
      "Epoch 55/100, Loss: 1.0024\n",
      "Epoch 56/100, Loss: 1.0021\n",
      "Epoch 57/100, Loss: 1.0019\n",
      "Epoch 58/100, Loss: 1.0020\n",
      "Epoch 59/100, Loss: 1.0025\n",
      "Epoch 60/100, Loss: 1.0028\n",
      "Epoch 61/100, Loss: 1.0019\n",
      "Epoch 62/100, Loss: 1.0027\n",
      "Epoch 63/100, Loss: 1.0026\n",
      "Epoch 64/100, Loss: 1.0014\n",
      "Epoch 65/100, Loss: 1.0012\n",
      "Epoch 66/100, Loss: 1.0021\n",
      "Epoch 67/100, Loss: 1.0012\n",
      "Epoch 68/100, Loss: 1.0029\n",
      "Epoch 69/100, Loss: 1.0018\n",
      "Epoch 70/100, Loss: 1.0016\n",
      "Epoch 71/100, Loss: 1.0024\n",
      "Epoch 72/100, Loss: 1.0019\n",
      "Epoch 73/100, Loss: 1.0020\n",
      "Epoch 74/100, Loss: 1.0020\n",
      "Epoch 75/100, Loss: 1.0021\n",
      "Epoch 76/100, Loss: 1.0017\n",
      "Epoch 77/100, Loss: 1.0016\n",
      "Epoch 78/100, Loss: 1.0026\n",
      "Epoch 79/100, Loss: 1.0016\n",
      "Epoch 80/100, Loss: 1.0028\n",
      "Epoch 81/100, Loss: 1.0022\n",
      "Epoch 82/100, Loss: 1.0020\n",
      "Epoch 83/100, Loss: 1.0019\n",
      "Epoch 84/100, Loss: 1.0021\n",
      "Epoch 85/100, Loss: 1.0017\n",
      "Epoch 86/100, Loss: 1.0019\n",
      "Epoch 87/100, Loss: 1.0016\n",
      "Epoch 88/100, Loss: 1.0021\n",
      "Epoch 89/100, Loss: 1.0021\n",
      "Epoch 90/100, Loss: 1.0018\n",
      "Epoch 91/100, Loss: 1.0014\n",
      "Epoch 92/100, Loss: 1.0018\n",
      "Epoch 93/100, Loss: 1.0015\n",
      "Epoch 94/100, Loss: 1.0023\n",
      "Epoch 95/100, Loss: 1.0018\n",
      "Epoch 96/100, Loss: 1.0023\n",
      "Epoch 97/100, Loss: 1.0021\n",
      "Epoch 98/100, Loss: 1.0022\n",
      "Epoch 99/100, Loss: 1.0022\n",
      "Epoch 100/100, Loss: 1.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 206.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1173\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0186\n",
      "Epoch 2/100, Loss: 1.0085\n",
      "Epoch 3/100, Loss: 1.0087\n",
      "Epoch 4/100, Loss: 1.0100\n",
      "Epoch 5/100, Loss: 1.0098\n",
      "Epoch 6/100, Loss: 1.0073\n",
      "Epoch 7/100, Loss: 1.0095\n",
      "Epoch 8/100, Loss: 1.0151\n",
      "Epoch 9/100, Loss: 1.0106\n",
      "Epoch 10/100, Loss: 1.0104\n",
      "Epoch 11/100, Loss: 1.0076\n",
      "Epoch 12/100, Loss: 1.0090\n",
      "Epoch 13/100, Loss: 1.0116\n",
      "Epoch 14/100, Loss: 1.0102\n",
      "Epoch 15/100, Loss: 1.0107\n",
      "Epoch 16/100, Loss: 1.0077\n",
      "Epoch 17/100, Loss: 1.0107\n",
      "Epoch 18/100, Loss: 1.0106\n",
      "Epoch 19/100, Loss: 1.0092\n",
      "Epoch 20/100, Loss: 1.0109\n",
      "Epoch 21/100, Loss: 1.0089\n",
      "Epoch 22/100, Loss: 1.0113\n",
      "Epoch 23/100, Loss: 1.0071\n",
      "Epoch 24/100, Loss: 1.0160\n",
      "Epoch 25/100, Loss: 1.0094\n",
      "Epoch 26/100, Loss: 1.0077\n",
      "Epoch 27/100, Loss: 1.0100\n",
      "Epoch 28/100, Loss: 1.0090\n",
      "Epoch 29/100, Loss: 1.0076\n",
      "Epoch 30/100, Loss: 1.0075\n",
      "Epoch 31/100, Loss: 1.0096\n",
      "Epoch 32/100, Loss: 1.0085\n",
      "Epoch 33/100, Loss: 1.0091\n",
      "Epoch 34/100, Loss: 1.0065\n",
      "Epoch 35/100, Loss: 1.0103\n",
      "Epoch 36/100, Loss: 1.0118\n",
      "Epoch 37/100, Loss: 1.0070\n",
      "Epoch 38/100, Loss: 1.0094\n",
      "Epoch 39/100, Loss: 1.0105\n",
      "Epoch 40/100, Loss: 1.0084\n",
      "Epoch 41/100, Loss: 1.0106\n",
      "Epoch 42/100, Loss: 1.0073\n",
      "Epoch 43/100, Loss: 1.0093\n",
      "Epoch 44/100, Loss: 1.0118\n",
      "Epoch 45/100, Loss: 1.0078\n",
      "Epoch 46/100, Loss: 1.0089\n",
      "Epoch 47/100, Loss: 1.0115\n",
      "Epoch 48/100, Loss: 1.0073\n",
      "Epoch 49/100, Loss: 1.0133\n",
      "Epoch 50/100, Loss: 1.0081\n",
      "Epoch 51/100, Loss: 1.0080\n",
      "Epoch 52/100, Loss: 1.0115\n",
      "Epoch 53/100, Loss: 1.0096\n",
      "Epoch 54/100, Loss: 1.0120\n",
      "Epoch 55/100, Loss: 1.0100\n",
      "Epoch 56/100, Loss: 1.0110\n",
      "Epoch 57/100, Loss: 1.0090\n",
      "Epoch 58/100, Loss: 1.0100\n",
      "Epoch 59/100, Loss: 1.0088\n",
      "Epoch 60/100, Loss: 1.0111\n",
      "Epoch 61/100, Loss: 1.0121\n",
      "Epoch 62/100, Loss: 1.0068\n",
      "Epoch 63/100, Loss: 1.0092\n",
      "Epoch 64/100, Loss: 1.0090\n",
      "Epoch 65/100, Loss: 1.0105\n",
      "Epoch 66/100, Loss: 1.0092\n",
      "Epoch 67/100, Loss: 1.0068\n",
      "Epoch 68/100, Loss: 1.0092\n",
      "Epoch 69/100, Loss: 1.0109\n",
      "Epoch 70/100, Loss: 1.0078\n",
      "Epoch 71/100, Loss: 1.0106\n",
      "Epoch 72/100, Loss: 1.0082\n",
      "Epoch 73/100, Loss: 1.0097\n",
      "Epoch 74/100, Loss: 1.0097\n",
      "Epoch 75/100, Loss: 1.0089\n",
      "Epoch 76/100, Loss: 1.0107\n",
      "Epoch 77/100, Loss: 1.0098\n",
      "Epoch 78/100, Loss: 1.0076\n",
      "Epoch 79/100, Loss: 1.0096\n",
      "Epoch 80/100, Loss: 1.0073\n",
      "Epoch 81/100, Loss: 1.0107\n",
      "Epoch 82/100, Loss: 1.0109\n",
      "Epoch 83/100, Loss: 1.0103\n",
      "Epoch 84/100, Loss: 1.0100\n",
      "Epoch 85/100, Loss: 1.0106\n",
      "Epoch 86/100, Loss: 1.0081\n",
      "Epoch 87/100, Loss: 1.0075\n",
      "Epoch 88/100, Loss: 1.0071\n",
      "Epoch 89/100, Loss: 1.0090\n",
      "Epoch 90/100, Loss: 1.0076\n",
      "Epoch 91/100, Loss: 1.0072\n",
      "Epoch 92/100, Loss: 1.0121\n",
      "Epoch 93/100, Loss: 1.0091\n",
      "Epoch 94/100, Loss: 1.0118\n",
      "Epoch 95/100, Loss: 1.0091\n",
      "Epoch 96/100, Loss: 1.0075\n",
      "Epoch 97/100, Loss: 1.0128\n",
      "Epoch 98/100, Loss: 1.0080\n",
      "Epoch 99/100, Loss: 1.0092\n",
      "Epoch 100/100, Loss: 1.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 241.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1146\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.7354\n",
      "Epoch 2/100, Loss: 0.5399\n",
      "Epoch 3/100, Loss: 0.5000\n",
      "Epoch 4/100, Loss: 0.5073\n",
      "Epoch 5/100, Loss: 0.4224\n",
      "Epoch 6/100, Loss: 0.3962\n",
      "Epoch 7/100, Loss: 0.4105\n",
      "Epoch 8/100, Loss: 0.4308\n",
      "Epoch 9/100, Loss: 0.3807\n",
      "Epoch 10/100, Loss: 0.3832\n",
      "Epoch 11/100, Loss: 0.3978\n",
      "Epoch 12/100, Loss: 0.4286\n",
      "Epoch 13/100, Loss: 0.4230\n",
      "Epoch 14/100, Loss: 0.3822\n",
      "Epoch 15/100, Loss: 0.3858\n",
      "Epoch 16/100, Loss: 0.3621\n",
      "Epoch 17/100, Loss: 0.3674\n",
      "Epoch 18/100, Loss: 0.3688\n",
      "Epoch 19/100, Loss: 0.3931\n",
      "Epoch 20/100, Loss: 0.3583\n",
      "Epoch 21/100, Loss: 0.3673\n",
      "Epoch 22/100, Loss: 0.4046\n",
      "Epoch 23/100, Loss: 0.4086\n",
      "Epoch 24/100, Loss: 0.3707\n",
      "Epoch 25/100, Loss: 0.4244\n",
      "Epoch 26/100, Loss: 0.3738\n",
      "Epoch 27/100, Loss: 0.3603\n",
      "Epoch 28/100, Loss: 0.3658\n",
      "Epoch 29/100, Loss: 0.3860\n",
      "Epoch 30/100, Loss: 0.4154\n",
      "Epoch 31/100, Loss: 0.3744\n",
      "Epoch 32/100, Loss: 0.3696\n",
      "Epoch 33/100, Loss: 0.3680\n",
      "Epoch 34/100, Loss: 0.3585\n",
      "Epoch 35/100, Loss: 0.3545\n",
      "Epoch 36/100, Loss: 0.3610\n",
      "Epoch 37/100, Loss: 0.3617\n",
      "Epoch 38/100, Loss: 0.4399\n",
      "Epoch 39/100, Loss: 0.4283\n",
      "Epoch 40/100, Loss: 0.3731\n",
      "Epoch 41/100, Loss: 0.3632\n",
      "Epoch 42/100, Loss: 0.3684\n",
      "Epoch 43/100, Loss: 0.3335\n",
      "Epoch 44/100, Loss: 0.3421\n",
      "Epoch 45/100, Loss: 0.3421\n",
      "Epoch 46/100, Loss: 0.4080\n",
      "Epoch 47/100, Loss: 0.3705\n",
      "Epoch 48/100, Loss: 0.3579\n",
      "Epoch 49/100, Loss: 0.3428\n",
      "Epoch 50/100, Loss: 0.3308\n",
      "Epoch 51/100, Loss: 0.3334\n",
      "Epoch 52/100, Loss: 0.3441\n",
      "Epoch 53/100, Loss: 0.3582\n",
      "Epoch 54/100, Loss: 0.3393\n",
      "Epoch 55/100, Loss: 0.3301\n",
      "Epoch 56/100, Loss: 0.3848\n",
      "Epoch 57/100, Loss: 0.3957\n",
      "Epoch 58/100, Loss: 0.3840\n",
      "Epoch 59/100, Loss: 0.3794\n",
      "Epoch 60/100, Loss: 0.3302\n",
      "Epoch 61/100, Loss: 0.3216\n",
      "Epoch 62/100, Loss: 0.3210\n",
      "Epoch 63/100, Loss: 0.3367\n",
      "Epoch 64/100, Loss: 0.3283\n",
      "Epoch 65/100, Loss: 0.3151\n",
      "Epoch 66/100, Loss: 0.3124\n",
      "Epoch 67/100, Loss: 0.3076\n",
      "Epoch 68/100, Loss: 0.3180\n",
      "Epoch 69/100, Loss: 0.2950\n",
      "Epoch 70/100, Loss: 0.3088\n",
      "Epoch 71/100, Loss: 0.3171\n",
      "Epoch 72/100, Loss: 0.3093\n",
      "Epoch 73/100, Loss: 0.3758\n",
      "Epoch 74/100, Loss: 0.3693\n",
      "Epoch 75/100, Loss: 0.3997\n",
      "Epoch 76/100, Loss: 0.3246\n",
      "Epoch 77/100, Loss: 0.2974\n",
      "Epoch 78/100, Loss: 0.3394\n",
      "Epoch 79/100, Loss: 0.2906\n",
      "Epoch 80/100, Loss: 0.2851\n",
      "Epoch 81/100, Loss: 0.3838\n",
      "Epoch 82/100, Loss: 0.3302\n",
      "Epoch 83/100, Loss: 0.3242\n",
      "Epoch 84/100, Loss: 0.3550\n",
      "Epoch 85/100, Loss: 0.3406\n",
      "Epoch 86/100, Loss: 0.3640\n",
      "Epoch 87/100, Loss: 0.3772\n",
      "Epoch 88/100, Loss: 0.3388\n",
      "Epoch 89/100, Loss: 0.2805\n",
      "Epoch 90/100, Loss: 0.2799\n",
      "Epoch 91/100, Loss: 0.3237\n",
      "Epoch 92/100, Loss: 0.2981\n",
      "Epoch 93/100, Loss: 0.3209\n",
      "Epoch 94/100, Loss: 0.3227\n",
      "Epoch 95/100, Loss: 0.2925\n",
      "Epoch 96/100, Loss: 0.2908\n",
      "Epoch 97/100, Loss: 0.2782\n",
      "Epoch 98/100, Loss: 0.2958\n",
      "Epoch 99/100, Loss: 0.2467\n",
      "Epoch 100/100, Loss: 0.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 118.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3311\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.7284\n",
      "Epoch 2/100, Loss: 0.6791\n",
      "Epoch 3/100, Loss: 0.6526\n",
      "Epoch 4/100, Loss: 0.6353\n",
      "Epoch 5/100, Loss: 0.6496\n",
      "Epoch 6/100, Loss: 0.6310\n",
      "Epoch 7/100, Loss: 0.6208\n",
      "Epoch 8/100, Loss: 0.6238\n",
      "Epoch 9/100, Loss: 0.6010\n",
      "Epoch 10/100, Loss: 0.6351\n",
      "Epoch 11/100, Loss: 0.7860\n",
      "Epoch 12/100, Loss: 0.7534\n",
      "Epoch 13/100, Loss: 0.7556\n",
      "Epoch 14/100, Loss: 0.7601\n",
      "Epoch 15/100, Loss: 0.8161\n",
      "Epoch 16/100, Loss: 0.7923\n",
      "Epoch 17/100, Loss: 0.7515\n",
      "Epoch 18/100, Loss: 0.7210\n",
      "Epoch 19/100, Loss: 0.7180\n",
      "Epoch 20/100, Loss: 0.7173\n",
      "Epoch 21/100, Loss: 0.7159\n",
      "Epoch 22/100, Loss: 0.7192\n",
      "Epoch 23/100, Loss: 0.7158\n",
      "Epoch 24/100, Loss: 0.7179\n",
      "Epoch 25/100, Loss: 0.7160\n",
      "Epoch 26/100, Loss: 0.7176\n",
      "Epoch 27/100, Loss: 0.7173\n",
      "Epoch 28/100, Loss: 0.7166\n",
      "Epoch 29/100, Loss: 0.7211\n",
      "Epoch 30/100, Loss: 0.7165\n",
      "Epoch 31/100, Loss: 0.7149\n",
      "Epoch 32/100, Loss: 0.7169\n",
      "Epoch 33/100, Loss: 0.7147\n",
      "Epoch 34/100, Loss: 0.7151\n",
      "Epoch 35/100, Loss: 0.7168\n",
      "Epoch 36/100, Loss: 0.7153\n",
      "Epoch 37/100, Loss: 0.7167\n",
      "Epoch 38/100, Loss: 0.7145\n",
      "Epoch 39/100, Loss: 0.7161\n",
      "Epoch 40/100, Loss: 0.7168\n",
      "Epoch 41/100, Loss: 0.7154\n",
      "Epoch 42/100, Loss: 0.7155\n",
      "Epoch 43/100, Loss: 0.7147\n",
      "Epoch 44/100, Loss: 0.7155\n",
      "Epoch 45/100, Loss: 0.7148\n",
      "Epoch 46/100, Loss: 0.7148\n",
      "Epoch 47/100, Loss: 0.7152\n",
      "Epoch 48/100, Loss: 0.7167\n",
      "Epoch 49/100, Loss: 0.7156\n",
      "Epoch 50/100, Loss: 0.7180\n",
      "Epoch 51/100, Loss: 0.7140\n",
      "Epoch 52/100, Loss: 0.7145\n",
      "Epoch 53/100, Loss: 0.7153\n",
      "Epoch 54/100, Loss: 0.7161\n",
      "Epoch 55/100, Loss: 0.7149\n",
      "Epoch 56/100, Loss: 0.7163\n",
      "Epoch 57/100, Loss: 0.7153\n",
      "Epoch 58/100, Loss: 0.7147\n",
      "Epoch 59/100, Loss: 0.7162\n",
      "Epoch 60/100, Loss: 0.7151\n",
      "Epoch 61/100, Loss: 0.7140\n",
      "Epoch 62/100, Loss: 0.7161\n",
      "Epoch 63/100, Loss: 0.7160\n",
      "Epoch 64/100, Loss: 0.7143\n",
      "Epoch 65/100, Loss: 0.7142\n",
      "Epoch 66/100, Loss: 0.7156\n",
      "Epoch 67/100, Loss: 0.7152\n",
      "Epoch 68/100, Loss: 0.7152\n",
      "Epoch 69/100, Loss: 0.7159\n",
      "Epoch 70/100, Loss: 0.7158\n",
      "Epoch 71/100, Loss: 0.7169\n",
      "Epoch 72/100, Loss: 0.7168\n",
      "Epoch 73/100, Loss: 0.7169\n",
      "Epoch 74/100, Loss: 0.7177\n",
      "Epoch 75/100, Loss: 0.7146\n",
      "Epoch 76/100, Loss: 0.7146\n",
      "Epoch 77/100, Loss: 0.7161\n",
      "Epoch 78/100, Loss: 0.7163\n",
      "Epoch 79/100, Loss: 0.7180\n",
      "Epoch 80/100, Loss: 0.7182\n",
      "Epoch 81/100, Loss: 0.7160\n",
      "Epoch 82/100, Loss: 0.7149\n",
      "Epoch 83/100, Loss: 0.7150\n",
      "Epoch 84/100, Loss: 0.7149\n",
      "Epoch 85/100, Loss: 0.7163\n",
      "Epoch 86/100, Loss: 0.7164\n",
      "Epoch 87/100, Loss: 0.7191\n",
      "Epoch 88/100, Loss: 0.7154\n",
      "Epoch 89/100, Loss: 0.7180\n",
      "Epoch 90/100, Loss: 0.7145\n",
      "Epoch 91/100, Loss: 0.7151\n",
      "Epoch 92/100, Loss: 0.7145\n",
      "Epoch 93/100, Loss: 0.7155\n",
      "Epoch 94/100, Loss: 0.7167\n",
      "Epoch 95/100, Loss: 0.7159\n",
      "Epoch 96/100, Loss: 0.7172\n",
      "Epoch 97/100, Loss: 0.7153\n",
      "Epoch 98/100, Loss: 0.7150\n",
      "Epoch 99/100, Loss: 0.7186\n",
      "Epoch 100/100, Loss: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 151.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1997\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0130\n",
      "Epoch 2/100, Loss: 1.0091\n",
      "Epoch 3/100, Loss: 1.0103\n",
      "Epoch 4/100, Loss: 1.0101\n",
      "Epoch 5/100, Loss: 1.0107\n",
      "Epoch 6/100, Loss: 1.0095\n",
      "Epoch 7/100, Loss: 1.0089\n",
      "Epoch 8/100, Loss: 1.0102\n",
      "Epoch 9/100, Loss: 1.0101\n",
      "Epoch 10/100, Loss: 1.0105\n",
      "Epoch 11/100, Loss: 1.0113\n",
      "Epoch 12/100, Loss: 1.0071\n",
      "Epoch 13/100, Loss: 1.0077\n",
      "Epoch 14/100, Loss: 1.0104\n",
      "Epoch 15/100, Loss: 1.0077\n",
      "Epoch 16/100, Loss: 1.0083\n",
      "Epoch 17/100, Loss: 1.0088\n",
      "Epoch 18/100, Loss: 1.0102\n",
      "Epoch 19/100, Loss: 1.0082\n",
      "Epoch 20/100, Loss: 1.0082\n",
      "Epoch 21/100, Loss: 1.0087\n",
      "Epoch 22/100, Loss: 1.0095\n",
      "Epoch 23/100, Loss: 1.0095\n",
      "Epoch 24/100, Loss: 1.0108\n",
      "Epoch 25/100, Loss: 1.0101\n",
      "Epoch 26/100, Loss: 1.0115\n",
      "Epoch 27/100, Loss: 1.0087\n",
      "Epoch 28/100, Loss: 1.0097\n",
      "Epoch 29/100, Loss: 1.0095\n",
      "Epoch 30/100, Loss: 1.0092\n",
      "Epoch 31/100, Loss: 1.0076\n",
      "Epoch 32/100, Loss: 1.0084\n",
      "Epoch 33/100, Loss: 1.0076\n",
      "Epoch 34/100, Loss: 1.0075\n",
      "Epoch 35/100, Loss: 1.0143\n",
      "Epoch 36/100, Loss: 1.0069\n",
      "Epoch 37/100, Loss: 1.0070\n",
      "Epoch 38/100, Loss: 1.0151\n",
      "Epoch 39/100, Loss: 1.0097\n",
      "Epoch 40/100, Loss: 1.0080\n",
      "Epoch 41/100, Loss: 1.0087\n",
      "Epoch 42/100, Loss: 1.0090\n",
      "Epoch 43/100, Loss: 1.0079\n",
      "Epoch 44/100, Loss: 1.0089\n",
      "Epoch 45/100, Loss: 1.0107\n",
      "Epoch 46/100, Loss: 1.0118\n",
      "Epoch 47/100, Loss: 1.0115\n",
      "Epoch 48/100, Loss: 1.0111\n",
      "Epoch 49/100, Loss: 1.0096\n",
      "Epoch 50/100, Loss: 1.0078\n",
      "Epoch 51/100, Loss: 1.0093\n",
      "Epoch 52/100, Loss: 1.0070\n",
      "Epoch 53/100, Loss: 1.0102\n",
      "Epoch 54/100, Loss: 1.0055\n",
      "Epoch 55/100, Loss: 1.0081\n",
      "Epoch 56/100, Loss: 1.0087\n",
      "Epoch 57/100, Loss: 1.0104\n",
      "Epoch 58/100, Loss: 1.0117\n",
      "Epoch 59/100, Loss: 1.0137\n",
      "Epoch 60/100, Loss: 1.0074\n",
      "Epoch 61/100, Loss: 1.0095\n",
      "Epoch 62/100, Loss: 1.0101\n",
      "Epoch 63/100, Loss: 1.0085\n",
      "Epoch 64/100, Loss: 1.0103\n",
      "Epoch 65/100, Loss: 1.0123\n",
      "Epoch 66/100, Loss: 1.0110\n",
      "Epoch 67/100, Loss: 1.0092\n",
      "Epoch 68/100, Loss: 1.0093\n",
      "Epoch 69/100, Loss: 1.0097\n",
      "Epoch 70/100, Loss: 1.0101\n",
      "Epoch 71/100, Loss: 1.0106\n",
      "Epoch 72/100, Loss: 1.0092\n",
      "Epoch 73/100, Loss: 1.0104\n",
      "Epoch 74/100, Loss: 1.0090\n",
      "Epoch 75/100, Loss: 1.0091\n",
      "Epoch 76/100, Loss: 1.0079\n",
      "Epoch 77/100, Loss: 1.0069\n",
      "Epoch 78/100, Loss: 1.0109\n",
      "Epoch 79/100, Loss: 1.0091\n",
      "Epoch 80/100, Loss: 1.0102\n",
      "Epoch 81/100, Loss: 1.0084\n",
      "Epoch 82/100, Loss: 1.0096\n",
      "Epoch 83/100, Loss: 1.0080\n",
      "Epoch 84/100, Loss: 1.0111\n",
      "Epoch 85/100, Loss: 1.0115\n",
      "Epoch 86/100, Loss: 1.0123\n",
      "Epoch 87/100, Loss: 1.0104\n",
      "Epoch 88/100, Loss: 1.0070\n",
      "Epoch 89/100, Loss: 1.0087\n",
      "Epoch 90/100, Loss: 1.0082\n",
      "Epoch 91/100, Loss: 1.0074\n",
      "Epoch 92/100, Loss: 1.0088\n",
      "Epoch 93/100, Loss: 1.0096\n",
      "Epoch 94/100, Loss: 1.0088\n",
      "Epoch 95/100, Loss: 1.0102\n",
      "Epoch 96/100, Loss: 1.0080\n",
      "Epoch 97/100, Loss: 1.0098\n",
      "Epoch 98/100, Loss: 1.0069\n",
      "Epoch 99/100, Loss: 1.0087\n",
      "Epoch 100/100, Loss: 1.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 133.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1109\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.9991\n",
      "Epoch 2/100, Loss: 1.0009\n",
      "Epoch 3/100, Loss: 1.0009\n",
      "Epoch 4/100, Loss: 1.0009\n",
      "Epoch 5/100, Loss: 1.0009\n",
      "Epoch 6/100, Loss: 1.0009\n",
      "Epoch 7/100, Loss: 1.0012\n",
      "Epoch 8/100, Loss: 1.0014\n",
      "Epoch 9/100, Loss: 1.0007\n",
      "Epoch 10/100, Loss: 1.0008\n",
      "Epoch 11/100, Loss: 1.0007\n",
      "Epoch 12/100, Loss: 1.0007\n",
      "Epoch 13/100, Loss: 1.0012\n",
      "Epoch 14/100, Loss: 1.0010\n",
      "Epoch 15/100, Loss: 1.0005\n",
      "Epoch 16/100, Loss: 1.0011\n",
      "Epoch 17/100, Loss: 1.0012\n",
      "Epoch 18/100, Loss: 1.0008\n",
      "Epoch 19/100, Loss: 1.0006\n",
      "Epoch 20/100, Loss: 1.0007\n",
      "Epoch 21/100, Loss: 1.0013\n",
      "Epoch 22/100, Loss: 1.0008\n",
      "Epoch 23/100, Loss: 1.0008\n",
      "Epoch 24/100, Loss: 1.0011\n",
      "Epoch 25/100, Loss: 1.0013\n",
      "Epoch 26/100, Loss: 1.0010\n",
      "Epoch 27/100, Loss: 1.0004\n",
      "Epoch 28/100, Loss: 1.0014\n",
      "Epoch 29/100, Loss: 1.0009\n",
      "Epoch 30/100, Loss: 1.0007\n",
      "Epoch 31/100, Loss: 1.0008\n",
      "Epoch 32/100, Loss: 1.0009\n",
      "Epoch 33/100, Loss: 1.0008\n",
      "Epoch 34/100, Loss: 1.0008\n",
      "Epoch 35/100, Loss: 1.0012\n",
      "Epoch 36/100, Loss: 1.0009\n",
      "Epoch 37/100, Loss: 1.0005\n",
      "Epoch 38/100, Loss: 1.0017\n",
      "Epoch 39/100, Loss: 1.0010\n",
      "Epoch 40/100, Loss: 1.0008\n",
      "Epoch 41/100, Loss: 1.0008\n",
      "Epoch 42/100, Loss: 1.0010\n",
      "Epoch 43/100, Loss: 1.0008\n",
      "Epoch 44/100, Loss: 1.0009\n",
      "Epoch 45/100, Loss: 1.0014\n",
      "Epoch 46/100, Loss: 1.0007\n",
      "Epoch 47/100, Loss: 1.0008\n",
      "Epoch 48/100, Loss: 1.0008\n",
      "Epoch 49/100, Loss: 1.0011\n",
      "Epoch 50/100, Loss: 1.0011\n",
      "Epoch 51/100, Loss: 1.0005\n",
      "Epoch 52/100, Loss: 1.0009\n",
      "Epoch 53/100, Loss: 1.0009\n",
      "Epoch 54/100, Loss: 1.0012\n",
      "Epoch 55/100, Loss: 1.0006\n",
      "Epoch 56/100, Loss: 1.0010\n",
      "Epoch 57/100, Loss: 1.0010\n",
      "Epoch 58/100, Loss: 1.0005\n",
      "Epoch 59/100, Loss: 0.9997\n",
      "Epoch 60/100, Loss: 1.0010\n",
      "Epoch 61/100, Loss: 1.0008\n",
      "Epoch 62/100, Loss: 1.0015\n",
      "Epoch 63/100, Loss: 1.0008\n",
      "Epoch 64/100, Loss: 1.0009\n",
      "Epoch 65/100, Loss: 1.0007\n",
      "Epoch 66/100, Loss: 1.0009\n",
      "Epoch 67/100, Loss: 1.0012\n",
      "Epoch 68/100, Loss: 1.0009\n",
      "Epoch 69/100, Loss: 1.0010\n",
      "Epoch 70/100, Loss: 1.0012\n",
      "Epoch 71/100, Loss: 1.0009\n",
      "Epoch 72/100, Loss: 1.0012\n",
      "Epoch 73/100, Loss: 1.0007\n",
      "Epoch 74/100, Loss: 1.0011\n",
      "Epoch 75/100, Loss: 1.0003\n",
      "Epoch 76/100, Loss: 1.0013\n",
      "Epoch 77/100, Loss: 1.0010\n",
      "Epoch 78/100, Loss: 1.0007\n",
      "Epoch 79/100, Loss: 1.0010\n",
      "Epoch 80/100, Loss: 1.0008\n",
      "Epoch 81/100, Loss: 1.0008\n",
      "Epoch 82/100, Loss: 1.0008\n",
      "Epoch 83/100, Loss: 1.0005\n",
      "Epoch 84/100, Loss: 1.0009\n",
      "Epoch 85/100, Loss: 1.0008\n",
      "Epoch 86/100, Loss: 1.0006\n",
      "Epoch 87/100, Loss: 1.0013\n",
      "Epoch 88/100, Loss: 1.0012\n",
      "Epoch 89/100, Loss: 1.0013\n",
      "Epoch 90/100, Loss: 1.0009\n",
      "Epoch 91/100, Loss: 1.0012\n",
      "Epoch 92/100, Loss: 1.0006\n",
      "Epoch 93/100, Loss: 1.0010\n",
      "Epoch 94/100, Loss: 1.0011\n",
      "Epoch 95/100, Loss: 1.0007\n",
      "Epoch 96/100, Loss: 1.0010\n",
      "Epoch 97/100, Loss: 1.0009\n",
      "Epoch 98/100, Loss: 1.0009\n",
      "Epoch 99/100, Loss: 1.0006\n",
      "Epoch 100/100, Loss: 1.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 183.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1191\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 0.8667\n",
      "Epoch 2/100, Loss: 0.8050\n",
      "Epoch 3/100, Loss: 0.6500\n",
      "Epoch 4/100, Loss: 0.4472\n",
      "Epoch 5/100, Loss: 0.4593\n",
      "Epoch 6/100, Loss: 0.4670\n",
      "Epoch 7/100, Loss: 0.4509\n",
      "Epoch 8/100, Loss: 0.4357\n",
      "Epoch 9/100, Loss: 0.4286\n",
      "Epoch 10/100, Loss: 0.4364\n",
      "Epoch 11/100, Loss: 0.4263\n",
      "Epoch 12/100, Loss: 0.4382\n",
      "Epoch 13/100, Loss: 0.4144\n",
      "Epoch 14/100, Loss: 0.4339\n",
      "Epoch 15/100, Loss: 0.4595\n",
      "Epoch 16/100, Loss: 0.5500\n",
      "Epoch 17/100, Loss: 0.5330\n",
      "Epoch 18/100, Loss: 0.4956\n",
      "Epoch 19/100, Loss: 0.4438\n",
      "Epoch 20/100, Loss: 0.4352\n",
      "Epoch 21/100, Loss: 0.4130\n",
      "Epoch 22/100, Loss: 0.4313\n",
      "Epoch 23/100, Loss: 0.3994\n",
      "Epoch 24/100, Loss: 0.4757\n",
      "Epoch 25/100, Loss: 0.4417\n",
      "Epoch 26/100, Loss: 0.4521\n",
      "Epoch 27/100, Loss: 0.4334\n",
      "Epoch 28/100, Loss: 0.4196\n",
      "Epoch 29/100, Loss: 0.4210\n",
      "Epoch 30/100, Loss: 0.7146\n",
      "Epoch 31/100, Loss: 0.7685\n",
      "Epoch 32/100, Loss: 0.7974\n",
      "Epoch 33/100, Loss: 0.8568\n",
      "Epoch 34/100, Loss: 0.7372\n",
      "Epoch 35/100, Loss: 0.9278\n",
      "Epoch 36/100, Loss: 0.4827\n",
      "Epoch 37/100, Loss: 0.4328\n",
      "Epoch 38/100, Loss: 0.7918\n",
      "Epoch 39/100, Loss: 0.5712\n",
      "Epoch 40/100, Loss: 0.5662\n",
      "Epoch 41/100, Loss: 0.5794\n",
      "Epoch 42/100, Loss: 0.5819\n",
      "Epoch 43/100, Loss: 0.5624\n",
      "Epoch 44/100, Loss: 0.6080\n",
      "Epoch 45/100, Loss: 0.5302\n",
      "Epoch 46/100, Loss: 0.5254\n",
      "Epoch 47/100, Loss: 0.5225\n",
      "Epoch 48/100, Loss: 0.5231\n",
      "Epoch 49/100, Loss: 0.5221\n",
      "Epoch 50/100, Loss: 0.5246\n",
      "Epoch 51/100, Loss: 0.5209\n",
      "Epoch 52/100, Loss: 0.5224\n",
      "Epoch 53/100, Loss: 0.5253\n",
      "Epoch 54/100, Loss: 0.5222\n",
      "Epoch 55/100, Loss: 0.5247\n",
      "Epoch 56/100, Loss: 0.5234\n",
      "Epoch 57/100, Loss: 0.5239\n",
      "Epoch 58/100, Loss: 0.5205\n",
      "Epoch 59/100, Loss: 0.5241\n",
      "Epoch 60/100, Loss: 0.4466\n",
      "Epoch 61/100, Loss: 0.4213\n",
      "Epoch 62/100, Loss: 0.4082\n",
      "Epoch 63/100, Loss: 0.4041\n",
      "Epoch 64/100, Loss: 0.4032\n",
      "Epoch 65/100, Loss: 0.4013\n",
      "Epoch 66/100, Loss: 0.4039\n",
      "Epoch 67/100, Loss: 0.4014\n",
      "Epoch 68/100, Loss: 0.4015\n",
      "Epoch 69/100, Loss: 0.4013\n",
      "Epoch 70/100, Loss: 0.4053\n",
      "Epoch 71/100, Loss: 0.4009\n",
      "Epoch 72/100, Loss: 0.4004\n",
      "Epoch 73/100, Loss: 0.4025\n",
      "Epoch 74/100, Loss: 0.4009\n",
      "Epoch 75/100, Loss: 0.4012\n",
      "Epoch 76/100, Loss: 0.4009\n",
      "Epoch 77/100, Loss: 0.3999\n",
      "Epoch 78/100, Loss: 0.4001\n",
      "Epoch 79/100, Loss: 0.4009\n",
      "Epoch 80/100, Loss: 0.3990\n",
      "Epoch 81/100, Loss: 0.4021\n",
      "Epoch 82/100, Loss: 0.4007\n",
      "Epoch 83/100, Loss: 0.3994\n",
      "Epoch 84/100, Loss: 0.3988\n",
      "Epoch 85/100, Loss: 0.4022\n",
      "Epoch 86/100, Loss: 0.4005\n",
      "Epoch 87/100, Loss: 0.4018\n",
      "Epoch 88/100, Loss: 0.3995\n",
      "Epoch 89/100, Loss: 0.4012\n",
      "Epoch 90/100, Loss: 0.4027\n",
      "Epoch 91/100, Loss: 0.4012\n",
      "Epoch 92/100, Loss: 0.3991\n",
      "Epoch 93/100, Loss: 0.4004\n",
      "Epoch 94/100, Loss: 0.4013\n",
      "Epoch 95/100, Loss: 0.3991\n",
      "Epoch 96/100, Loss: 0.3996\n",
      "Epoch 97/100, Loss: 0.3999\n",
      "Epoch 98/100, Loss: 0.3987\n",
      "Epoch 99/100, Loss: 0.4021\n",
      "Epoch 100/100, Loss: 0.3982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 223.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2051\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0091\n",
      "Epoch 2/100, Loss: 1.0086\n",
      "Epoch 3/100, Loss: 1.0111\n",
      "Epoch 4/100, Loss: 1.0082\n",
      "Epoch 5/100, Loss: 1.0093\n",
      "Epoch 6/100, Loss: 1.0100\n",
      "Epoch 7/100, Loss: 1.0092\n",
      "Epoch 8/100, Loss: 1.0100\n",
      "Epoch 9/100, Loss: 1.0081\n",
      "Epoch 10/100, Loss: 1.0106\n",
      "Epoch 11/100, Loss: 1.0098\n",
      "Epoch 12/100, Loss: 1.0106\n",
      "Epoch 13/100, Loss: 1.0094\n",
      "Epoch 14/100, Loss: 1.0103\n",
      "Epoch 15/100, Loss: 1.0070\n",
      "Epoch 16/100, Loss: 1.0076\n",
      "Epoch 17/100, Loss: 1.0085\n",
      "Epoch 18/100, Loss: 1.0098\n",
      "Epoch 19/100, Loss: 1.0085\n",
      "Epoch 20/100, Loss: 1.0139\n",
      "Epoch 21/100, Loss: 1.0087\n",
      "Epoch 22/100, Loss: 1.0104\n",
      "Epoch 23/100, Loss: 1.0075\n",
      "Epoch 24/100, Loss: 1.0105\n",
      "Epoch 25/100, Loss: 1.0075\n",
      "Epoch 26/100, Loss: 1.0070\n",
      "Epoch 27/100, Loss: 1.0101\n",
      "Epoch 28/100, Loss: 1.0134\n",
      "Epoch 29/100, Loss: 1.0084\n",
      "Epoch 30/100, Loss: 1.0110\n",
      "Epoch 31/100, Loss: 1.0146\n",
      "Epoch 32/100, Loss: 1.0090\n",
      "Epoch 33/100, Loss: 1.0111\n",
      "Epoch 34/100, Loss: 1.0098\n",
      "Epoch 35/100, Loss: 1.0108\n",
      "Epoch 36/100, Loss: 1.0118\n",
      "Epoch 37/100, Loss: 1.0099\n",
      "Epoch 38/100, Loss: 1.0101\n",
      "Epoch 39/100, Loss: 1.0087\n",
      "Epoch 40/100, Loss: 1.0085\n",
      "Epoch 41/100, Loss: 1.0090\n",
      "Epoch 42/100, Loss: 1.0096\n",
      "Epoch 43/100, Loss: 1.0148\n",
      "Epoch 44/100, Loss: 1.0114\n",
      "Epoch 45/100, Loss: 1.0084\n",
      "Epoch 46/100, Loss: 1.0092\n",
      "Epoch 47/100, Loss: 1.0081\n",
      "Epoch 48/100, Loss: 1.0115\n",
      "Epoch 49/100, Loss: 1.0071\n",
      "Epoch 50/100, Loss: 1.0090\n",
      "Epoch 51/100, Loss: 1.0103\n",
      "Epoch 52/100, Loss: 1.0103\n",
      "Epoch 53/100, Loss: 1.0100\n",
      "Epoch 54/100, Loss: 1.0077\n",
      "Epoch 55/100, Loss: 1.0096\n",
      "Epoch 56/100, Loss: 1.0062\n",
      "Epoch 57/100, Loss: 1.0094\n",
      "Epoch 58/100, Loss: 1.0109\n",
      "Epoch 59/100, Loss: 1.0101\n",
      "Epoch 60/100, Loss: 1.0093\n",
      "Epoch 61/100, Loss: 1.0089\n",
      "Epoch 62/100, Loss: 1.0083\n",
      "Epoch 63/100, Loss: 1.0106\n",
      "Epoch 64/100, Loss: 1.0086\n",
      "Epoch 65/100, Loss: 1.0099\n",
      "Epoch 66/100, Loss: 1.0090\n",
      "Epoch 67/100, Loss: 1.0112\n",
      "Epoch 68/100, Loss: 1.0091\n",
      "Epoch 69/100, Loss: 1.0095\n",
      "Epoch 70/100, Loss: 1.0083\n",
      "Epoch 71/100, Loss: 1.0081\n",
      "Epoch 72/100, Loss: 1.0123\n",
      "Epoch 73/100, Loss: 1.0075\n",
      "Epoch 74/100, Loss: 1.0082\n",
      "Epoch 75/100, Loss: 1.0096\n",
      "Epoch 76/100, Loss: 1.0120\n",
      "Epoch 77/100, Loss: 1.0104\n",
      "Epoch 78/100, Loss: 1.0101\n",
      "Epoch 79/100, Loss: 1.0105\n",
      "Epoch 80/100, Loss: 1.0113\n",
      "Epoch 81/100, Loss: 1.0093\n",
      "Epoch 82/100, Loss: 1.0085\n",
      "Epoch 83/100, Loss: 1.0101\n",
      "Epoch 84/100, Loss: 1.0071\n",
      "Epoch 85/100, Loss: 1.0095\n",
      "Epoch 86/100, Loss: 1.0092\n",
      "Epoch 87/100, Loss: 1.0077\n",
      "Epoch 88/100, Loss: 1.0098\n",
      "Epoch 89/100, Loss: 1.0085\n",
      "Epoch 90/100, Loss: 1.0069\n",
      "Epoch 91/100, Loss: 1.0099\n",
      "Epoch 92/100, Loss: 1.0097\n",
      "Epoch 93/100, Loss: 1.0115\n",
      "Epoch 94/100, Loss: 1.0113\n",
      "Epoch 95/100, Loss: 1.0089\n",
      "Epoch 96/100, Loss: 1.0082\n",
      "Epoch 97/100, Loss: 1.0119\n",
      "Epoch 98/100, Loss: 1.0104\n",
      "Epoch 99/100, Loss: 1.0081\n",
      "Epoch 100/100, Loss: 1.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 177.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1117\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.9756\n",
      "Epoch 2/100, Loss: 0.9281\n",
      "Epoch 3/100, Loss: 0.8954\n",
      "Epoch 4/100, Loss: 0.8981\n",
      "Epoch 5/100, Loss: 0.8393\n",
      "Epoch 6/100, Loss: 0.8482\n",
      "Epoch 7/100, Loss: 0.8161\n",
      "Epoch 8/100, Loss: 0.8057\n",
      "Epoch 9/100, Loss: 0.8159\n",
      "Epoch 10/100, Loss: 0.8311\n",
      "Epoch 11/100, Loss: 0.8224\n",
      "Epoch 12/100, Loss: 0.8017\n",
      "Epoch 13/100, Loss: 0.8623\n",
      "Epoch 14/100, Loss: 0.8034\n",
      "Epoch 15/100, Loss: 0.8097\n",
      "Epoch 16/100, Loss: 0.7863\n",
      "Epoch 17/100, Loss: 0.7852\n",
      "Epoch 18/100, Loss: 0.7879\n",
      "Epoch 19/100, Loss: 0.7832\n",
      "Epoch 20/100, Loss: 0.7827\n",
      "Epoch 21/100, Loss: 0.7864\n",
      "Epoch 22/100, Loss: 0.8268\n",
      "Epoch 23/100, Loss: 0.7783\n",
      "Epoch 24/100, Loss: 0.7675\n",
      "Epoch 25/100, Loss: 0.7763\n",
      "Epoch 26/100, Loss: 0.7735\n",
      "Epoch 27/100, Loss: 0.8005\n",
      "Epoch 28/100, Loss: 0.7673\n",
      "Epoch 29/100, Loss: 0.7660\n",
      "Epoch 30/100, Loss: 0.7629\n",
      "Epoch 31/100, Loss: 0.7637\n",
      "Epoch 32/100, Loss: 0.7805\n",
      "Epoch 33/100, Loss: 0.7593\n",
      "Epoch 34/100, Loss: 0.8256\n",
      "Epoch 35/100, Loss: 0.7979\n",
      "Epoch 36/100, Loss: 0.7741\n",
      "Epoch 37/100, Loss: 0.8728\n",
      "Epoch 38/100, Loss: 0.8362\n",
      "Epoch 39/100, Loss: 0.7875\n",
      "Epoch 40/100, Loss: 0.7673\n",
      "Epoch 41/100, Loss: 0.7674\n",
      "Epoch 42/100, Loss: 0.8155\n",
      "Epoch 43/100, Loss: 0.7851\n",
      "Epoch 44/100, Loss: 0.7744\n",
      "Epoch 45/100, Loss: 0.7603\n",
      "Epoch 46/100, Loss: 0.7587\n",
      "Epoch 47/100, Loss: 0.7585\n",
      "Epoch 48/100, Loss: 0.7604\n",
      "Epoch 49/100, Loss: 0.7580\n",
      "Epoch 50/100, Loss: 0.7580\n",
      "Epoch 51/100, Loss: 0.7583\n",
      "Epoch 52/100, Loss: 0.7586\n",
      "Epoch 53/100, Loss: 0.7593\n",
      "Epoch 54/100, Loss: 0.7579\n",
      "Epoch 55/100, Loss: 0.7585\n",
      "Epoch 56/100, Loss: 0.7596\n",
      "Epoch 57/100, Loss: 0.7583\n",
      "Epoch 58/100, Loss: 0.7573\n",
      "Epoch 59/100, Loss: 0.7599\n",
      "Epoch 60/100, Loss: 0.7576\n",
      "Epoch 61/100, Loss: 0.7618\n",
      "Epoch 62/100, Loss: 0.7577\n",
      "Epoch 63/100, Loss: 0.7580\n",
      "Epoch 64/100, Loss: 0.7598\n",
      "Epoch 65/100, Loss: 0.7585\n",
      "Epoch 66/100, Loss: 0.7619\n",
      "Epoch 67/100, Loss: 0.7596\n",
      "Epoch 68/100, Loss: 0.7577\n",
      "Epoch 69/100, Loss: 0.7585\n",
      "Epoch 70/100, Loss: 0.7582\n",
      "Epoch 71/100, Loss: 0.7579\n",
      "Epoch 72/100, Loss: 0.7599\n",
      "Epoch 73/100, Loss: 0.7574\n",
      "Epoch 74/100, Loss: 0.7583\n",
      "Epoch 75/100, Loss: 0.7570\n",
      "Epoch 76/100, Loss: 0.7576\n",
      "Epoch 77/100, Loss: 0.7602\n",
      "Epoch 78/100, Loss: 0.7580\n",
      "Epoch 79/100, Loss: 0.7593\n",
      "Epoch 80/100, Loss: 0.7582\n",
      "Epoch 81/100, Loss: 0.7583\n",
      "Epoch 82/100, Loss: 0.7578\n",
      "Epoch 83/100, Loss: 0.7579\n",
      "Epoch 84/100, Loss: 0.7578\n",
      "Epoch 85/100, Loss: 0.7575\n",
      "Epoch 86/100, Loss: 0.7580\n",
      "Epoch 87/100, Loss: 0.7596\n",
      "Epoch 88/100, Loss: 0.7595\n",
      "Epoch 89/100, Loss: 0.7582\n",
      "Epoch 90/100, Loss: 0.7581\n",
      "Epoch 91/100, Loss: 0.7602\n",
      "Epoch 92/100, Loss: 0.7584\n",
      "Epoch 93/100, Loss: 0.7603\n",
      "Epoch 94/100, Loss: 0.7582\n",
      "Epoch 95/100, Loss: 0.7580\n",
      "Epoch 96/100, Loss: 0.7584\n",
      "Epoch 97/100, Loss: 0.7602\n",
      "Epoch 98/100, Loss: 0.7579\n",
      "Epoch 99/100, Loss: 0.7597\n",
      "Epoch 100/100, Loss: 0.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 269.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1994\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0140\n",
      "Epoch 2/100, Loss: 1.0023\n",
      "Epoch 3/100, Loss: 1.0015\n",
      "Epoch 4/100, Loss: 1.0023\n",
      "Epoch 5/100, Loss: 1.0029\n",
      "Epoch 6/100, Loss: 1.0019\n",
      "Epoch 7/100, Loss: 1.0024\n",
      "Epoch 8/100, Loss: 1.0029\n",
      "Epoch 9/100, Loss: 1.0015\n",
      "Epoch 10/100, Loss: 1.0027\n",
      "Epoch 11/100, Loss: 1.0027\n",
      "Epoch 12/100, Loss: 1.0026\n",
      "Epoch 13/100, Loss: 1.0012\n",
      "Epoch 14/100, Loss: 1.0020\n",
      "Epoch 15/100, Loss: 1.0017\n",
      "Epoch 16/100, Loss: 1.0020\n",
      "Epoch 17/100, Loss: 1.0021\n",
      "Epoch 18/100, Loss: 1.0015\n",
      "Epoch 19/100, Loss: 1.0022\n",
      "Epoch 20/100, Loss: 1.0018\n",
      "Epoch 21/100, Loss: 1.0019\n",
      "Epoch 22/100, Loss: 1.0018\n",
      "Epoch 23/100, Loss: 1.0024\n",
      "Epoch 24/100, Loss: 1.0017\n",
      "Epoch 25/100, Loss: 1.0018\n",
      "Epoch 26/100, Loss: 1.0019\n",
      "Epoch 27/100, Loss: 1.0031\n",
      "Epoch 28/100, Loss: 1.0017\n",
      "Epoch 29/100, Loss: 1.0021\n",
      "Epoch 30/100, Loss: 1.0017\n",
      "Epoch 31/100, Loss: 1.0016\n",
      "Epoch 32/100, Loss: 1.0018\n",
      "Epoch 33/100, Loss: 1.0020\n",
      "Epoch 34/100, Loss: 1.0024\n",
      "Epoch 35/100, Loss: 1.0026\n",
      "Epoch 36/100, Loss: 1.0017\n",
      "Epoch 37/100, Loss: 1.0021\n",
      "Epoch 38/100, Loss: 1.0023\n",
      "Epoch 39/100, Loss: 1.0017\n",
      "Epoch 40/100, Loss: 1.0029\n",
      "Epoch 41/100, Loss: 1.0013\n",
      "Epoch 42/100, Loss: 1.0025\n",
      "Epoch 43/100, Loss: 1.0018\n",
      "Epoch 44/100, Loss: 1.0019\n",
      "Epoch 45/100, Loss: 1.0016\n",
      "Epoch 46/100, Loss: 1.0017\n",
      "Epoch 47/100, Loss: 1.0014\n",
      "Epoch 48/100, Loss: 1.0030\n",
      "Epoch 49/100, Loss: 1.0016\n",
      "Epoch 50/100, Loss: 1.0014\n",
      "Epoch 51/100, Loss: 1.0017\n",
      "Epoch 52/100, Loss: 1.0018\n",
      "Epoch 53/100, Loss: 1.0019\n",
      "Epoch 54/100, Loss: 1.0018\n",
      "Epoch 55/100, Loss: 1.0022\n",
      "Epoch 56/100, Loss: 1.0011\n",
      "Epoch 57/100, Loss: 1.0026\n",
      "Epoch 58/100, Loss: 1.0020\n",
      "Epoch 59/100, Loss: 1.0017\n",
      "Epoch 60/100, Loss: 1.0014\n",
      "Epoch 61/100, Loss: 1.0037\n",
      "Epoch 62/100, Loss: 1.0028\n",
      "Epoch 63/100, Loss: 1.0025\n",
      "Epoch 64/100, Loss: 1.0023\n",
      "Epoch 65/100, Loss: 1.0020\n",
      "Epoch 66/100, Loss: 1.0017\n",
      "Epoch 67/100, Loss: 1.0024\n",
      "Epoch 68/100, Loss: 1.0026\n",
      "Epoch 69/100, Loss: 1.0016\n",
      "Epoch 70/100, Loss: 1.0021\n",
      "Epoch 71/100, Loss: 1.0013\n",
      "Epoch 72/100, Loss: 1.0013\n",
      "Epoch 73/100, Loss: 1.0026\n",
      "Epoch 74/100, Loss: 1.0021\n",
      "Epoch 75/100, Loss: 1.0020\n",
      "Epoch 76/100, Loss: 1.0017\n",
      "Epoch 77/100, Loss: 1.0019\n",
      "Epoch 78/100, Loss: 1.0031\n",
      "Epoch 79/100, Loss: 1.0019\n",
      "Epoch 80/100, Loss: 1.0022\n",
      "Epoch 81/100, Loss: 1.0014\n",
      "Epoch 82/100, Loss: 1.0017\n",
      "Epoch 83/100, Loss: 1.0018\n",
      "Epoch 84/100, Loss: 1.0019\n",
      "Epoch 85/100, Loss: 1.0025\n",
      "Epoch 86/100, Loss: 1.0023\n",
      "Epoch 87/100, Loss: 1.0024\n",
      "Epoch 88/100, Loss: 1.0021\n",
      "Epoch 89/100, Loss: 1.0016\n",
      "Epoch 90/100, Loss: 1.0031\n",
      "Epoch 91/100, Loss: 1.0017\n",
      "Epoch 92/100, Loss: 1.0015\n",
      "Epoch 93/100, Loss: 1.0017\n",
      "Epoch 94/100, Loss: 1.0019\n",
      "Epoch 95/100, Loss: 1.0016\n",
      "Epoch 96/100, Loss: 1.0019\n",
      "Epoch 97/100, Loss: 1.0023\n",
      "Epoch 98/100, Loss: 1.0020\n",
      "Epoch 99/100, Loss: 1.0021\n",
      "Epoch 100/100, Loss: 1.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 279.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1250\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0199\n",
      "Epoch 2/100, Loss: 1.0081\n",
      "Epoch 3/100, Loss: 1.0091\n",
      "Epoch 4/100, Loss: 1.0092\n",
      "Epoch 5/100, Loss: 1.0063\n",
      "Epoch 6/100, Loss: 1.0100\n",
      "Epoch 7/100, Loss: 1.0109\n",
      "Epoch 8/100, Loss: 1.0073\n",
      "Epoch 9/100, Loss: 1.0100\n",
      "Epoch 10/100, Loss: 1.0101\n",
      "Epoch 11/100, Loss: 1.0101\n",
      "Epoch 12/100, Loss: 1.0084\n",
      "Epoch 13/100, Loss: 1.0098\n",
      "Epoch 14/100, Loss: 1.0074\n",
      "Epoch 15/100, Loss: 1.0118\n",
      "Epoch 16/100, Loss: 1.0099\n",
      "Epoch 17/100, Loss: 1.0084\n",
      "Epoch 18/100, Loss: 1.0083\n",
      "Epoch 19/100, Loss: 1.0096\n",
      "Epoch 20/100, Loss: 1.0068\n",
      "Epoch 21/100, Loss: 1.0139\n",
      "Epoch 22/100, Loss: 1.0097\n",
      "Epoch 23/100, Loss: 1.0122\n",
      "Epoch 24/100, Loss: 1.0070\n",
      "Epoch 25/100, Loss: 1.0092\n",
      "Epoch 26/100, Loss: 1.0103\n",
      "Epoch 27/100, Loss: 1.0092\n",
      "Epoch 28/100, Loss: 1.0095\n",
      "Epoch 29/100, Loss: 1.0087\n",
      "Epoch 30/100, Loss: 1.0081\n",
      "Epoch 31/100, Loss: 1.0078\n",
      "Epoch 32/100, Loss: 1.0058\n",
      "Epoch 33/100, Loss: 1.0089\n",
      "Epoch 34/100, Loss: 1.0078\n",
      "Epoch 35/100, Loss: 1.0092\n",
      "Epoch 36/100, Loss: 1.0122\n",
      "Epoch 37/100, Loss: 1.0112\n",
      "Epoch 38/100, Loss: 1.0136\n",
      "Epoch 39/100, Loss: 1.0076\n",
      "Epoch 40/100, Loss: 1.0086\n",
      "Epoch 41/100, Loss: 1.0069\n",
      "Epoch 42/100, Loss: 1.0100\n",
      "Epoch 43/100, Loss: 1.0103\n",
      "Epoch 44/100, Loss: 1.0104\n",
      "Epoch 45/100, Loss: 1.0078\n",
      "Epoch 46/100, Loss: 1.0077\n",
      "Epoch 47/100, Loss: 1.0090\n",
      "Epoch 48/100, Loss: 1.0103\n",
      "Epoch 49/100, Loss: 1.0089\n",
      "Epoch 50/100, Loss: 1.0087\n",
      "Epoch 51/100, Loss: 1.0073\n",
      "Epoch 52/100, Loss: 1.0110\n",
      "Epoch 53/100, Loss: 1.0088\n",
      "Epoch 54/100, Loss: 1.0097\n",
      "Epoch 55/100, Loss: 1.0083\n",
      "Epoch 56/100, Loss: 1.0096\n",
      "Epoch 57/100, Loss: 1.0067\n",
      "Epoch 58/100, Loss: 1.0090\n",
      "Epoch 59/100, Loss: 1.0082\n",
      "Epoch 60/100, Loss: 1.0082\n",
      "Epoch 61/100, Loss: 1.0080\n",
      "Epoch 62/100, Loss: 1.0107\n",
      "Epoch 63/100, Loss: 1.0100\n",
      "Epoch 64/100, Loss: 1.0061\n",
      "Epoch 65/100, Loss: 1.0100\n",
      "Epoch 66/100, Loss: 1.0134\n",
      "Epoch 67/100, Loss: 1.0077\n",
      "Epoch 68/100, Loss: 1.0144\n",
      "Epoch 69/100, Loss: 1.0084\n",
      "Epoch 70/100, Loss: 1.0102\n",
      "Epoch 71/100, Loss: 1.0065\n",
      "Epoch 72/100, Loss: 1.0127\n",
      "Epoch 73/100, Loss: 1.0118\n",
      "Epoch 74/100, Loss: 1.0091\n",
      "Epoch 75/100, Loss: 1.0112\n",
      "Epoch 76/100, Loss: 1.0114\n",
      "Epoch 77/100, Loss: 1.0115\n",
      "Epoch 78/100, Loss: 1.0081\n",
      "Epoch 79/100, Loss: 1.0104\n",
      "Epoch 80/100, Loss: 1.0129\n",
      "Epoch 81/100, Loss: 1.0095\n",
      "Epoch 82/100, Loss: 1.0107\n",
      "Epoch 83/100, Loss: 1.0132\n",
      "Epoch 84/100, Loss: 1.0113\n",
      "Epoch 85/100, Loss: 1.0066\n",
      "Epoch 86/100, Loss: 1.0085\n",
      "Epoch 87/100, Loss: 1.0093\n",
      "Epoch 88/100, Loss: 1.0073\n",
      "Epoch 89/100, Loss: 1.0073\n",
      "Epoch 90/100, Loss: 1.0097\n",
      "Epoch 91/100, Loss: 1.0074\n",
      "Epoch 92/100, Loss: 1.0084\n",
      "Epoch 93/100, Loss: 1.0131\n",
      "Epoch 94/100, Loss: 1.0093\n",
      "Epoch 95/100, Loss: 1.0096\n",
      "Epoch 96/100, Loss: 1.0101\n",
      "Epoch 97/100, Loss: 1.0069\n",
      "Epoch 98/100, Loss: 1.0103\n",
      "Epoch 99/100, Loss: 1.0089\n",
      "Epoch 100/100, Loss: 1.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 105.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1146\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.7558\n",
      "Epoch 2/100, Loss: 0.6573\n",
      "Epoch 3/100, Loss: 0.5676\n",
      "Epoch 4/100, Loss: 0.5325\n",
      "Epoch 5/100, Loss: 0.5171\n",
      "Epoch 6/100, Loss: 0.5287\n",
      "Epoch 7/100, Loss: 0.5271\n",
      "Epoch 8/100, Loss: 0.5292\n",
      "Epoch 9/100, Loss: 0.5255\n",
      "Epoch 10/100, Loss: 0.5340\n",
      "Epoch 11/100, Loss: 0.4958\n",
      "Epoch 12/100, Loss: 0.4975\n",
      "Epoch 13/100, Loss: 0.5082\n",
      "Epoch 14/100, Loss: 0.5002\n",
      "Epoch 15/100, Loss: 0.4987\n",
      "Epoch 16/100, Loss: 0.5050\n",
      "Epoch 17/100, Loss: 0.5020\n",
      "Epoch 18/100, Loss: 0.5014\n",
      "Epoch 19/100, Loss: 0.5140\n",
      "Epoch 20/100, Loss: 0.5402\n",
      "Epoch 21/100, Loss: 0.5229\n",
      "Epoch 22/100, Loss: 0.5222\n",
      "Epoch 23/100, Loss: 0.5204\n",
      "Epoch 24/100, Loss: 0.5215\n",
      "Epoch 25/100, Loss: 0.5247\n",
      "Epoch 26/100, Loss: 0.5145\n",
      "Epoch 27/100, Loss: 0.4908\n",
      "Epoch 28/100, Loss: 0.4932\n",
      "Epoch 29/100, Loss: 0.5018\n",
      "Epoch 30/100, Loss: 0.4893\n",
      "Epoch 31/100, Loss: 0.4999\n",
      "Epoch 32/100, Loss: 0.5117\n",
      "Epoch 33/100, Loss: 0.4968\n",
      "Epoch 34/100, Loss: 0.5306\n",
      "Epoch 35/100, Loss: 0.5029\n",
      "Epoch 36/100, Loss: 0.4914\n",
      "Epoch 37/100, Loss: 0.5428\n",
      "Epoch 38/100, Loss: 0.4817\n",
      "Epoch 39/100, Loss: 0.5159\n",
      "Epoch 40/100, Loss: 0.4936\n",
      "Epoch 41/100, Loss: 0.4834\n",
      "Epoch 42/100, Loss: 0.5211\n",
      "Epoch 43/100, Loss: 0.4971\n",
      "Epoch 44/100, Loss: 0.5043\n",
      "Epoch 45/100, Loss: 0.4915\n",
      "Epoch 46/100, Loss: 0.5139\n",
      "Epoch 47/100, Loss: 0.5266\n",
      "Epoch 48/100, Loss: 0.4910\n",
      "Epoch 49/100, Loss: 0.5210\n",
      "Epoch 50/100, Loss: 0.4934\n",
      "Epoch 51/100, Loss: 0.5351\n",
      "Epoch 52/100, Loss: 0.5090\n",
      "Epoch 53/100, Loss: 0.4897\n",
      "Epoch 54/100, Loss: 0.5047\n",
      "Epoch 55/100, Loss: 0.4992\n",
      "Epoch 56/100, Loss: 0.4974\n",
      "Epoch 57/100, Loss: 0.5481\n",
      "Epoch 58/100, Loss: 0.5043\n",
      "Epoch 59/100, Loss: 0.4984\n",
      "Epoch 60/100, Loss: 0.5010\n",
      "Epoch 61/100, Loss: 0.5185\n",
      "Epoch 62/100, Loss: 0.5004\n",
      "Epoch 63/100, Loss: 0.5062\n",
      "Epoch 64/100, Loss: 0.4839\n",
      "Epoch 65/100, Loss: 0.4931\n",
      "Epoch 66/100, Loss: 0.4923\n",
      "Epoch 67/100, Loss: 0.4814\n",
      "Epoch 68/100, Loss: 0.4802\n",
      "Epoch 69/100, Loss: 0.4857\n",
      "Epoch 70/100, Loss: 0.5040\n",
      "Epoch 71/100, Loss: 0.5079\n",
      "Epoch 72/100, Loss: 0.4836\n",
      "Epoch 73/100, Loss: 0.4874\n",
      "Epoch 74/100, Loss: 0.4816\n",
      "Epoch 75/100, Loss: 0.4819\n",
      "Epoch 76/100, Loss: 0.4781\n",
      "Epoch 77/100, Loss: 0.4782\n",
      "Epoch 78/100, Loss: 0.4822\n",
      "Epoch 79/100, Loss: 0.4769\n",
      "Epoch 80/100, Loss: 0.4754\n",
      "Epoch 81/100, Loss: 0.4749\n",
      "Epoch 82/100, Loss: 0.4730\n",
      "Epoch 83/100, Loss: 0.4684\n",
      "Epoch 84/100, Loss: 0.4710\n",
      "Epoch 85/100, Loss: 0.4699\n",
      "Epoch 86/100, Loss: 0.4619\n",
      "Epoch 87/100, Loss: 0.5848\n",
      "Epoch 88/100, Loss: 0.5233\n",
      "Epoch 89/100, Loss: 0.4884\n",
      "Epoch 90/100, Loss: 0.4805\n",
      "Epoch 91/100, Loss: 0.4769\n",
      "Epoch 92/100, Loss: 0.4797\n",
      "Epoch 93/100, Loss: 0.4730\n",
      "Epoch 94/100, Loss: 0.4556\n",
      "Epoch 95/100, Loss: 0.4488\n",
      "Epoch 96/100, Loss: 0.4486\n",
      "Epoch 97/100, Loss: 0.4571\n",
      "Epoch 98/100, Loss: 0.4489\n",
      "Epoch 99/100, Loss: 0.4567\n",
      "Epoch 100/100, Loss: 0.4371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 177.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.2427\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.6, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0059\n",
      "Epoch 2/100, Loss: 1.0020\n",
      "Epoch 3/100, Loss: 1.0017\n",
      "Epoch 4/100, Loss: 1.0027\n",
      "Epoch 5/100, Loss: 1.0022\n",
      "Epoch 6/100, Loss: 1.0024\n",
      "Epoch 7/100, Loss: 1.0016\n",
      "Epoch 8/100, Loss: 1.0015\n",
      "Epoch 9/100, Loss: 1.0026\n",
      "Epoch 10/100, Loss: 1.0024\n",
      "Epoch 11/100, Loss: 1.0021\n",
      "Epoch 12/100, Loss: 1.0027\n",
      "Epoch 13/100, Loss: 1.0016\n",
      "Epoch 14/100, Loss: 1.0015\n",
      "Epoch 15/100, Loss: 1.0021\n",
      "Epoch 16/100, Loss: 1.0018\n",
      "Epoch 17/100, Loss: 1.0018\n",
      "Epoch 18/100, Loss: 1.0022\n",
      "Epoch 19/100, Loss: 1.0021\n",
      "Epoch 20/100, Loss: 1.0017\n",
      "Epoch 21/100, Loss: 1.0022\n",
      "Epoch 22/100, Loss: 1.0029\n",
      "Epoch 23/100, Loss: 1.0023\n",
      "Epoch 24/100, Loss: 1.0031\n",
      "Epoch 25/100, Loss: 1.0020\n",
      "Epoch 26/100, Loss: 1.0019\n",
      "Epoch 27/100, Loss: 1.0016\n",
      "Epoch 28/100, Loss: 1.0024\n",
      "Epoch 29/100, Loss: 1.0023\n",
      "Epoch 30/100, Loss: 1.0019\n",
      "Epoch 31/100, Loss: 1.0025\n",
      "Epoch 32/100, Loss: 1.0022\n",
      "Epoch 33/100, Loss: 1.0023\n",
      "Epoch 34/100, Loss: 1.0016\n",
      "Epoch 35/100, Loss: 1.0017\n",
      "Epoch 36/100, Loss: 1.0022\n",
      "Epoch 37/100, Loss: 1.0018\n",
      "Epoch 38/100, Loss: 1.0016\n",
      "Epoch 39/100, Loss: 1.0017\n",
      "Epoch 40/100, Loss: 1.0017\n",
      "Epoch 41/100, Loss: 1.0025\n",
      "Epoch 42/100, Loss: 1.0015\n",
      "Epoch 43/100, Loss: 1.0018\n",
      "Epoch 44/100, Loss: 1.0031\n",
      "Epoch 45/100, Loss: 1.0018\n",
      "Epoch 46/100, Loss: 1.0021\n",
      "Epoch 47/100, Loss: 1.0023\n",
      "Epoch 48/100, Loss: 1.0023\n",
      "Epoch 49/100, Loss: 1.0022\n",
      "Epoch 50/100, Loss: 1.0024\n",
      "Epoch 51/100, Loss: 1.0016\n",
      "Epoch 52/100, Loss: 1.0021\n",
      "Epoch 53/100, Loss: 1.0009\n",
      "Epoch 54/100, Loss: 1.0023\n",
      "Epoch 55/100, Loss: 1.0018\n",
      "Epoch 56/100, Loss: 1.0018\n",
      "Epoch 57/100, Loss: 1.0020\n",
      "Epoch 58/100, Loss: 1.0025\n",
      "Epoch 59/100, Loss: 1.0015\n",
      "Epoch 60/100, Loss: 1.0016\n",
      "Epoch 61/100, Loss: 1.0023\n",
      "Epoch 62/100, Loss: 1.0021\n",
      "Epoch 63/100, Loss: 1.0021\n",
      "Epoch 64/100, Loss: 1.0020\n",
      "Epoch 65/100, Loss: 1.0014\n",
      "Epoch 66/100, Loss: 1.0012\n",
      "Epoch 67/100, Loss: 1.0017\n",
      "Epoch 68/100, Loss: 1.0022\n",
      "Epoch 69/100, Loss: 1.0027\n",
      "Epoch 70/100, Loss: 1.0026\n",
      "Epoch 71/100, Loss: 1.0018\n",
      "Epoch 72/100, Loss: 1.0019\n",
      "Epoch 73/100, Loss: 1.0018\n",
      "Epoch 74/100, Loss: 1.0019\n",
      "Epoch 75/100, Loss: 1.0019\n",
      "Epoch 76/100, Loss: 1.0024\n",
      "Epoch 77/100, Loss: 1.0029\n",
      "Epoch 78/100, Loss: 1.0022\n",
      "Epoch 79/100, Loss: 1.0020\n",
      "Epoch 80/100, Loss: 1.0022\n",
      "Epoch 81/100, Loss: 1.0014\n",
      "Epoch 82/100, Loss: 1.0020\n",
      "Epoch 83/100, Loss: 1.0013\n",
      "Epoch 84/100, Loss: 1.0018\n",
      "Epoch 85/100, Loss: 1.0017\n",
      "Epoch 86/100, Loss: 1.0018\n",
      "Epoch 87/100, Loss: 1.0014\n",
      "Epoch 88/100, Loss: 1.0023\n",
      "Epoch 89/100, Loss: 1.0020\n",
      "Epoch 90/100, Loss: 1.0021\n",
      "Epoch 91/100, Loss: 1.0020\n",
      "Epoch 92/100, Loss: 1.0024\n",
      "Epoch 93/100, Loss: 1.0024\n",
      "Epoch 94/100, Loss: 1.0017\n",
      "Epoch 95/100, Loss: 1.0025\n",
      "Epoch 96/100, Loss: 1.0020\n",
      "Epoch 97/100, Loss: 1.0023\n",
      "Epoch 98/100, Loss: 1.0015\n",
      "Epoch 99/100, Loss: 1.0011\n",
      "Epoch 100/100, Loss: 1.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 160.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1279\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.6, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0145\n",
      "Epoch 2/100, Loss: 1.0094\n",
      "Epoch 3/100, Loss: 1.0092\n",
      "Epoch 4/100, Loss: 1.0134\n",
      "Epoch 5/100, Loss: 1.0105\n",
      "Epoch 6/100, Loss: 1.0109\n",
      "Epoch 7/100, Loss: 1.0079\n",
      "Epoch 8/100, Loss: 1.0098\n",
      "Epoch 9/100, Loss: 1.0093\n",
      "Epoch 10/100, Loss: 1.0118\n",
      "Epoch 11/100, Loss: 1.0099\n",
      "Epoch 12/100, Loss: 1.0145\n",
      "Epoch 13/100, Loss: 1.0087\n",
      "Epoch 14/100, Loss: 1.0078\n",
      "Epoch 15/100, Loss: 1.0090\n",
      "Epoch 16/100, Loss: 1.0108\n",
      "Epoch 17/100, Loss: 1.0103\n",
      "Epoch 18/100, Loss: 1.0086\n",
      "Epoch 19/100, Loss: 1.0097\n",
      "Epoch 20/100, Loss: 1.0101\n",
      "Epoch 21/100, Loss: 1.0095\n",
      "Epoch 22/100, Loss: 1.0083\n",
      "Epoch 23/100, Loss: 1.0101\n",
      "Epoch 24/100, Loss: 1.0085\n",
      "Epoch 25/100, Loss: 1.0093\n",
      "Epoch 26/100, Loss: 1.0074\n",
      "Epoch 27/100, Loss: 1.0121\n",
      "Epoch 28/100, Loss: 1.0114\n",
      "Epoch 29/100, Loss: 1.0069\n",
      "Epoch 30/100, Loss: 1.0090\n",
      "Epoch 31/100, Loss: 1.0092\n",
      "Epoch 32/100, Loss: 1.0096\n",
      "Epoch 33/100, Loss: 1.0117\n",
      "Epoch 34/100, Loss: 1.0089\n",
      "Epoch 35/100, Loss: 1.0078\n",
      "Epoch 36/100, Loss: 1.0081\n",
      "Epoch 37/100, Loss: 1.0090\n",
      "Epoch 38/100, Loss: 1.0123\n",
      "Epoch 39/100, Loss: 1.0122\n",
      "Epoch 40/100, Loss: 1.0089\n",
      "Epoch 41/100, Loss: 1.0081\n",
      "Epoch 42/100, Loss: 1.0108\n",
      "Epoch 43/100, Loss: 1.0088\n",
      "Epoch 44/100, Loss: 1.0120\n",
      "Epoch 45/100, Loss: 1.0096\n",
      "Epoch 46/100, Loss: 1.0122\n",
      "Epoch 47/100, Loss: 1.0057\n",
      "Epoch 48/100, Loss: 1.0084\n",
      "Epoch 49/100, Loss: 1.0126\n",
      "Epoch 50/100, Loss: 1.0072\n",
      "Epoch 51/100, Loss: 1.0103\n",
      "Epoch 52/100, Loss: 1.0118\n",
      "Epoch 53/100, Loss: 1.0092\n",
      "Epoch 54/100, Loss: 1.0064\n",
      "Epoch 55/100, Loss: 1.0075\n",
      "Epoch 56/100, Loss: 1.0115\n",
      "Epoch 57/100, Loss: 1.0085\n",
      "Epoch 58/100, Loss: 1.0095\n",
      "Epoch 59/100, Loss: 1.0086\n",
      "Epoch 60/100, Loss: 1.0103\n",
      "Epoch 61/100, Loss: 1.0096\n",
      "Epoch 62/100, Loss: 1.0086\n",
      "Epoch 63/100, Loss: 1.0099\n",
      "Epoch 64/100, Loss: 1.0072\n",
      "Epoch 65/100, Loss: 1.0104\n",
      "Epoch 66/100, Loss: 1.0092\n",
      "Epoch 67/100, Loss: 1.0102\n",
      "Epoch 68/100, Loss: 1.0100\n",
      "Epoch 69/100, Loss: 1.0114\n",
      "Epoch 70/100, Loss: 1.0083\n",
      "Epoch 71/100, Loss: 1.0128\n",
      "Epoch 72/100, Loss: 1.0081\n",
      "Epoch 73/100, Loss: 1.0070\n",
      "Epoch 74/100, Loss: 1.0096\n",
      "Epoch 75/100, Loss: 1.0119\n",
      "Epoch 76/100, Loss: 1.0092\n",
      "Epoch 77/100, Loss: 1.0074\n",
      "Epoch 78/100, Loss: 1.0118\n",
      "Epoch 79/100, Loss: 1.0099\n",
      "Epoch 80/100, Loss: 1.0115\n",
      "Epoch 81/100, Loss: 1.0075\n",
      "Epoch 82/100, Loss: 1.0109\n",
      "Epoch 83/100, Loss: 1.0126\n",
      "Epoch 84/100, Loss: 1.0082\n",
      "Epoch 85/100, Loss: 1.0086\n",
      "Epoch 86/100, Loss: 1.0104\n",
      "Epoch 87/100, Loss: 1.0155\n",
      "Epoch 88/100, Loss: 1.0093\n",
      "Epoch 89/100, Loss: 1.0104\n",
      "Epoch 90/100, Loss: 1.0083\n",
      "Epoch 91/100, Loss: 1.0082\n",
      "Epoch 92/100, Loss: 1.0103\n",
      "Epoch 93/100, Loss: 1.0081\n",
      "Epoch 94/100, Loss: 1.0107\n",
      "Epoch 95/100, Loss: 1.0097\n",
      "Epoch 96/100, Loss: 1.0098\n",
      "Epoch 97/100, Loss: 1.0089\n",
      "Epoch 98/100, Loss: 1.0136\n",
      "Epoch 99/100, Loss: 1.0092\n",
      "Epoch 100/100, Loss: 1.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 176.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1120\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.8, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.4248\n",
      "Epoch 2/100, Loss: 0.2505\n",
      "Epoch 3/100, Loss: 0.2341\n",
      "Epoch 4/100, Loss: 0.2094\n",
      "Epoch 5/100, Loss: 0.2266\n",
      "Epoch 6/100, Loss: 0.2142\n",
      "Epoch 7/100, Loss: 0.1992\n",
      "Epoch 8/100, Loss: 0.2112\n",
      "Epoch 9/100, Loss: 0.1741\n",
      "Epoch 10/100, Loss: 0.1604\n",
      "Epoch 11/100, Loss: 0.1592\n",
      "Epoch 12/100, Loss: 0.1635\n",
      "Epoch 13/100, Loss: 0.1450\n",
      "Epoch 14/100, Loss: 0.2030\n",
      "Epoch 15/100, Loss: 0.1863\n",
      "Epoch 16/100, Loss: 0.1973\n",
      "Epoch 17/100, Loss: 0.1653\n",
      "Epoch 18/100, Loss: 0.1401\n",
      "Epoch 19/100, Loss: 0.1139\n",
      "Epoch 20/100, Loss: 0.1229\n",
      "Epoch 21/100, Loss: 0.1456\n",
      "Epoch 22/100, Loss: 0.1594\n",
      "Epoch 23/100, Loss: 0.2323\n",
      "Epoch 24/100, Loss: 0.1775\n",
      "Epoch 25/100, Loss: 0.1514\n",
      "Epoch 26/100, Loss: 0.1270\n",
      "Epoch 27/100, Loss: 0.1060\n",
      "Epoch 28/100, Loss: 0.1519\n",
      "Epoch 29/100, Loss: 0.0958\n",
      "Epoch 30/100, Loss: 0.1101\n",
      "Epoch 31/100, Loss: 0.1516\n",
      "Epoch 32/100, Loss: 0.1131\n",
      "Epoch 33/100, Loss: 0.1012\n",
      "Epoch 34/100, Loss: 0.1076\n",
      "Epoch 35/100, Loss: 0.1621\n",
      "Epoch 36/100, Loss: 0.1003\n",
      "Epoch 37/100, Loss: 0.0852\n",
      "Epoch 38/100, Loss: 0.0928\n",
      "Epoch 39/100, Loss: 0.2076\n",
      "Epoch 40/100, Loss: 0.0629\n",
      "Epoch 41/100, Loss: 0.0658\n",
      "Epoch 42/100, Loss: 0.1287\n",
      "Epoch 43/100, Loss: 0.1091\n",
      "Epoch 44/100, Loss: 0.0892\n",
      "Epoch 45/100, Loss: 0.1329\n",
      "Epoch 46/100, Loss: 0.1134\n",
      "Epoch 47/100, Loss: 0.1030\n",
      "Epoch 48/100, Loss: 0.0770\n",
      "Epoch 49/100, Loss: 0.1068\n",
      "Epoch 50/100, Loss: 0.0935\n",
      "Epoch 51/100, Loss: 0.0812\n",
      "Epoch 52/100, Loss: 0.0725\n",
      "Epoch 53/100, Loss: 0.0514\n",
      "Epoch 54/100, Loss: 0.0394\n",
      "Epoch 55/100, Loss: 0.0841\n",
      "Epoch 56/100, Loss: 0.0944\n",
      "Epoch 57/100, Loss: 0.1667\n",
      "Epoch 58/100, Loss: 0.2098\n",
      "Epoch 59/100, Loss: 0.1532\n",
      "Epoch 60/100, Loss: 0.1546\n",
      "Epoch 61/100, Loss: 0.0972\n",
      "Epoch 62/100, Loss: 0.0956\n",
      "Epoch 63/100, Loss: 0.0875\n",
      "Epoch 64/100, Loss: 0.0698\n",
      "Epoch 65/100, Loss: 0.0459\n",
      "Epoch 66/100, Loss: 0.0426\n",
      "Epoch 67/100, Loss: 0.0911\n",
      "Epoch 68/100, Loss: 0.0905\n",
      "Epoch 69/100, Loss: 0.1112\n",
      "Epoch 70/100, Loss: 0.0938\n",
      "Epoch 71/100, Loss: 0.0713\n",
      "Epoch 72/100, Loss: 0.0709\n",
      "Epoch 73/100, Loss: 0.0647\n",
      "Epoch 74/100, Loss: 0.0699\n",
      "Epoch 75/100, Loss: 0.0501\n",
      "Epoch 76/100, Loss: 0.0466\n",
      "Epoch 77/100, Loss: 0.0652\n",
      "Epoch 78/100, Loss: 0.1194\n",
      "Epoch 79/100, Loss: 0.0793\n",
      "Epoch 80/100, Loss: 0.0542\n",
      "Epoch 81/100, Loss: 0.0587\n",
      "Epoch 82/100, Loss: 0.0645\n",
      "Epoch 83/100, Loss: 0.1146\n",
      "Epoch 84/100, Loss: 0.1158\n",
      "Epoch 85/100, Loss: 0.0935\n",
      "Epoch 86/100, Loss: 0.0580\n",
      "Epoch 87/100, Loss: 0.0373\n",
      "Epoch 88/100, Loss: 0.0639\n",
      "Epoch 89/100, Loss: 0.0601\n",
      "Epoch 90/100, Loss: 0.0515\n",
      "Epoch 91/100, Loss: 0.0861\n",
      "Epoch 92/100, Loss: 0.0715\n",
      "Epoch 93/100, Loss: 0.0764\n",
      "Epoch 94/100, Loss: 0.0669\n",
      "Epoch 95/100, Loss: 0.0674\n",
      "Epoch 96/100, Loss: 0.0806\n",
      "Epoch 97/100, Loss: 0.0497\n",
      "Epoch 98/100, Loss: 0.0362\n",
      "Epoch 99/100, Loss: 0.0404\n",
      "Epoch 100/100, Loss: -0.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 175.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3796\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.8, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0021\n",
      "Epoch 2/100, Loss: 1.0022\n",
      "Epoch 3/100, Loss: 1.0016\n",
      "Epoch 4/100, Loss: 1.0019\n",
      "Epoch 5/100, Loss: 1.0020\n",
      "Epoch 6/100, Loss: 1.0021\n",
      "Epoch 7/100, Loss: 1.0023\n",
      "Epoch 8/100, Loss: 1.0018\n",
      "Epoch 9/100, Loss: 1.0019\n",
      "Epoch 10/100, Loss: 1.0029\n",
      "Epoch 11/100, Loss: 1.0014\n",
      "Epoch 12/100, Loss: 1.0014\n",
      "Epoch 13/100, Loss: 1.0019\n",
      "Epoch 14/100, Loss: 1.0022\n",
      "Epoch 15/100, Loss: 1.0022\n",
      "Epoch 16/100, Loss: 1.0028\n",
      "Epoch 17/100, Loss: 1.0018\n",
      "Epoch 18/100, Loss: 1.0021\n",
      "Epoch 19/100, Loss: 1.0019\n",
      "Epoch 20/100, Loss: 1.0028\n",
      "Epoch 21/100, Loss: 1.0021\n",
      "Epoch 22/100, Loss: 1.0014\n",
      "Epoch 23/100, Loss: 1.0017\n",
      "Epoch 24/100, Loss: 1.0024\n",
      "Epoch 25/100, Loss: 1.0019\n",
      "Epoch 26/100, Loss: 1.0022\n",
      "Epoch 27/100, Loss: 1.0018\n",
      "Epoch 28/100, Loss: 1.0013\n",
      "Epoch 29/100, Loss: 1.0021\n",
      "Epoch 30/100, Loss: 1.0012\n",
      "Epoch 31/100, Loss: 1.0027\n",
      "Epoch 32/100, Loss: 1.0018\n",
      "Epoch 33/100, Loss: 1.0020\n",
      "Epoch 34/100, Loss: 1.0023\n",
      "Epoch 35/100, Loss: 1.0026\n",
      "Epoch 36/100, Loss: 1.0021\n",
      "Epoch 37/100, Loss: 1.0014\n",
      "Epoch 38/100, Loss: 1.0014\n",
      "Epoch 39/100, Loss: 1.0024\n",
      "Epoch 40/100, Loss: 1.0018\n",
      "Epoch 41/100, Loss: 1.0022\n",
      "Epoch 42/100, Loss: 1.0024\n",
      "Epoch 43/100, Loss: 1.0014\n",
      "Epoch 44/100, Loss: 1.0022\n",
      "Epoch 45/100, Loss: 1.0012\n",
      "Epoch 46/100, Loss: 1.0019\n",
      "Epoch 47/100, Loss: 1.0017\n",
      "Epoch 48/100, Loss: 1.0032\n",
      "Epoch 49/100, Loss: 1.0018\n",
      "Epoch 50/100, Loss: 1.0021\n",
      "Epoch 51/100, Loss: 1.0025\n",
      "Epoch 52/100, Loss: 1.0009\n",
      "Epoch 53/100, Loss: 1.0033\n",
      "Epoch 54/100, Loss: 1.0024\n",
      "Epoch 55/100, Loss: 1.0017\n",
      "Epoch 56/100, Loss: 1.0019\n",
      "Epoch 57/100, Loss: 1.0025\n",
      "Epoch 58/100, Loss: 1.0022\n",
      "Epoch 59/100, Loss: 1.0019\n",
      "Epoch 60/100, Loss: 1.0027\n",
      "Epoch 61/100, Loss: 1.0020\n",
      "Epoch 62/100, Loss: 1.0016\n",
      "Epoch 63/100, Loss: 1.0018\n",
      "Epoch 64/100, Loss: 1.0014\n",
      "Epoch 65/100, Loss: 1.0014\n",
      "Epoch 66/100, Loss: 1.0019\n",
      "Epoch 67/100, Loss: 1.0012\n",
      "Epoch 68/100, Loss: 1.0026\n",
      "Epoch 69/100, Loss: 1.0015\n",
      "Epoch 70/100, Loss: 1.0021\n",
      "Epoch 71/100, Loss: 1.0020\n",
      "Epoch 72/100, Loss: 1.0015\n",
      "Epoch 73/100, Loss: 1.0018\n",
      "Epoch 74/100, Loss: 1.0021\n",
      "Epoch 75/100, Loss: 1.0015\n",
      "Epoch 76/100, Loss: 1.0022\n",
      "Epoch 77/100, Loss: 1.0020\n",
      "Epoch 78/100, Loss: 1.0018\n",
      "Epoch 79/100, Loss: 1.0014\n",
      "Epoch 80/100, Loss: 1.0024\n",
      "Epoch 81/100, Loss: 1.0019\n",
      "Epoch 82/100, Loss: 1.0022\n",
      "Epoch 83/100, Loss: 1.0021\n",
      "Epoch 84/100, Loss: 1.0014\n",
      "Epoch 85/100, Loss: 1.0030\n",
      "Epoch 86/100, Loss: 1.0016\n",
      "Epoch 87/100, Loss: 1.0020\n",
      "Epoch 88/100, Loss: 1.0017\n",
      "Epoch 89/100, Loss: 1.0013\n",
      "Epoch 90/100, Loss: 1.0014\n",
      "Epoch 91/100, Loss: 1.0017\n",
      "Epoch 92/100, Loss: 1.0016\n",
      "Epoch 93/100, Loss: 1.0016\n",
      "Epoch 94/100, Loss: 1.0015\n",
      "Epoch 95/100, Loss: 1.0022\n",
      "Epoch 96/100, Loss: 1.0017\n",
      "Epoch 97/100, Loss: 1.0017\n",
      "Epoch 98/100, Loss: 1.0015\n",
      "Epoch 99/100, Loss: 1.0021\n",
      "Epoch 100/100, Loss: 1.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 134.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1151\n",
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 4, 'gamma': 0.8, 'mu': 0.8, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0069\n",
      "Epoch 2/100, Loss: 1.0084\n",
      "Epoch 3/100, Loss: 1.0098\n",
      "Epoch 4/100, Loss: 1.0095\n",
      "Epoch 5/100, Loss: 1.0108\n",
      "Epoch 6/100, Loss: 1.0090\n",
      "Epoch 7/100, Loss: 1.0068\n",
      "Epoch 8/100, Loss: 1.0090\n",
      "Epoch 9/100, Loss: 1.0088\n",
      "Epoch 10/100, Loss: 1.0093\n",
      "Epoch 11/100, Loss: 1.0092\n",
      "Epoch 12/100, Loss: 1.0081\n",
      "Epoch 13/100, Loss: 1.0086\n",
      "Epoch 14/100, Loss: 1.0084\n",
      "Epoch 15/100, Loss: 1.0104\n",
      "Epoch 16/100, Loss: 1.0070\n",
      "Epoch 17/100, Loss: 1.0098\n",
      "Epoch 18/100, Loss: 1.0118\n",
      "Epoch 19/100, Loss: 1.0089\n",
      "Epoch 20/100, Loss: 1.0110\n",
      "Epoch 21/100, Loss: 1.0104\n",
      "Epoch 22/100, Loss: 1.0081\n",
      "Epoch 23/100, Loss: 1.0093\n",
      "Epoch 24/100, Loss: 1.0071\n",
      "Epoch 25/100, Loss: 1.0105\n",
      "Epoch 26/100, Loss: 1.0092\n",
      "Epoch 27/100, Loss: 1.0090\n",
      "Epoch 28/100, Loss: 1.0062\n",
      "Epoch 29/100, Loss: 1.0080\n",
      "Epoch 30/100, Loss: 1.0047\n",
      "Epoch 31/100, Loss: 1.0114\n",
      "Epoch 32/100, Loss: 1.0127\n",
      "Epoch 33/100, Loss: 1.0089\n",
      "Epoch 34/100, Loss: 1.0146\n",
      "Epoch 35/100, Loss: 1.0082\n",
      "Epoch 36/100, Loss: 1.0096\n",
      "Epoch 37/100, Loss: 1.0066\n",
      "Epoch 38/100, Loss: 1.0105\n",
      "Epoch 39/100, Loss: 1.0072\n",
      "Epoch 40/100, Loss: 1.0094\n",
      "Epoch 41/100, Loss: 1.0082\n",
      "Epoch 42/100, Loss: 1.0091\n",
      "Epoch 43/100, Loss: 1.0079\n",
      "Epoch 44/100, Loss: 1.0084\n",
      "Epoch 45/100, Loss: 1.0106\n",
      "Epoch 46/100, Loss: 1.0105\n",
      "Epoch 47/100, Loss: 1.0097\n",
      "Epoch 48/100, Loss: 1.0109\n",
      "Epoch 49/100, Loss: 1.0081\n",
      "Epoch 50/100, Loss: 1.0092\n",
      "Epoch 51/100, Loss: 1.0122\n",
      "Epoch 52/100, Loss: 1.0111\n",
      "Epoch 53/100, Loss: 1.0091\n",
      "Epoch 54/100, Loss: 1.0091\n",
      "Epoch 55/100, Loss: 1.0099\n",
      "Epoch 56/100, Loss: 1.0069\n",
      "Epoch 57/100, Loss: 1.0098\n",
      "Epoch 58/100, Loss: 1.0104\n",
      "Epoch 59/100, Loss: 1.0074\n",
      "Epoch 60/100, Loss: 1.0095\n",
      "Epoch 61/100, Loss: 1.0116\n",
      "Epoch 62/100, Loss: 1.0107\n",
      "Epoch 63/100, Loss: 1.0114\n",
      "Epoch 64/100, Loss: 1.0086\n",
      "Epoch 65/100, Loss: 1.0115\n",
      "Epoch 66/100, Loss: 1.0086\n",
      "Epoch 67/100, Loss: 1.0099\n",
      "Epoch 68/100, Loss: 1.0078\n",
      "Epoch 69/100, Loss: 1.0113\n",
      "Epoch 70/100, Loss: 1.0113\n",
      "Epoch 71/100, Loss: 1.0091\n",
      "Epoch 72/100, Loss: 1.0072\n",
      "Epoch 73/100, Loss: 1.0099\n",
      "Epoch 74/100, Loss: 1.0089\n",
      "Epoch 75/100, Loss: 1.0088\n",
      "Epoch 76/100, Loss: 1.0075\n",
      "Epoch 77/100, Loss: 1.0061\n",
      "Epoch 78/100, Loss: 1.0088\n",
      "Epoch 79/100, Loss: 1.0128\n",
      "Epoch 80/100, Loss: 1.0074\n",
      "Epoch 81/100, Loss: 1.0087\n",
      "Epoch 82/100, Loss: 1.0076\n",
      "Epoch 83/100, Loss: 1.0092\n",
      "Epoch 84/100, Loss: 1.0076\n",
      "Epoch 85/100, Loss: 1.0071\n",
      "Epoch 86/100, Loss: 1.0122\n",
      "Epoch 87/100, Loss: 1.0076\n",
      "Epoch 88/100, Loss: 1.0094\n",
      "Epoch 89/100, Loss: 1.0111\n",
      "Epoch 90/100, Loss: 1.0119\n",
      "Epoch 91/100, Loss: 1.0070\n",
      "Epoch 92/100, Loss: 1.0130\n",
      "Epoch 93/100, Loss: 1.0071\n",
      "Epoch 94/100, Loss: 1.0083\n",
      "Epoch 95/100, Loss: 1.0119\n",
      "Epoch 96/100, Loss: 1.0083\n",
      "Epoch 97/100, Loss: 1.0080\n",
      "Epoch 98/100, Loss: 1.0076\n",
      "Epoch 99/100, Loss: 1.0097\n",
      "Epoch 100/100, Loss: 1.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 167.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1134\n",
      "Best Hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.8, 'learning_rate': 0.005}, Best MAP Score: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bits': 12,\n",
       "  'num_blocks': 3,\n",
       "  'gamma': 0.6,\n",
       "  'mu': 0.8,\n",
       "  'learning_rate': 0.005},\n",
       " 0.46850225681346364,\n",
       " {(('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.005)): 0.29066666613068326,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.01)): 0.19212862620413287,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.05)): 0.11545830324950894,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.1115995737803102,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.01)): 0.2115598759323527,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.05)): 0.11517744438184513,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.005)): 0.11704816229390555,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.01)): 0.11090847341658329,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.05)): 0.11531713852721309,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.005)): 0.18845491420410715,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.01)): 0.1295866873793528,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.05)): 0.11409110009947195,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.3469679793061645,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.01)): 0.23319159440106932,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.05)): 0.11144899344677849,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.005)): 0.46850225681346364,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.01)): 0.11511967922887542,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.05)): 0.113363684922405,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.005)): 0.11326823927613952,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.01)): 0.12067398958087408,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.05)): 0.11809190334215895,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.3443318644310487,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.01)): 0.11016101840614456,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.05)): 0.11515678972489557,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.005)): 0.3551421139783939,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.01)): 0.1975508905738283,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.05)): 0.11292465310357055,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.005)): 0.27221606796369113,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.01)): 0.11538012347873866,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.05)): 0.11678016239880537,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.38843840582318523,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.01)): 0.11389250672420362,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.05)): 0.11273630659766941,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.005)): 0.36447506490868403,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.01)): 0.11494003709436379,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.2),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.05)): 0.11501110526397537,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.005)): 0.2035375203087706,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.01)): 0.11727659624255339,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.05)): 0.11461468265163349,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.33110225458120934,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.01)): 0.19968583375238702,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.05)): 0.11093957295880971,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.005)): 0.11907013298339642,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.01)): 0.2051210495190117,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.05)): 0.11167897391070719,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.005)): 0.19940041101440292,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.01)): 0.12499181455135715,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.2),\n",
       "   ('learning_rate', 0.05)): 0.11459428847913287,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.2426535248735226,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.01)): 0.1279112509653743,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.05)): 0.11198267383821578,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.005)): 0.37956985916787556,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.01)): 0.11512826575683684,\n",
       "  (('bits', 12),\n",
       "   ('num_blocks', 4),\n",
       "   ('gamma', 0.8),\n",
       "   ('mu', 0.8),\n",
       "   ('learning_rate', 0.05)): 0.11339933436164765})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "losses = []\n",
    "maps = []\n",
    "\n",
    "hyper_tuning(param_grid=bits_12_param_dicts, epochs=100, hpo_train=X_hpo, hpo_loader=hpo_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'bits': 24, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.7965\n",
      "Epoch 2/100, Loss: 0.6030\n",
      "Epoch 3/100, Loss: 0.5161\n",
      "Epoch 4/100, Loss: 0.4979\n",
      "Epoch 5/100, Loss: 0.5102\n",
      "Epoch 6/100, Loss: 0.4793\n",
      "Epoch 7/100, Loss: 0.4449\n",
      "Epoch 8/100, Loss: 0.4805\n",
      "Epoch 9/100, Loss: 0.4733\n",
      "Epoch 10/100, Loss: 0.4278\n",
      "Epoch 11/100, Loss: 0.4476\n",
      "Epoch 12/100, Loss: 0.4259\n",
      "Epoch 13/100, Loss: 0.4068\n",
      "Epoch 14/100, Loss: 0.4147\n",
      "Epoch 15/100, Loss: 0.4705\n",
      "Epoch 16/100, Loss: 0.4227\n",
      "Epoch 17/100, Loss: 0.4418\n",
      "Epoch 18/100, Loss: 0.4077\n",
      "Epoch 19/100, Loss: 0.4573\n",
      "Epoch 20/100, Loss: 0.4167\n",
      "Epoch 21/100, Loss: 0.4585\n",
      "Epoch 22/100, Loss: 0.4177\n",
      "Epoch 23/100, Loss: 0.4147\n",
      "Epoch 24/100, Loss: 0.4147\n",
      "Epoch 25/100, Loss: 0.4000\n",
      "Epoch 26/100, Loss: 0.3765\n",
      "Epoch 27/100, Loss: 0.3647\n",
      "Epoch 28/100, Loss: 0.3683\n",
      "Epoch 29/100, Loss: 0.3691\n",
      "Epoch 30/100, Loss: 0.4155\n",
      "Epoch 31/100, Loss: 0.3826\n",
      "Epoch 32/100, Loss: 0.3785\n",
      "Epoch 33/100, Loss: 0.3832\n",
      "Epoch 34/100, Loss: 0.4310\n",
      "Epoch 35/100, Loss: 0.4021\n",
      "Epoch 36/100, Loss: 0.3968\n",
      "Epoch 37/100, Loss: 0.3640\n",
      "Epoch 38/100, Loss: 0.3989\n",
      "Epoch 39/100, Loss: 0.3582\n",
      "Epoch 40/100, Loss: 0.3686\n",
      "Epoch 41/100, Loss: 0.4131\n",
      "Epoch 42/100, Loss: 0.3643\n",
      "Epoch 43/100, Loss: 0.3547\n",
      "Epoch 44/100, Loss: 0.3867\n",
      "Epoch 45/100, Loss: 0.3581\n",
      "Epoch 46/100, Loss: 0.3793\n",
      "Epoch 47/100, Loss: 0.3642\n",
      "Epoch 48/100, Loss: 0.3649\n",
      "Epoch 49/100, Loss: 0.3400\n",
      "Epoch 50/100, Loss: 0.3470\n",
      "Epoch 51/100, Loss: 0.3679\n",
      "Epoch 52/100, Loss: 0.3750\n",
      "Epoch 53/100, Loss: 0.3812\n",
      "Epoch 54/100, Loss: 0.3541\n",
      "Epoch 55/100, Loss: 0.3609\n",
      "Epoch 56/100, Loss: 0.3677\n",
      "Epoch 57/100, Loss: 0.3635\n",
      "Epoch 58/100, Loss: 0.3403\n",
      "Epoch 59/100, Loss: 0.3457\n",
      "Epoch 60/100, Loss: 0.3395\n",
      "Epoch 61/100, Loss: 0.3391\n",
      "Epoch 62/100, Loss: 0.3884\n",
      "Epoch 63/100, Loss: 0.4152\n",
      "Epoch 64/100, Loss: 0.3709\n",
      "Epoch 65/100, Loss: 0.3460\n",
      "Epoch 66/100, Loss: 0.3597\n",
      "Epoch 67/100, Loss: 0.3678\n",
      "Epoch 68/100, Loss: 0.3294\n",
      "Epoch 69/100, Loss: 0.4007\n",
      "Epoch 70/100, Loss: 0.3803\n",
      "Epoch 71/100, Loss: 0.3627\n",
      "Epoch 72/100, Loss: 0.3717\n",
      "Epoch 73/100, Loss: 0.3578\n",
      "Epoch 74/100, Loss: 0.3872\n",
      "Epoch 75/100, Loss: 0.3725\n",
      "Epoch 76/100, Loss: 0.4123\n",
      "Epoch 77/100, Loss: 0.3806\n",
      "Epoch 78/100, Loss: 0.3497\n",
      "Epoch 79/100, Loss: 0.3586\n",
      "Epoch 80/100, Loss: 0.3471\n",
      "Epoch 81/100, Loss: 0.3436\n",
      "Epoch 82/100, Loss: 0.3242\n",
      "Epoch 83/100, Loss: 0.3323\n",
      "Epoch 84/100, Loss: 0.3624\n",
      "Epoch 85/100, Loss: 0.3402\n",
      "Epoch 86/100, Loss: 0.3530\n",
      "Epoch 87/100, Loss: 0.3826\n",
      "Epoch 88/100, Loss: 0.4098\n",
      "Epoch 89/100, Loss: 0.3911\n",
      "Epoch 90/100, Loss: 0.3852\n",
      "Epoch 91/100, Loss: 0.4062\n",
      "Epoch 92/100, Loss: 0.3945\n",
      "Epoch 93/100, Loss: 0.3745\n",
      "Epoch 94/100, Loss: 0.3678\n",
      "Epoch 95/100, Loss: 0.3461\n",
      "Epoch 96/100, Loss: 0.3412\n",
      "Epoch 97/100, Loss: 0.3140\n",
      "Epoch 98/100, Loss: 0.3347\n",
      "Epoch 99/100, Loss: 0.3614\n",
      "Epoch 100/100, Loss: 0.3713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 95.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3652\n",
      "Testing hyperparameters: {'bits': 24, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Loss: 1.0020\n",
      "Epoch 2/100, Loss: 1.0007\n",
      "Epoch 3/100, Loss: 1.0016\n",
      "Epoch 4/100, Loss: 1.0011\n",
      "Epoch 5/100, Loss: 1.0017\n",
      "Epoch 6/100, Loss: 1.0014\n",
      "Epoch 7/100, Loss: 1.0018\n",
      "Epoch 8/100, Loss: 1.0015\n",
      "Epoch 9/100, Loss: 1.0015\n",
      "Epoch 10/100, Loss: 1.0013\n",
      "Epoch 11/100, Loss: 1.0017\n",
      "Epoch 12/100, Loss: 1.0016\n",
      "Epoch 13/100, Loss: 1.0018\n",
      "Epoch 14/100, Loss: 1.0019\n",
      "Epoch 15/100, Loss: 1.0009\n",
      "Epoch 16/100, Loss: 1.0016\n",
      "Epoch 17/100, Loss: 1.0015\n",
      "Epoch 18/100, Loss: 1.0010\n",
      "Epoch 19/100, Loss: 1.0015\n",
      "Epoch 20/100, Loss: 1.0013\n",
      "Epoch 21/100, Loss: 1.0021\n",
      "Epoch 22/100, Loss: 1.0013\n",
      "Epoch 23/100, Loss: 1.0018\n",
      "Epoch 24/100, Loss: 1.0016\n",
      "Epoch 25/100, Loss: 1.0023\n",
      "Epoch 26/100, Loss: 1.0018\n",
      "Epoch 27/100, Loss: 1.0018\n",
      "Epoch 28/100, Loss: 1.0019\n",
      "Epoch 29/100, Loss: 1.0013\n",
      "Epoch 30/100, Loss: 1.0014\n",
      "Epoch 31/100, Loss: 1.0017\n",
      "Epoch 32/100, Loss: 1.0015\n",
      "Epoch 33/100, Loss: 1.0013\n",
      "Epoch 34/100, Loss: 1.0015\n",
      "Epoch 35/100, Loss: 1.0020\n",
      "Epoch 36/100, Loss: 1.0015\n",
      "Epoch 37/100, Loss: 1.0017\n",
      "Epoch 38/100, Loss: 1.0012\n",
      "Epoch 39/100, Loss: 1.0014\n",
      "Epoch 40/100, Loss: 1.0020\n",
      "Epoch 41/100, Loss: 1.0019\n",
      "Epoch 42/100, Loss: 1.0018\n",
      "Epoch 43/100, Loss: 1.0013\n",
      "Epoch 44/100, Loss: 1.0022\n",
      "Epoch 45/100, Loss: 1.0012\n",
      "Epoch 46/100, Loss: 1.0015\n",
      "Epoch 47/100, Loss: 1.0019\n",
      "Epoch 48/100, Loss: 1.0016\n",
      "Epoch 49/100, Loss: 1.0009\n",
      "Epoch 50/100, Loss: 1.0013\n",
      "Epoch 51/100, Loss: 1.0012\n",
      "Epoch 52/100, Loss: 1.0021\n",
      "Epoch 53/100, Loss: 1.0019\n",
      "Epoch 54/100, Loss: 1.0019\n",
      "Epoch 55/100, Loss: 1.0017\n",
      "Epoch 56/100, Loss: 1.0012\n",
      "Epoch 57/100, Loss: 1.0018\n",
      "Epoch 58/100, Loss: 1.0013\n",
      "Epoch 59/100, Loss: 1.0015\n",
      "Epoch 60/100, Loss: 1.0011\n",
      "Epoch 61/100, Loss: 1.0014\n",
      "Epoch 62/100, Loss: 1.0015\n",
      "Epoch 63/100, Loss: 1.0007\n",
      "Epoch 64/100, Loss: 1.0022\n",
      "Epoch 65/100, Loss: 1.0016\n",
      "Epoch 66/100, Loss: 1.0012\n",
      "Epoch 67/100, Loss: 1.0018\n",
      "Epoch 68/100, Loss: 1.0017\n",
      "Epoch 69/100, Loss: 1.0011\n",
      "Epoch 70/100, Loss: 1.0018\n",
      "Epoch 71/100, Loss: 1.0009\n",
      "Epoch 72/100, Loss: 1.0018\n",
      "Epoch 73/100, Loss: 1.0013\n",
      "Epoch 74/100, Loss: 1.0024\n",
      "Epoch 75/100, Loss: 1.0015\n",
      "Epoch 76/100, Loss: 1.0013\n",
      "Epoch 77/100, Loss: 1.0019\n",
      "Epoch 78/100, Loss: 1.0022\n",
      "Epoch 79/100, Loss: 1.0012\n",
      "Epoch 80/100, Loss: 1.0016\n",
      "Epoch 81/100, Loss: 1.0014\n",
      "Epoch 82/100, Loss: 1.0019\n",
      "Epoch 83/100, Loss: 1.0010\n",
      "Epoch 84/100, Loss: 1.0019\n",
      "Epoch 85/100, Loss: 1.0015\n",
      "Epoch 86/100, Loss: 1.0018\n",
      "Epoch 87/100, Loss: 1.0015\n",
      "Epoch 88/100, Loss: 1.0021\n",
      "Epoch 89/100, Loss: 1.0018\n",
      "Epoch 90/100, Loss: 1.0019\n",
      "Epoch 91/100, Loss: 1.0026\n",
      "Epoch 92/100, Loss: 1.0014\n",
      "Epoch 93/100, Loss: 1.0016\n",
      "Epoch 94/100, Loss: 1.0019\n",
      "Epoch 95/100, Loss: 1.0016\n",
      "Epoch 96/100, Loss: 1.0018\n",
      "Epoch 97/100, Loss: 1.0020\n",
      "Epoch 98/100, Loss: 1.0016\n",
      "Epoch 99/100, Loss: 1.0012\n",
      "Epoch 100/100, Loss: 1.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 117.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1147\n",
      "Testing hyperparameters: {'bits': 24, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.2, 'learning_rate': 0.05}\n",
      "Epoch 1/100, Loss: 1.0088\n",
      "Epoch 2/100, Loss: 1.0082\n",
      "Epoch 3/100, Loss: 1.0093\n",
      "Epoch 4/100, Loss: 1.0074\n",
      "Epoch 5/100, Loss: 1.0074\n",
      "Epoch 6/100, Loss: 1.0085\n",
      "Epoch 7/100, Loss: 1.0073\n",
      "Epoch 8/100, Loss: 1.0083\n",
      "Epoch 9/100, Loss: 1.0076\n",
      "Epoch 10/100, Loss: 1.0074\n",
      "Epoch 11/100, Loss: 1.0061\n",
      "Epoch 12/100, Loss: 1.0075\n",
      "Epoch 13/100, Loss: 1.0093\n",
      "Epoch 14/100, Loss: 1.0068\n",
      "Epoch 15/100, Loss: 1.0090\n",
      "Epoch 16/100, Loss: 1.0084\n",
      "Epoch 17/100, Loss: 1.0083\n",
      "Epoch 18/100, Loss: 1.0091\n",
      "Epoch 19/100, Loss: 1.0099\n",
      "Epoch 20/100, Loss: 1.0076\n",
      "Epoch 21/100, Loss: 1.0095\n",
      "Epoch 22/100, Loss: 1.0071\n",
      "Epoch 23/100, Loss: 1.0079\n",
      "Epoch 24/100, Loss: 1.0061\n",
      "Epoch 25/100, Loss: 1.0075\n",
      "Epoch 26/100, Loss: 1.0063\n",
      "Epoch 27/100, Loss: 1.0087\n",
      "Epoch 28/100, Loss: 1.0067\n",
      "Epoch 29/100, Loss: 1.0073\n",
      "Epoch 30/100, Loss: 1.0096\n",
      "Epoch 31/100, Loss: 1.0114\n",
      "Epoch 32/100, Loss: 1.0062\n",
      "Epoch 33/100, Loss: 1.0095\n",
      "Epoch 34/100, Loss: 1.0106\n",
      "Epoch 35/100, Loss: 1.0085\n",
      "Epoch 36/100, Loss: 1.0059\n",
      "Epoch 37/100, Loss: 1.0083\n",
      "Epoch 38/100, Loss: 1.0072\n",
      "Epoch 39/100, Loss: 1.0081\n",
      "Epoch 40/100, Loss: 1.0089\n",
      "Epoch 41/100, Loss: 1.0058\n",
      "Epoch 42/100, Loss: 1.0099\n",
      "Epoch 43/100, Loss: 1.0073\n",
      "Epoch 44/100, Loss: 1.0106\n",
      "Epoch 45/100, Loss: 1.0064\n",
      "Epoch 46/100, Loss: 1.0081\n",
      "Epoch 47/100, Loss: 1.0111\n",
      "Epoch 48/100, Loss: 1.0068\n",
      "Epoch 49/100, Loss: 1.0077\n",
      "Epoch 50/100, Loss: 1.0071\n",
      "Epoch 51/100, Loss: 1.0073\n",
      "Epoch 52/100, Loss: 1.0067\n",
      "Epoch 53/100, Loss: 1.0078\n",
      "Epoch 54/100, Loss: 1.0064\n",
      "Epoch 55/100, Loss: 1.0046\n",
      "Epoch 56/100, Loss: 1.0078\n",
      "Epoch 57/100, Loss: 1.0050\n",
      "Epoch 58/100, Loss: 1.0065\n",
      "Epoch 59/100, Loss: 1.0058\n",
      "Epoch 60/100, Loss: 1.0067\n",
      "Epoch 61/100, Loss: 1.0059\n",
      "Epoch 62/100, Loss: 1.0112\n",
      "Epoch 63/100, Loss: 1.0079\n",
      "Epoch 64/100, Loss: 1.0068\n",
      "Epoch 65/100, Loss: 1.0073\n",
      "Epoch 66/100, Loss: 1.0101\n",
      "Epoch 67/100, Loss: 1.0085\n",
      "Epoch 68/100, Loss: 1.0087\n",
      "Epoch 69/100, Loss: 1.0086\n",
      "Epoch 70/100, Loss: 1.0070\n",
      "Epoch 71/100, Loss: 1.0066\n",
      "Epoch 72/100, Loss: 1.0069\n",
      "Epoch 73/100, Loss: 1.0091\n",
      "Epoch 74/100, Loss: 1.0076\n",
      "Epoch 75/100, Loss: 1.0058\n",
      "Epoch 76/100, Loss: 1.0089\n",
      "Epoch 77/100, Loss: 1.0054\n",
      "Epoch 78/100, Loss: 1.0096\n",
      "Epoch 79/100, Loss: 1.0084\n",
      "Epoch 80/100, Loss: 1.0077\n",
      "Epoch 81/100, Loss: 1.0060\n",
      "Epoch 82/100, Loss: 1.0066\n",
      "Epoch 83/100, Loss: 1.0083\n",
      "Epoch 84/100, Loss: 1.0082\n",
      "Epoch 85/100, Loss: 1.0072\n",
      "Epoch 86/100, Loss: 1.0090\n",
      "Epoch 87/100, Loss: 1.0072\n",
      "Epoch 88/100, Loss: 1.0075\n",
      "Epoch 89/100, Loss: 1.0071\n",
      "Epoch 90/100, Loss: 1.0073\n",
      "Epoch 91/100, Loss: 1.0069\n",
      "Epoch 92/100, Loss: 1.0063\n",
      "Epoch 93/100, Loss: 1.0072\n",
      "Epoch 94/100, Loss: 1.0078\n",
      "Epoch 95/100, Loss: 1.0055\n",
      "Epoch 96/100, Loss: 1.0078\n",
      "Epoch 97/100, Loss: 1.0089\n",
      "Epoch 98/100, Loss: 1.0060\n",
      "Epoch 99/100, Loss: 1.0103\n",
      "Epoch 100/100, Loss: 1.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 240.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.1135\n",
      "Testing hyperparameters: {'bits': 24, 'num_blocks': 3, 'gamma': 0.2, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.6626\n",
      "Epoch 2/100, Loss: 0.4429\n",
      "Epoch 3/100, Loss: 0.3772\n",
      "Epoch 4/100, Loss: 0.3171\n",
      "Epoch 5/100, Loss: 0.3208\n",
      "Epoch 6/100, Loss: 0.2107\n",
      "Epoch 7/100, Loss: 0.1884\n",
      "Epoch 8/100, Loss: 0.1792\n",
      "Epoch 9/100, Loss: 0.1735\n",
      "Epoch 10/100, Loss: 0.1517\n",
      "Epoch 11/100, Loss: 0.1600\n",
      "Epoch 12/100, Loss: 0.1840\n",
      "Epoch 13/100, Loss: 0.1820\n",
      "Epoch 14/100, Loss: 0.1202\n",
      "Epoch 15/100, Loss: 0.1173\n",
      "Epoch 16/100, Loss: 0.1371\n",
      "Epoch 17/100, Loss: 0.1423\n",
      "Epoch 18/100, Loss: 0.1177\n",
      "Epoch 19/100, Loss: 0.1174\n",
      "Epoch 20/100, Loss: 0.1219\n",
      "Epoch 21/100, Loss: 0.1223\n",
      "Epoch 22/100, Loss: 0.1108\n",
      "Epoch 23/100, Loss: 0.0992\n",
      "Epoch 24/100, Loss: 0.1414\n",
      "Epoch 25/100, Loss: 0.0896\n",
      "Epoch 26/100, Loss: 0.0836\n",
      "Epoch 27/100, Loss: 0.0587\n",
      "Epoch 28/100, Loss: 0.0721\n",
      "Epoch 29/100, Loss: 0.1264\n",
      "Epoch 30/100, Loss: 0.0948\n",
      "Epoch 31/100, Loss: 0.0995\n",
      "Epoch 32/100, Loss: 0.0458\n",
      "Epoch 33/100, Loss: 0.0508\n",
      "Epoch 34/100, Loss: 0.0177\n",
      "Epoch 35/100, Loss: 0.0360\n",
      "Epoch 36/100, Loss: 0.0952\n",
      "Epoch 37/100, Loss: 0.0653\n",
      "Epoch 38/100, Loss: 0.0440\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhyper_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbits_24_param_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhpo_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_hpo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhpo_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhpo_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[198], line 29\u001b[0m, in \u001b[0;36mhyper_tuning\u001b[1;34m(param_grid, epochs, hpo_train, hpo_loader, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model with the current parameter set\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m trained_model, _ \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluate the model using MAP score\u001b[39;00m\n\u001b[0;32m     32\u001b[0m map_score \u001b[38;5;241m=\u001b[39m map_on_call(trained_model)\n",
      "Cell \u001b[1;32mIn[196], line 27\u001b[0m, in \u001b[0;36mloss_function\u001b[1;34m(epochs, bits, num_blocks, block_size, gamma, mu, learning_rate)\u001b[0m\n\u001b[0;32m     24\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat), labels\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m class_probs, binary_codes \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_one_hot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_total_loss(\n\u001b[0;32m     31\u001b[0m     class_probs, labels, binary_codes, num_blocks, block_size, gamma, mu\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[192], line 54\u001b[0m, in \u001b[0;36mSUBIC_encoder.forward\u001b[1;34m(self, x, use_one_hot)\u001b[0m\n\u001b[0;32m     51\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten if necessary\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_one_hot:\n\u001b[0;32m     57\u001b[0m     binary_codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_one_hot(z)\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\modules\\activation.py:104\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xiaoy\\OneDrive\\Desktop\\P7\\p7 project\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyper_tuning(param_grid=bits_24_param_dicts, epochs=100, hpo_train=X_hpo, hpo_loader=hpo_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid=bits_24_param_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param = [{'bits': 12,\n",
    "  'num_blocks': 3,\n",
    "  'gamma': 0.6,\n",
    "  'mu': 0.6,\n",
    "  'learning_rate': 0.005}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Loss: 0.6518\n",
      "Epoch 2/100, Loss: 0.5493\n",
      "Epoch 3/100, Loss: 0.4896\n",
      "Epoch 4/100, Loss: 0.3813\n",
      "Epoch 5/100, Loss: 0.3448\n",
      "Epoch 6/100, Loss: 0.4755\n",
      "Epoch 7/100, Loss: 0.4314\n",
      "Epoch 8/100, Loss: 0.4422\n",
      "Epoch 9/100, Loss: 0.4568\n",
      "Epoch 10/100, Loss: 0.4816\n",
      "Epoch 11/100, Loss: 0.4509\n",
      "Epoch 12/100, Loss: 0.4206\n",
      "Epoch 13/100, Loss: 0.4327\n",
      "Epoch 14/100, Loss: 0.3642\n",
      "Epoch 15/100, Loss: 0.3379\n",
      "Epoch 16/100, Loss: 0.3517\n",
      "Epoch 17/100, Loss: 0.2954\n",
      "Epoch 18/100, Loss: 0.3123\n",
      "Epoch 19/100, Loss: 0.3140\n",
      "Epoch 20/100, Loss: 0.3223\n",
      "Epoch 21/100, Loss: 0.2715\n",
      "Epoch 22/100, Loss: 0.2598\n",
      "Epoch 23/100, Loss: 0.2782\n",
      "Epoch 24/100, Loss: 0.3077\n",
      "Epoch 25/100, Loss: 0.2872\n",
      "Epoch 26/100, Loss: 0.2648\n",
      "Epoch 27/100, Loss: 0.3181\n",
      "Epoch 28/100, Loss: 0.2628\n",
      "Epoch 29/100, Loss: 0.3023\n",
      "Epoch 30/100, Loss: 0.2684\n",
      "Epoch 31/100, Loss: 0.2423\n",
      "Epoch 32/100, Loss: 0.2907\n",
      "Epoch 33/100, Loss: 0.3374\n",
      "Epoch 34/100, Loss: 0.3189\n",
      "Epoch 35/100, Loss: 0.2517\n",
      "Epoch 36/100, Loss: 0.2307\n",
      "Epoch 37/100, Loss: 0.1946\n",
      "Epoch 38/100, Loss: 0.1865\n",
      "Epoch 39/100, Loss: 0.2034\n",
      "Epoch 40/100, Loss: 0.2302\n",
      "Epoch 41/100, Loss: 0.2503\n",
      "Epoch 42/100, Loss: 0.2490\n",
      "Epoch 43/100, Loss: 0.2323\n",
      "Epoch 44/100, Loss: 0.1752\n",
      "Epoch 45/100, Loss: 0.2027\n",
      "Epoch 46/100, Loss: 0.2523\n",
      "Epoch 47/100, Loss: 0.1752\n",
      "Epoch 48/100, Loss: 0.1208\n",
      "Epoch 49/100, Loss: 0.2518\n",
      "Epoch 50/100, Loss: 0.2209\n",
      "Epoch 51/100, Loss: 0.1671\n",
      "Epoch 52/100, Loss: 0.1517\n",
      "Epoch 53/100, Loss: 0.1256\n",
      "Epoch 54/100, Loss: 0.1437\n",
      "Epoch 55/100, Loss: 0.0987\n",
      "Epoch 56/100, Loss: 0.1172\n",
      "Epoch 57/100, Loss: 0.1291\n",
      "Epoch 58/100, Loss: 0.1193\n",
      "Epoch 59/100, Loss: 0.1237\n",
      "Epoch 60/100, Loss: 0.0873\n",
      "Epoch 61/100, Loss: 0.0966\n",
      "Epoch 62/100, Loss: 0.1753\n",
      "Epoch 63/100, Loss: 0.1534\n",
      "Epoch 64/100, Loss: 0.1321\n",
      "Epoch 65/100, Loss: 0.1175\n",
      "Epoch 66/100, Loss: 0.1121\n",
      "Epoch 67/100, Loss: 0.1096\n",
      "Epoch 68/100, Loss: 0.1257\n",
      "Epoch 69/100, Loss: 0.1749\n",
      "Epoch 70/100, Loss: 0.1204\n",
      "Epoch 71/100, Loss: 0.1729\n",
      "Epoch 72/100, Loss: 0.1188\n",
      "Epoch 73/100, Loss: 0.1529\n",
      "Epoch 74/100, Loss: 0.2366\n",
      "Epoch 75/100, Loss: 0.2702\n",
      "Epoch 76/100, Loss: 0.1758\n",
      "Epoch 77/100, Loss: 0.1356\n",
      "Epoch 78/100, Loss: 0.1438\n",
      "Epoch 79/100, Loss: 0.1214\n",
      "Epoch 80/100, Loss: 0.1348\n",
      "Epoch 81/100, Loss: 0.1873\n",
      "Epoch 82/100, Loss: 0.1836\n",
      "Epoch 83/100, Loss: 0.1154\n",
      "Epoch 84/100, Loss: 0.1105\n",
      "Epoch 85/100, Loss: 0.1208\n",
      "Epoch 86/100, Loss: 0.1379\n",
      "Epoch 87/100, Loss: 0.1065\n",
      "Epoch 88/100, Loss: 0.1057\n",
      "Epoch 89/100, Loss: 0.1261\n",
      "Epoch 90/100, Loss: 0.1269\n",
      "Epoch 91/100, Loss: 0.0988\n",
      "Epoch 92/100, Loss: 0.0967\n",
      "Epoch 93/100, Loss: 0.1292\n",
      "Epoch 94/100, Loss: 0.1173\n",
      "Epoch 95/100, Loss: 0.0976\n",
      "Epoch 96/100, Loss: 0.0977\n",
      "Epoch 97/100, Loss: 0.1187\n",
      "Epoch 98/100, Loss: 0.1818\n",
      "Epoch 99/100, Loss: 0.1685\n",
      "Epoch 100/100, Loss: 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 166.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.3341\n",
      "Best Hyperparameters: {'bits': 12, 'num_blocks': 3, 'gamma': 0.6, 'mu': 0.6, 'learning_rate': 0.005}, Best MAP Score: 0.3341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bits': 12,\n",
       "  'num_blocks': 3,\n",
       "  'gamma': 0.6,\n",
       "  'mu': 0.6,\n",
       "  'learning_rate': 0.005},\n",
       " 0.33414062869259775,\n",
       " {(('bits', 12),\n",
       "   ('num_blocks', 3),\n",
       "   ('gamma', 0.6),\n",
       "   ('mu', 0.6),\n",
       "   ('learning_rate', 0.005)): 0.33414062869259775})"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_tuning(param_grid=test_param, epochs=100, hpo_train=X_hpo, hpo_loader=hpo_loader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
