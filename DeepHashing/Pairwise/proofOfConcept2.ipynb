{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import random\n",
    "from torchvision import models, transforms\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #Is transformed to be better with VGG16 model\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def getDataset(train=True, sample_size=100):\n",
    "    dataset = CIFAR10(root='./data',\n",
    "                  train=train, \n",
    "                  download=True,\n",
    "                  transform=transform)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        X.append( dataset[i][0] )\n",
    "        y.append( dataset[i][1] )\n",
    "\n",
    "    X = torch.stack( X )\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = getDataset() #Training data\n",
    "X_test, y_test = getDataset(train=False) #Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tobop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "pretrained_model = models.vgg16(pretrained=True)\n",
    "pretrained_model.classifier = torch.nn.Identity() # 25088 features output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(25088, 10000),  # First fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10000, 4000)    # Second fully connected layer to reduce to 4000\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, cnn_extractor, custom_nn):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.cnn_extractor = cnn_extractor  # Pretrained CNN (frozen)\n",
    "        self.custom_nn = custom_nn  # Custom NN (trainable)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_extractor(x)  # Extract features using the CNN\n",
    "        output = self.custom_nn(features)  # Pass the features through the custom NN\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_nn = CustomNN()\n",
    "model = CombinedModel(pretrained_model, custom_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "eta = 0.25 #Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, mean, std_dev, eta = 0.25, hash_length = 32):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        # Initialize W and V as learnable parameters\n",
    "        self.W = nn.Parameter(torch.normal(mean, std_dev, (4000, hash_length)))  # W will be updated during training\n",
    "        self.V = nn.Parameter(torch.normal(mean, std_dev, (hash_length, 1)))     # V will be updated during training\n",
    "        self.eta = eta  # Regularization parameter\n",
    "\n",
    "    def forward(self, outputs, targets, hash_length = 32):\n",
    "        targets = torch.tensor(targets)\n",
    "        S = (targets[:, None] == targets).float() # S calculation\n",
    "\n",
    "        #U calculation\n",
    "        U = []\n",
    "        for i in range(len(outputs)):\n",
    "            dot = torch.matmul(self.W.T, outputs[i])\n",
    "            dot = dot.reshape(32, 1)\n",
    "            u = (dot + self.V)\n",
    "            U.append(u)\n",
    "        U = torch.stack(U) # torch.Size([100, 32, 1])\n",
    "        U = U.reshape(100, 32)\n",
    "\n",
    "        #Calculate Theta\n",
    "        dot_product_matrix = torch.matmul(U, U.T)\n",
    "        dot_product_matrix # (sample_size, sample_size) Shape\n",
    "        Theta = 1/2 * dot_product_matrix\n",
    "\n",
    "        #Calculate hash codes\n",
    "        B = torch.sign(U)\n",
    "\n",
    "        loss = - torch.sum(S * Theta - torch.log(1 + torch.exp(Theta)))\n",
    "        loss += + self.eta * torch.sum(torch.norm(B - U, dim = 1).pow(2))    \n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CustomLoss(mean=0, std_dev=0.01, eta=0.25)\n",
    "\n",
    "\n",
    "for param in pretrained_model.parameters(): #LÃ¥s parameters i VGG16\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(model.custom_nn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    inputs = X_train  # Your input data\n",
    "    targets = y_train  # Your target labels\n",
    "    outputs = model(inputs)  # Forward pass through the combined model\n",
    "    loss = loss_fn(outputs, targets)  # Compute the custom loss\n",
    "    loss.backward()  # Backpropagate\n",
    "    optimizer.step()  # Update only the custom NN's parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
