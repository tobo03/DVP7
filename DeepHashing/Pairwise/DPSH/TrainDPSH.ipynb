{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root = '../../../'\n",
    "sys.path.append(root)\n",
    "from HelpfulFunctions.batchCreation import createBatch\n",
    "from HelpfulFunctions.metrics import meanAveragePrecision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataset(X, y, batch_size, train = 1):\n",
    "\n",
    "    if train == 1:\n",
    "        #Create X_train_tensor\n",
    "        X_train_tensor = torch.tensor(X)\n",
    "        X_size = X_train_tensor.shape[0]\n",
    "\n",
    "        #Create Y_train_tensor\n",
    "        y_train_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        #Create indices\n",
    "        indices_train = torch.arange(len(X_train_tensor))\n",
    "        dataset = TensorDataset(X_train_tensor, y_train_tensor, indices_train)\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        return train_loader, X_size\n",
    "\n",
    "    elif train == 2:\n",
    "        \n",
    "        #Create X_train_tensor\n",
    "        X_test_tensor = torch.tensor(X)\n",
    "\n",
    "        #Create Y_train_tensor\n",
    "        y_test_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        #Create indices\n",
    "        indices_test = torch.arange(len(X_test_tensor))\n",
    "        dataset = TensorDataset(X_test_tensor, y_test_tensor, indices_test)\n",
    "        test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        return test_loader, X_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5002, 4096])\n",
      "torch.Size([5002, 21])\n",
      "torch.Size([502, 4096])\n",
      "torch.Size([502, 21])\n",
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        [1, 0, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "train_loader = CreateDataset(batch_size = 128, train = 1, HPO=True)\n",
    "#test_loader = CreateDataset(root, num_classes = 10, batch_size = 128, train = 2)\n",
    "validation_loader = CreateDataset(batch_size = 128, train = 2, HPO = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(nn.Module):\n",
    "    def __init__(self, bits):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(4096, 1024),  # First fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, bits),    # Second fully connected layer to reduce to 4000\n",
    "        )\n",
    "\n",
    "        # Initialize weights and biases from gaussian distribution\n",
    "        for layer in self.fc_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=0.01)  # Initialize weights based on paper\n",
    "                nn.init.normal_(layer.bias, mean=0.0, std=0.01)    # Initialize biases based on paper\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPSHLoss(torch.nn.Module):\n",
    "    def __init__(self, train_size, n_classes, bit):\n",
    "        super(DPSHLoss, self).__init__()\n",
    "        self.U = torch.zeros(train_size, bit).float().to(device)\n",
    "        self.Y = torch.zeros(train_size, n_classes).float().to(device)\n",
    "\n",
    "    def forward(self, u, y, ind, eta):\n",
    "        self.U[ind, :] = u.data\n",
    "        self.Y[ind, :] = y.float()\n",
    "\n",
    "        s = (y @ self.Y.t() > 0).float().clamp(max = 1)\n",
    "        inner_product = u @ self.U.t() * 0.5\n",
    "\n",
    "        likelihood_loss = (1 + (-(inner_product.abs())).exp()).log() + inner_product.clamp(min=0) - s * inner_product\n",
    "\n",
    "        likelihood_loss = likelihood_loss.mean()\n",
    "\n",
    "        quantization_loss = eta * (u - u.sign()).pow(2).mean()\n",
    "\n",
    "        return likelihood_loss + quantization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "\n",
    "def DPSH(device: torch.device, X_train: np.ndarray, y_train: np.ndarray, bit: int, num_epoch: int, batch_size: int, lr: int, weight_decay: int, eta: int):\n",
    "\n",
    "    n_classes = y_train.shape[1]\n",
    "    train_loader, train_size = CreateDataset(X = X_train, y = y_train, batch_size = 128, train = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    customLoss = DPSHLoss(train_size, n_classes, bit)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    model = CustomNN(bits = bit).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr, weight_decay)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epoch):  # Example epoch count\n",
    "        #current_time = time.strftime('%H:%M:%S', time.localtime(time.time()))\n",
    "        #print(\"%s[%2d/%2d][%s] bit:%d, dataset:%s, training....\" % (\n",
    "        #\"DPSH\", epoch + 1, num_epoch, current_time, bit, \"CIFAR\"), end=\"\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for image, label, ind in train_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            u = model(image)\n",
    "\n",
    "            loss = customLoss(u, label.float(), ind, eta)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / (train_size / batch_size)\n",
    "        #print(\"\\b\\b\\b\\b\\b\\b\\b loss:%.5f\" % (train_loss))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPSH12Nus = DPSH(device, 5002, 21, 12, 150, 128, [0.01, 0.05, 0.1], [1e-6, 1e-5, 1e-4], [1e-6, 1e-5, 1e-4])\n",
    "DPSH24Nus = DPSH(device, 5002, 21, 24, 150, 128, [0.01, 0.05, 0.1], [1e-6, 1e-5, 1e-4], [1e-6, 1e-5, 1e-4])\n",
    "DPSH32Nus = DPSH(device, 5002, 21, 32, 150, 128, [0.01, 0.05, 0.1], [1e-6, 1e-5, 1e-4], [1e-6, 1e-5, 1e-4])\n",
    "DPSH48Nus = DPSH(device, 5002, 21, 48, 150, 128, [0.01, 0.05, 0.1], [1e-6, 1e-5, 1e-4], [1e-6, 1e-5, 1e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.05, 'learning_rate': 0.0001, 'weight_decay': 1e-06}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "DPSH48Cifar = {'eta': 0.05, 'learning_rate': 1e-05, 'weight_decay': 1e-05}\n",
    "DPSH32Cifar = {'eta': 0.1, 'learning_rate': 1e-05, 'weight_decay': 1e-05}\n",
    "DPSH24Cifar = {'eta': 0.1, 'learning_rate': 1e-05, 'weight_decay': 0.0001}\n",
    "DPSH12Cifar = {'eta': 0.01, 'learning_rate': 1e-05, 'weight_decay': 1e-06}\n",
    "DPSH12Img = {'eta': 0.1, 'learning_rate': 1e-06, 'weight_decay': 1e-06}\n",
    "DPSH24Img = {'eta': 0.1, 'learning_rate': 1e-06, 'weight_decay': 1e-05}\n",
    "DPSH32Img = {'eta': 0.1, 'learning_rate': 1e-06, 'weight_decay': 1e-06}\n",
    "DPSH48Img = {'eta': 0.1, 'learning_rate': 1e-06, 'weight_decay': 1e-06}\n",
    "DPSH12Nus = {'eta': 0.05, 'learning_rate': 0.0001, 'weight_decay': 1e-05}\n",
    "DPSH24Nus = {'eta': 0.01, 'learning_rate': 0.0001, 'weight_decay': 1e-05}\n",
    "DPSH32Nus = {'eta': 0.05, 'learning_rate': 0.0001, 'weight_decay': 0.0001}\n",
    "DPSH48Nus = {'eta': 0.05, 'learning_rate': 0.0001, 'weight_decay': 1e-06}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "Order Preserved: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Dummy dataset\n",
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.data = torch.arange(size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = DummyDataset(size=20)\n",
    "batch_size = 4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Collect all batches and verify order\n",
    "all_batches = []\n",
    "for batch in dataloader:\n",
    "    all_batches.append(batch)\n",
    "\n",
    "# Concatenate all batches\n",
    "concatenated = torch.cat(all_batches)\n",
    "\n",
    "# Check if order is preserved\n",
    "original = torch.arange(len(dataset))\n",
    "order_preserved = torch.equal(original, concatenated)\n",
    "\n",
    "print(\"Concatenated Tensor:\", concatenated)\n",
    "print(\"Order Preserved:\", order_preserved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "Order Preserved: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a tensor\n",
    "data = torch.arange(20)\n",
    "\n",
    "# Wrap the tensor with a DataLoader\n",
    "batch_size = 4\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Collect all batches and verify order\n",
    "all_batches = []\n",
    "for batch in dataloader:\n",
    "    all_batches.append(batch)\n",
    "\n",
    "# Concatenate all batches\n",
    "concatenated = torch.cat(all_batches)\n",
    "\n",
    "# Check if order is preserved\n",
    "original = torch.arange(len(data))\n",
    "order_preserved = torch.equal(original, concatenated)\n",
    "\n",
    "print(\"Concatenated Tensor:\", concatenated)\n",
    "print(\"Order Preserved:\", order_preserved)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
