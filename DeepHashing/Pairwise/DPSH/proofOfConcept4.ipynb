{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import random\n",
    "from torchvision import models, transforms\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root = '../../'\n",
    "sys.path.append(root)\n",
    "from HelpfulFunctions.batchCreation import createBatch\n",
    "from HelpfulFunctions.metrics import meanAveragePrecision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load( root + \"Features/train_features_vgg16_cifar10.npy\" ) # Shape = (45000, 4096)\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train = np.load( root + \"Features/train_labels_vgg16_cifar10.npy\" ) # Shape = (45000,)\n",
    "\n",
    "\n",
    "X_test = np.load( root + \"Features/test_features_vgg16_cifar10.npy\" ) # Shape = (10000, 4096)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test = np.load( root + \"Features/test_labels_vgg16_cifar10.npy\" ) # Shape = (10000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataset(root, num_classes, batch_size, train = True):\n",
    "    if train == True:\n",
    "        #Create X_train_tensor\n",
    "        X_train = np.load( root + \"Features/train_features_vgg16_cifar10.npy\" ) # Shape = (45000, 4096)\n",
    "        X_train_tensor = torch.tensor(X_train)\n",
    "\n",
    "        #Create Y_train_tensor\n",
    "        y_train = np.load( root + \"Features/train_labels_vgg16_cifar10.npy\" ) # Shape = (45000,)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        y_train_tensor = torch.nn.functional.one_hot(y_train_tensor, num_classes) #One-Hot Encoded -> Shape = (45000, num_classes)\n",
    "\n",
    "        #Create indices\n",
    "        indices = torch.arange(len(X_train_tensor))\n",
    "\n",
    "        dataset = TensorDataset(X_train_tensor, y_train_tensor, indices)\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    #Missing implementation for Test and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = CreateDataset(root, num_classes = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(4096, 1024),  # First fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 48),    # Second fully connected layer to reduce to 4000\n",
    "        )\n",
    "\n",
    "        # Initialize weights and biases from gaussian distribution\n",
    "        for layer in self.fc_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=0.01)  # Initialize weights based on paper\n",
    "                nn.init.normal_(layer.bias, mean=0.0, std=0.01)    # Initialize biases based on paper\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPSHLoss(torch.nn.Module):\n",
    "    def __init__(self, train_size, n_classes, bit):\n",
    "        super(DPSHLoss, self).__init__()\n",
    "        self.U = torch.zeros(train_size, bit).float().to(device)\n",
    "        self.Y = torch.zeros(train_size, n_classes).float().to(device)\n",
    "\n",
    "    def forward(self, u, y, ind, eta):\n",
    "        self.U[ind, :] = u.data\n",
    "        self.Y[ind, :] = y.float()\n",
    "\n",
    "        s = (y @ self.Y.t() > 0).float()\n",
    "        inner_product = u @ self.U.t() * 0.5\n",
    "\n",
    "        likelihood_loss = (1 + (-(inner_product.abs())).exp()).log() + inner_product.clamp(min=0) - s * inner_product\n",
    "\n",
    "        likelihood_loss = likelihood_loss.mean()\n",
    "\n",
    "        quantization_loss = eta * (u - u.sign()).pow(2).mean()\n",
    "\n",
    "        return likelihood_loss + quantization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(device, X_train_tensor, y_train, train_size, batch_size, n_classes, bit, num_epoch, lr):\n",
    "\n",
    "    num_batches = train_size / batch_size\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    criterion = DPSHLoss(train_size, n_classes, bit)\n",
    "\n",
    "\n",
    "    #model.train()\n",
    "\n",
    "    #Best_mAP = 0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        current_time = time.strftime('%H:%M:%S', time.localtime(time.time()))\n",
    "\n",
    "        print(\"%s[%2d/%2d][%s] bit:%d, dataset:%s, training....\" % (\n",
    "            \"DPSH\", epoch + 1, num_epoch, current_time, bit, \"CIFAR\"), end=\"\")\n",
    "\n",
    "        train_loss = 0\n",
    "        for image, label, ind in train_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            u = model(image)\n",
    "\n",
    "\n",
    "            loss = criterion(u, label.float(), ind, lr)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / (train_size / batch_size)\n",
    "\n",
    "        print(\"\\b\\b\\b\\b\\b\\b\\b loss:%.5f\" % (train_loss))\n",
    "\n",
    "        #if (epoch + 1) % config[\"test_map\"] == 0:\n",
    "            #Best_mAP = validate(config, Best_mAP, test_loader, dataset_loader, net, bit, epoch, num_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([128, 4096])\n",
      "y_batch shape: torch.Size([128, 10])\n",
      "index: [24537, 3169, 28218, 19101, 33748, 22950, 24920, 43712, 12844, 14679, 29841, 25541, 18170, 39498, 22498, 43331, 22797, 31116, 43760, 28106, 35695, 5553, 44256, 18495, 41903, 21266, 43520, 22004, 11852, 29611, 37479, 1833, 14885, 34272, 31900, 39101, 8938, 19987, 16481, 3501, 20774, 25222, 44651, 11930, 18174, 21043, 19311, 38530, 16773, 9039, 19364, 41085, 30653, 11661, 37551, 24866, 15791, 16285, 30489, 27225, 13307, 14659, 27826, 19397, 11492, 44101, 38720, 21494, 36214, 41854, 37268, 22770, 22218, 17015, 32168, 28242, 37728, 16717, 26209, 15731, 9232, 20525, 2302, 1191, 8831, 8040, 24937, 35759, 30582, 41430, 17203, 40685, 42114, 23253, 9597, 29584, 13539, 42145, 24903, 4428, 38802, 980, 15339, 42010, 15444, 38427, 32480, 27259, 15351, 17766, 21811, 18229, 38711, 24572, 19504, 27285, 11878, 30917, 14630, 44192, 29624, 42711, 42614, 2192, 34469, 42475, 20635, 6435]\n"
     ]
    }
   ],
   "source": [
    "X_batch, y_batch, index = createBatch(X_train_tensor, y_train, batch_size = 128, oneHot = 10)\n",
    "print(\"X_batch shape:\", X_batch.shape)  # Should be (batch_size, num_features)\n",
    "print(\"y_batch shape:\", y_batch.shape)  # Should be (batch_size, num_classes)\n",
    "print(\"index:\", index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPSH[ 1/150][21:15:07] bit:48, dataset:CIFAR, training... loss:0.79733\n",
      "DPSH[ 2/150][21:15:09] bit:48, dataset:CIFAR, training... loss:0.77960\n",
      "DPSH[ 3/150][21:15:12] bit:48, dataset:CIFAR, training... loss:0.78334\n",
      "DPSH[ 4/150][21:15:14] bit:48, dataset:CIFAR, training... loss:0.78391\n",
      "DPSH[ 5/150][21:15:17] bit:48, dataset:CIFAR, training... loss:0.78409\n",
      "DPSH[ 6/150][21:15:19] bit:48, dataset:CIFAR, training... loss:0.78402\n",
      "DPSH[ 7/150][21:15:21] bit:48, dataset:CIFAR, training... loss:0.78449\n",
      "DPSH[ 8/150][21:15:24] bit:48, dataset:CIFAR, training... loss:0.78555\n",
      "DPSH[ 9/150][21:15:26] bit:48, dataset:CIFAR, training... loss:0.78661\n",
      "DPSH[10/150][21:15:29] bit:48, dataset:CIFAR, training... loss:0.78781\n",
      "DPSH[11/150][21:15:32] bit:48, dataset:CIFAR, training... loss:0.78895\n",
      "DPSH[12/150][21:15:35] bit:48, dataset:CIFAR, training... loss:0.78911\n",
      "DPSH[13/150][21:15:38] bit:48, dataset:CIFAR, training... loss:0.78881\n",
      "DPSH[14/150][21:15:41] bit:48, dataset:CIFAR, training... loss:0.78942\n",
      "DPSH[15/150][21:15:44] bit:48, dataset:CIFAR, training... loss:0.79062\n",
      "DPSH[16/150][21:15:48] bit:48, dataset:CIFAR, training... loss:0.78924\n",
      "DPSH[17/150][21:15:51] bit:48, dataset:CIFAR, training... loss:0.78624\n",
      "DPSH[18/150][21:15:54] bit:48, dataset:CIFAR, training... loss:0.78529\n",
      "DPSH[19/150][21:15:57] bit:48, dataset:CIFAR, training... loss:0.78618\n",
      "DPSH[20/150][21:15:59] bit:48, dataset:CIFAR, training... loss:0.78664\n",
      "DPSH[21/150][21:16:01] bit:48, dataset:CIFAR, training... loss:0.78674\n",
      "DPSH[22/150][21:16:03] bit:48, dataset:CIFAR, training... loss:0.78701\n",
      "DPSH[23/150][21:16:06] bit:48, dataset:CIFAR, training...."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m45000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[102], line 31\u001b[0m, in \u001b[0;36mtrain_val\u001b[1;34m(device, X_train_tensor, y_train, train_size, batch_size, n_classes, bit, num_epoch, lr)\u001b[0m\n\u001b[0;32m     27\u001b[0m u \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(u, label\u001b[38;5;241m.\u001b[39mfloat(), ind, lr)\n\u001b[1;32m---> 31\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_val(device, X_train_tensor, y_train, train_size = 45000, batch_size = 128, n_classes = 10, bit = 48, num_epoch = 150, lr = 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
