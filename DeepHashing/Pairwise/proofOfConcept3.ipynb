{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import random\n",
    "from torchvision import models, transforms\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "root = '../../'\n",
    "sys.path.append(root)\n",
    "from HelpfulFunctions.BatchCreation import CreateBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load( root + \"Features/train_features_vgg16_cifar10.npy\" ) # Shape = (50000, 4096)\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train = np.load( root + \"Features/train_labels_vgg16_cifar10.npy\" ) # Shape = (50000,)\n",
    "\n",
    "X_test = np.load( root + \"Features/test_features_vgg16_cifar10.npy\" ) # Shape = (10000, 4096)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test = np.load( root + \"Features/test_labels_vgg16_cifar10.npy\" ) # Shape = (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(4096, 256),  # First fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32)    # Second fully connected layer to reduce to 4000\n",
    "        )\n",
    "\n",
    "        # Initialize weights and biases from gaussian distribution\n",
    "        for layer in self.fc_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=0.01)  # Initialize weights\n",
    "                nn.init.normal_(layer.bias, mean=0.0, std=0.01)    # Initialize biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, eta = 0.25):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.eta = eta\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        #S calculation\n",
    "        targets = torch.tensor(targets)\n",
    "        S = (targets[:, None] == targets).float() # Shape = (sample_size, sample_size)\n",
    "\n",
    "\n",
    "        #U calculation\n",
    "        U = outputs\n",
    "\n",
    "        #Calculate Theta\n",
    "        dot_product_matrix = torch.matmul(U, U.T)\n",
    "        dot_product_matrix # (sample_size, sample_size) Shape\n",
    "        Theta = 1/2 * dot_product_matrix\n",
    "\n",
    "\n",
    "        #Calculate hash codes\n",
    "        B = torch.sign(U) # Shape = (sample_size, hash_length)\n",
    "\n",
    "\n",
    "        loss = - torch.sum(S * Theta - torch.log(1 + torch.exp(Theta))) + self.eta * torch.sum(torch.norm(B - U, dim = 1).pow(2))\n",
    "        #print(loss) # Should give tensor(loss, grad_fn) NO CLUE HVAD GRAD_FN ER, NOK HVORDAN GRADIENT SKAL UDREGNES\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Custom_loss And Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_loss = CustomLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #Create batch for current iteration\n",
    "    X_batch_tensor, y_batch = CreateBatch(X_train_tensor, y_train, 100)\n",
    "\n",
    "    # Zero gradients from the previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Calculate outputs using model\n",
    "    outputs = model(X_batch_tensor)\n",
    "\n",
    "    # Forward pass\n",
    "    loss = custom_loss(outputs, y_batch)\n",
    "    \n",
    "    \n",
    "    # Backward pass to compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters using optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Optionally, print loss for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hashcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_train = torch.sign(model(X_train_tensor))\n",
    "hash_test = torch.sign(model(X_test_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Perform K-Means Clustering\n",
    "def kmeans_clustering(hash_codes, n_clusters=10, n_init=10, random_state=42):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, random_state=random_state)\n",
    "    clusters = kmeans.fit_predict(hash_codes)\n",
    "    return clusters\n",
    "\n",
    "# Step 2: Build the label-cluster matrix\n",
    "def build_label_cluster_matrix(clusters, true_labels, n_clusters=10):\n",
    "    # Initialize a matrix to count label-cluster relationships  \n",
    "    label_cluster_matrix = np.zeros((10, n_clusters), dtype=int)\n",
    "    \n",
    "    for label, cluster in zip(true_labels, clusters):\n",
    "        label_cluster_matrix[label][cluster] += 1\n",
    "    \n",
    "    return label_cluster_matrix\n",
    "\n",
    "# Step 3: Visualize the result as a heatmap\n",
    "def plot_heatmap(label_cluster_matrix):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(label_cluster_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True)\n",
    "    plt.title(\"Label Distribution Across Clusters\")\n",
    "    plt.xlabel(\"Clusters\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def easyHeatmap(hashCodes, labels):\n",
    "    raw_clusters = kmeans_clustering(hashCodes, n_clusters=10)\n",
    "\n",
    "    raw_label_cluster_matrix = build_label_cluster_matrix(raw_clusters, labels)\n",
    "\n",
    "    plot_heatmap(raw_label_cluster_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
