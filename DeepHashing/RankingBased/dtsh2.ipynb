{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse.linalg import eigsh\n",
    "#from pretrainedModel import pretrainedModel\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "root = '../../'\n",
    "bits = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 3, 2,  ..., 1, 5, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor( np.load( root + r\"Features/HPO og Validering/CIFAR/y_hpo_CIfar.npy\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar():\n",
    "    \"\"\"    \n",
    "    X_train, y_train, X_val, y_val\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train = torch.tensor( np.load( root + r\"Features/HPO og Validering/CIFAR/X_hpo_Cifar.npy\" ) )\n",
    "    y_train = torch.tensor( np.load( root + r\"Features/HPO og Validering/CIFAR/y_hpo_CIfar.npy\" ) )\n",
    "\n",
    "    label_amnt = len(y_train.unique())\n",
    "    y_train = torch.nn.functional.one_hot(y_train, label_amnt)\n",
    "\n",
    "    X_val = torch.tensor( np.load( root + r\"Features/HPO og Validering/CIFAR/X_val_Cifar.npy\" ) )\n",
    "    y_val = torch.tensor( np.load( root + r\"Features/HPO og Validering/CIFAR/y_val_Cifar.npy\" ) )\n",
    "\n",
    "    label_amnt = len(y_val.unique())\n",
    "    y_val = torch.nn.functional.one_hot(y_val, label_amnt)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "def get_dataloader(file):\n",
    "    \"\"\"\n",
    "    \"cifar\"\n",
    "\n",
    "    \"\"\"\n",
    "    file = file.lower()\n",
    "    legal_files = [\"cifar\"]\n",
    "    if file not in legal_files:\n",
    "        raise ValueError(f'The given file name was \"{file}\", expected from {legal_files}')\n",
    "\n",
    "\n",
    "    # == LOAD IN THE DATA ==\n",
    "    if file == \"cifar\":\n",
    "        X_train, y_train, _, _ = get_cifar()\n",
    "\n",
    "\n",
    "    # == MAKE DATA LOADER ==\n",
    "    train_data = []\n",
    "    for i in range(len(X_train)):\n",
    "        train_data.append([X_train[i], y_train[i]])\n",
    "    dataloader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "for i,batch  in enumerate(get_dataloader(\"cifar\")):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTSHLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DTSHLoss, self).__init__()\n",
    "\n",
    "    def forward(self, u, y, LAMBDA=1, ALPHA=1):\n",
    "        #LAMBDA = 1\n",
    "        #ALPHA  = 1\n",
    "\n",
    "        inner_product = u @ u.t()   # Similarity Matrix\n",
    "        s = y @ y.t() > 0           # A matrix that show if the two idexes are the same or not\n",
    "        count = 0\n",
    "\n",
    "        loss1 = 0\n",
    "        for row in range(s.shape[0]):\n",
    "            # if has positive pairs and negative pairs\n",
    "            if s[row].sum() != 0 and (~s[row]).sum() != 0:\n",
    "                count += 1\n",
    "                theta_positive = inner_product[row][s[row] == 1]                \n",
    "                theta_negative = inner_product[row][s[row] == 0]\n",
    "\n",
    "                triple = (theta_positive.unsqueeze(1) - theta_negative.unsqueeze(0) - ALPHA ).clamp(min=-100,max=50)\n",
    "                loss1 += -(triple - torch.log(1 + torch.exp(triple))).mean()\n",
    "\n",
    "        if count != 0:\n",
    "            loss1 = loss1 / count\n",
    "        else:\n",
    "            loss1 = 0\n",
    "\n",
    "        loss2 = LAMBDA * (u - u.sign()).pow(2).mean()\n",
    "\n",
    "        return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def one_hot_encode(a):\n",
    "    b = np.zeros((a.size, a.max() + 1))\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    return b\n",
    "\n",
    "def mean_average_precision(test_hashes, training_hashes, test_labels, training_labels):\n",
    "    aps = []\n",
    "    if len(training_labels.shape) == 1:\n",
    "        training_labels = one_hot_encode(training_labels)\n",
    "        test_labels = one_hot_encode(test_labels)\n",
    "    for i, test_hash in enumerate(tqdm(test_hashes)):\n",
    "        label = test_labels[i]\n",
    "        distances = np.abs(training_hashes - test_hashes[i]).sum(axis=1)\n",
    "        tp = np.where((training_labels*label).sum(axis=1)>0, 1, 0)\n",
    "        hash_df = pd.DataFrame({\"distances\":distances, \"tp\":tp}).reset_index()\n",
    "        hash_df = hash_df.sort_values([\"distances\", \"index\"]).reset_index(drop=True)\n",
    "        hash_df = hash_df.drop([\"index\", \"distances\"], axis=1).reset_index()\n",
    "        hash_df = hash_df[hash_df[\"tp\"]==1]\n",
    "        hash_df[\"tp\"] = hash_df[\"tp\"].cumsum()\n",
    "        hash_df[\"index\"] = hash_df[\"index\"] +1 \n",
    "        precision = np.array(hash_df[\"tp\"]) / np.array(hash_df[\"index\"])\n",
    "        ap = precision.mean()\n",
    "        aps.append(ap)\n",
    "    \n",
    "    return np.array(aps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earlyStop(LossList, n = 10):\n",
    "    bestVal = min(LossList)\n",
    "\n",
    "    bestVal_i = LossList.index(bestVal)\n",
    "\n",
    "    if bestVal_i < len(LossList) - n: return True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(X, model):\n",
    "    results =  model(X)\n",
    "    results = results.detach().numpy()\n",
    "\n",
    "    results = (results > 0).astype(int) \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HPO(HP):\n",
    "    # LAMBDA=1, \n",
    "    # ALPHA=1\n",
    "    # lr=1e-5\n",
    "    # weight_decay=1e-5\n",
    "    # bits = 16\n",
    "\n",
    "    LAMBDA= HP[\"lambda\"] \n",
    "    ALPHA=  HP[\"alpha\"]\n",
    "    lr=     HP[\"lr\"]\n",
    "    weight_decay= HP[\"wd\"]\n",
    "    bits = HP[\"bits\"]\n",
    "\n",
    "\n",
    "    model = nn.Sequential(  nn.Linear(4096,256),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(256, bits),\n",
    "                            )\n",
    "\n",
    "    criterion = DTSHLoss()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=lr , weight_decay=weight_decay)\n",
    "\n",
    "    dataloader = get_dataloader(\"cifar\")\n",
    "    historical_lostList = []\n",
    "    for i in range(1500):\n",
    "        loss_list = []\n",
    "        for j,batch  in enumerate(dataloader):\n",
    "            X_batch = batch[0]\n",
    "            y_batch = batch[1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            u = model(X_batch)\n",
    "            loss = criterion(u, y_batch.float(), LAMBDA=LAMBDA, ALPHA=ALPHA)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_list.append( float(loss) )\n",
    "        \n",
    "        \n",
    "        mean_loss = sum(loss_list) / len(loss_list)\n",
    "        if i % 10 == 1:\n",
    "            print(i, mean_loss)\n",
    "        historical_lostList.append(mean_loss)\n",
    "\n",
    "        if earlyStop(historical_lostList, n = 20): \n",
    "            print(i, mean_loss)\n",
    "            print(\"Early Stop!!!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    # === EVALUATE ===\n",
    "    X_train, y_train, X_val, y_val = get_cifar()\n",
    "\n",
    "    data = {}\n",
    "    data[\"hp\"] = HP\n",
    "    data[\"loss\"] = historical_lostList\n",
    "    data[\"map\"] = mean_average_precision(test_hashes=res(X_val, model), training_hashes=res(X_train, model), test_labels=y_val, training_labels=y_train)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combos(D):\n",
    "    l = list(D)\n",
    "    curr_i = dict(zip(l,[0]*len(l)))\n",
    "    combos = []\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(l)):\n",
    "            val = l[i]\n",
    "\n",
    "            if curr_i[val] > (len(D[val])-1):\n",
    "                curr_i[val] = 0\n",
    "                \n",
    "                if i+1 != len(l):\n",
    "                    curr_i[ l[i+1] ] += 1                    \n",
    "                else:\n",
    "                    return combos                    \n",
    "\n",
    "        combo = deepcopy(D)\n",
    "        for key in curr_i:\n",
    "            list_ = combo[key]\n",
    "            index = curr_i[key] \n",
    "             \n",
    "            combo[key] = list_[index]\n",
    "\n",
    "        combos.append( combo )\n",
    "        curr_i[l[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "def save_dict(d, path):\n",
    "    # === CLEAN PATH ===\n",
    "    path = path.replace(\"\\\\\", \"/\") # Ensures that it's always \"/\" and not \"\\\"\n",
    "\n",
    "    if path[-1] != \"/\": # Ensures that path ends with \"/\"\n",
    "        path += \"/\"\n",
    "\n",
    "    # === DEFINE FOLDER ===\n",
    "    folder_path = f\"{path}{os.environ['COMPUTERNAME']}\"\n",
    "\n",
    "    if not os.path.exists(folder_path): # Makes the Path if it doesn't exist\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # === DEFINE FILE NAME/PATH ===\n",
    "    now = str(datetime.datetime.now())\n",
    "    now = now[:now.index(\".\")].replace(\" \", \"_\").replace(\":\", \";\")\n",
    "\n",
    "    filePath = f\"{folder_path}/{now}.json\"\n",
    "\n",
    "    # === SAVE FILE ===\n",
    "    with open(filePath, \"w\") as fp:\n",
    "        json.dump(d , fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "{'lambda': 0.5, 'alpha': 0.5, 'lr': 0.0001, 'wd': 0.0001, 'bits': 12}\n",
      "1 0.45304609298706056\n",
      "11 0.27259749233722685\n",
      "21 0.20287711828947066\n",
      "31 0.16110509708523751\n",
      "41 0.12687018796801566\n",
      "51 0.1100686851143837\n",
      "61 0.08842064931988716\n",
      "71 0.08461065165698528\n",
      "81 0.06515292994678021\n",
      "91 0.06334872767329217\n",
      "101 0.05832636781036854\n",
      "111 0.05740471601486206\n",
      "121 0.046654238626360894\n",
      "131 0.051035604998469354\n",
      "141 0.038449977338314054\n",
      "151 0.04534109212458134\n",
      "161 0.041299344524741176\n",
      "171 0.0390989600494504\n",
      "181 0.03217027191072702\n",
      "191 0.03219738736748695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 760.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hp': {'lambda': 0.5, 'alpha': 0.5, 'lr': 0.0001, 'wd': 0.0001, 'bits': 12}, 'loss': [1.1490629774332046, 0.45304609298706056, 0.40761515974998475, 0.38615551829338074, 0.3645141625404358, 0.34951023042201995, 0.33676176190376284, 0.3246812230348587, 0.3109441050887108, 0.2945237347483635, 0.2846969649195671, 0.27259749233722685, 0.2687932774424553, 0.2561223044991493, 0.24275815099477768, 0.24823377937078475, 0.23421849578619003, 0.22583379328250885, 0.22064979910850524, 0.21170886874198913, 0.20482995897531509, 0.20287711828947066, 0.20210463106632232, 0.19022259175777434, 0.18752935588359831, 0.19024583399295808, 0.1812731795012951, 0.17033196598291397, 0.1704340758919716, 0.16369929611682893, 0.16525931149721146, 0.16110509708523751, 0.1543874190747738, 0.1514212094247341, 0.14926185443997383, 0.1482391183078289, 0.14124933242797852, 0.13699621111154556, 0.13631986305117608, 0.13470687717199326, 0.13430650115013124, 0.12687018796801566, 0.12234171003103256, 0.12551231041550637, 0.12160851195454597, 0.12099601805210114, 0.11625836938619613, 0.11793302401900291, 0.10974749267101287, 0.1112294228374958, 0.10667596891522407, 0.1100686851143837, 0.10450692340731621, 0.10576457530260086, 0.10043562084436417, 0.10128938794136047, 0.10035286039113998, 0.09589129745960236, 0.09996980145573615, 0.09296964645385743, 0.09371850550174714, 0.08842064931988716, 0.0895038405060768, 0.09206083059310913, 0.08451040148735046, 0.08824973583221435, 0.08272710397839546, 0.08562282323837281, 0.08167079038918018, 0.08376047745347023, 0.07674114987254142, 0.08461065165698528, 0.07684587046504021, 0.07726193621754646, 0.07600168079137802, 0.07858815938234329, 0.07123951569199562, 0.07243850007653237, 0.07610816359519959, 0.07315393097698689, 0.07670786522328854, 0.06515292994678021, 0.07351890318095684, 0.06329329520463943, 0.06907770678400993, 0.06573727548122406, 0.0694153892993927, 0.06389232724905014, 0.0664928225427866, 0.06571825675666332, 0.05913910672068596, 0.06334872767329217, 0.0644002777338028, 0.062075430154800416, 0.06020253174006939, 0.057630887925624846, 0.06270364798605442, 0.058098638951778414, 0.057085633873939515, 0.0580406254529953, 0.05880018070340157, 0.05832636781036854, 0.057707727923989295, 0.05584269523620605, 0.05596739739179611, 0.05313941806554794, 0.056526868641376495, 0.05306915491819382, 0.05519774325191975, 0.05266760796308517, 0.049585792124271395, 0.05740471601486206, 0.048341443687677385, 0.05323830954730511, 0.04987914532423019, 0.05122514262795448, 0.05283616177737713, 0.04841310687363148, 0.04728174015879631, 0.05145072862505913, 0.049166018664836886, 0.046654238626360894, 0.04682193391025066, 0.05299287848174572, 0.046476630046963695, 0.042161953300237656, 0.049897823631763455, 0.04835533753037453, 0.04007693078368902, 0.044911160692572595, 0.04954741232097149, 0.051035604998469354, 0.03929543048143387, 0.04358692243695259, 0.04519011788070202, 0.04166777886450291, 0.04279520906507969, 0.046486249789595604, 0.05079785734415054, 0.037484516128897666, 0.0421483975276351, 0.038449977338314054, 0.044765071868896486, 0.04327111907303333, 0.04292873952537775, 0.04045818615704775, 0.03920405931770801, 0.03897857576608658, 0.04490174487233162, 0.03962285961955786, 0.03940806411206722, 0.04534109212458134, 0.033442167416214946, 0.04050952319055796, 0.03964702446013689, 0.04206975221633911, 0.037156045734882355, 0.039235769771039486, 0.040570856593549254, 0.03810591120272875, 0.0355077513307333, 0.041299344524741176, 0.04141918756067753, 0.03270747404545546, 0.0357949473336339, 0.04185168199241161, 0.035870989263057707, 0.036760800369083885, 0.04285165634006262, 0.031340236738324166, 0.03543402783572674, 0.0390989600494504, 0.03555875070393086, 0.03542640782892704, 0.03406533963978291, 0.040442462451756, 0.03290126822888851, 0.036181757673621175, 0.03645424447953701, 0.03443159088492394, 0.03577737778425217, 0.03217027191072702, 0.044162481389939785, 0.028596862889826297, 0.040271256007254126, 0.03072894237935543, 0.030769038274884225, 0.032335854433476925, 0.03744415111839771, 0.030576594956219196, 0.03471382196992636, 0.03219738736748695, 0.03656404979526997, 0.03782232366502285, 0.02730807915329933, 0.03866829831153154, 0.029914506413042545, 0.033557230159640315, 0.03867696698755026, 0.0336209686845541], 'map': 0.7996869939942403}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'lambda': 1, 'alpha': 0.5, 'lr': 0.0001, 'wd': 0.0001, 'bits': 12}\n",
      "1 0.5337165087461472\n",
      "11 0.35195569455623626\n",
      "21 0.2740262460708618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(hp)\n\u001b[1;32m---> 13\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m  \u001b[43mHPO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_dict)\n\u001b[0;32m     16\u001b[0m save_dict(result_dict, root\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHPO\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDTSH\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mHPO\u001b[1;34m(HP)\u001b[0m\n\u001b[0;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     33\u001b[0m u \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m---> 34\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAMBDA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLAMBDA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mALPHA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALPHA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mDTSHLoss.forward\u001b[1;34m(self, u, y, LAMBDA, ALPHA)\u001b[0m\n\u001b[0;32m     19\u001b[0m         theta_negative \u001b[38;5;241m=\u001b[39m inner_product[row][s[row] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m         triple \u001b[38;5;241m=\u001b[39m (theta_positive\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m theta_negative\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m ALPHA )\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m         loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43m(\u001b[49m\u001b[43mtriple\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtriple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     25\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m loss1 \u001b[38;5;241m/\u001b[39m count\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "HP = {\n",
    "    \"lambda\" : [0.5 , 1, 2, 4],\n",
    "    \"alpha\"  : [0.5 , 1, 2, 4],\n",
    "    \"lr\"     : [1e-4 ,1e-5, 1e-6],\n",
    "    \"wd\"     : [1e-4 ,1e-5, 1e-6],\n",
    "    \"bits\"   : [12, 24, 32, 48]\n",
    "}\n",
    "\n",
    "\n",
    "for hp in get_combos(HP):\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(hp)\n",
    "    result_dict =  HPO(hp)\n",
    "    print(result_dict)\n",
    "\n",
    "    save_dict(result_dict, root+r\"Results\\HPO\\DTSH\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
