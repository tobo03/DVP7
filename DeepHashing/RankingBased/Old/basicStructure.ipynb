{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def getDataset(train=True, sample_size=10):\n",
    "    dataset = CIFAR10(root='./data',\n",
    "                  train=train, \n",
    "                  download=True,\n",
    "                  transform=transform)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        X.append( dataset[i][0] )\n",
    "        y.append( dataset[i][1] )\n",
    "\n",
    "    X = torch.stack( X )\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "pretrained_model = models.vgg16(pretrained=True)\n",
    "pretrained_model.classifier = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "test_model = nn.Sequential(  nn.Flatten(),\n",
    "                        nn.Linear(25088,256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(256,32),\n",
    "                        nn.Sigmoid()\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5156, 0.4813, 0.4866, 0.4827, 0.4496, 0.4007, 0.4776, 0.4451, 0.4116,\n",
       "         0.4792, 0.4731, 0.5263, 0.4515, 0.5255, 0.4766, 0.5852, 0.5386, 0.4828,\n",
       "         0.5729, 0.5244, 0.4979, 0.4503, 0.5051, 0.4483, 0.5544, 0.4927, 0.5381,\n",
       "         0.4984, 0.4521, 0.4460, 0.5093, 0.5168],\n",
       "        [0.4603, 0.5174, 0.5442, 0.5188, 0.4018, 0.4602, 0.5060, 0.4857, 0.4586,\n",
       "         0.4568, 0.5022, 0.4644, 0.4079, 0.4949, 0.4776, 0.6046, 0.5302, 0.4781,\n",
       "         0.5595, 0.5263, 0.5313, 0.4570, 0.4646, 0.5255, 0.5440, 0.4750, 0.5996,\n",
       "         0.4745, 0.4207, 0.4642, 0.5184, 0.4903],\n",
       "        [0.4509, 0.4936, 0.5030, 0.4751, 0.4276, 0.4099, 0.5023, 0.4583, 0.4311,\n",
       "         0.4921, 0.4393, 0.4780, 0.4717, 0.4809, 0.5130, 0.5722, 0.5053, 0.5066,\n",
       "         0.5152, 0.5019, 0.4946, 0.4670, 0.4489, 0.4808, 0.5494, 0.5219, 0.5026,\n",
       "         0.4701, 0.4527, 0.4936, 0.4941, 0.5003],\n",
       "        [0.5042, 0.5177, 0.4914, 0.4937, 0.4912, 0.4869, 0.4909, 0.4863, 0.4758,\n",
       "         0.4977, 0.5267, 0.5378, 0.4722, 0.4950, 0.4966, 0.5241, 0.4895, 0.4851,\n",
       "         0.5516, 0.5217, 0.4857, 0.4765, 0.5028, 0.4828, 0.4943, 0.5064, 0.5195,\n",
       "         0.4867, 0.4566, 0.4886, 0.4965, 0.4906],\n",
       "        [0.4949, 0.5013, 0.5272, 0.4325, 0.3885, 0.4426, 0.5031, 0.4965, 0.4346,\n",
       "         0.5255, 0.5191, 0.5189, 0.4395, 0.4331, 0.5196, 0.5182, 0.5163, 0.4550,\n",
       "         0.5195, 0.4967, 0.4498, 0.4236, 0.4693, 0.4861, 0.5376, 0.4900, 0.5617,\n",
       "         0.4943, 0.4533, 0.4896, 0.5733, 0.4841],\n",
       "        [0.4387, 0.5204, 0.4844, 0.5325, 0.4716, 0.4908, 0.4927, 0.4938, 0.4104,\n",
       "         0.5050, 0.4700, 0.5529, 0.4601, 0.4430, 0.4633, 0.5440, 0.5434, 0.5109,\n",
       "         0.5966, 0.4788, 0.4509, 0.4645, 0.5236, 0.5513, 0.5072, 0.4813, 0.5692,\n",
       "         0.4726, 0.3978, 0.4895, 0.5226, 0.4898],\n",
       "        [0.4394, 0.4514, 0.5481, 0.5289, 0.4061, 0.4615, 0.4905, 0.4734, 0.4350,\n",
       "         0.4607, 0.4776, 0.5293, 0.4292, 0.4807, 0.4612, 0.6088, 0.5122, 0.4808,\n",
       "         0.5295, 0.4772, 0.5215, 0.4420, 0.4780, 0.4961, 0.4784, 0.4804, 0.5546,\n",
       "         0.4696, 0.4526, 0.4477, 0.4823, 0.5343],\n",
       "        [0.4841, 0.5014, 0.5391, 0.4976, 0.4382, 0.4969, 0.4538, 0.4742, 0.3671,\n",
       "         0.5062, 0.5330, 0.4932, 0.4077, 0.5306, 0.5440, 0.5490, 0.5337, 0.4205,\n",
       "         0.5341, 0.5610, 0.5288, 0.4275, 0.5140, 0.4756, 0.5719, 0.4635, 0.4740,\n",
       "         0.4504, 0.3681, 0.5641, 0.5174, 0.5009],\n",
       "        [0.4982, 0.5150, 0.4916, 0.5263, 0.4970, 0.4388, 0.4961, 0.4773, 0.4452,\n",
       "         0.4857, 0.4488, 0.5417, 0.4629, 0.4761, 0.5034, 0.5716, 0.5281, 0.4835,\n",
       "         0.5148, 0.5187, 0.4426, 0.4698, 0.4875, 0.4793, 0.5294, 0.4816, 0.5107,\n",
       "         0.4518, 0.4494, 0.4621, 0.5289, 0.5208],\n",
       "        [0.4924, 0.4971, 0.4872, 0.5143, 0.4450, 0.5142, 0.5039, 0.4979, 0.4258,\n",
       "         0.4749, 0.5025, 0.5199, 0.4486, 0.5127, 0.5052, 0.5338, 0.5332, 0.4830,\n",
       "         0.5558, 0.5184, 0.4831, 0.4927, 0.4837, 0.5232, 0.5250, 0.4755, 0.5391,\n",
       "         0.4695, 0.4599, 0.4748, 0.4944, 0.4976]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(pretrained_model(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_model1 = models.vgg16(pretrained=True)\n",
    "pretrained_model1 = nn.Sequential(*list(pretrained_model1.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512, 7, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model1(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (3): ReLU(inplace=True)\n",
       "   (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (6): ReLU(inplace=True)\n",
       "   (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (8): ReLU(inplace=True)\n",
       "   (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (11): ReLU(inplace=True)\n",
       "   (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (13): ReLU(inplace=True)\n",
       "   (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (15): ReLU(inplace=True)\n",
       "   (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (18): ReLU(inplace=True)\n",
       "   (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (20): ReLU(inplace=True)\n",
       "   (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (22): ReLU(inplace=True)\n",
       "   (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (25): ReLU(inplace=True)\n",
       "   (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (27): ReLU(inplace=True)\n",
       "   (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (29): ReLU(inplace=True)\n",
       "   (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(7, 7))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pretrained_model1.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thors\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = models.vgg16(pretrained=True)\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.classifier = pretrained_model.classifier[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
