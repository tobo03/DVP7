{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from pretrainedModel import pretrainedModel\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this file, we will do spectral hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#x_train = scaler.fit_transform(x_train.reshape(x_train.shape[-0], -1)).reshape(x_train.shape)\n",
    "#x_test = scaler.fit_transform(x_test.reshape(x_test.shape[-0], -1)).reshape(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = x_train.reshape(x_train.shape[-0], -1)\n",
    "test_features = x_test.reshape(x_test.shape[-0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "images done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [07:52<00:00, 126.99it/s]\n",
      "100%|██████████| 10000/10000 [01:18<00:00, 127.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = pretrainedModel()\n",
    "print(\"model loaded\")\n",
    "# Process the images and move the output to the CPU for use in a list\n",
    "train_images = [Image.fromarray(image).convert('RGB') for image in x_train]\n",
    "test_images = [Image.fromarray(image).convert('RGB') for image in x_test]\n",
    "print(\"images done\")\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations for faster inference\n",
    "with torch.no_grad():\n",
    "    training_features = np.array([np.array(model(image).cpu()) for image in tqdm(train_images)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_features = np.array([np.array(model(image).cpu()) for image in tqdm(test_images)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\features\\training_features_cnn.npy', training_features)\n",
    "np.save(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\features\\test_features_cnn.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = np.load(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\features\\training_features_cnn.npy')\n",
    "test_features = np.load(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\features\\test_features_cnn.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "training_features = scaler.fit_transform(training_features)  # Standardize the data\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)  # Set the number of components to keep\n",
    "training_features = pca.fit_transform(training_features)  # Fit PCA on the standardized data and transform\n",
    "test_features = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=50).fit(training_features)\n",
    "\n",
    "# Find the nearest neighbors\n",
    "distances, indices = nbrs.kneighbors(training_features)\n",
    "\n",
    "# Create an adjacency matrix\n",
    "n_samples = training_features.shape[0]\n",
    "adjacency_matrix = np.zeros((n_samples, n_samples))\n",
    "\n",
    "# Populate the adjacency matrix\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for neighbor in neighbors:\n",
    "        adjacency_matrix[i, neighbor] = 1\n",
    "        adjacency_matrix[neighbor, i] = 1  # Ensure symmetry for an undirected graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [2:15:22<00:00,  7.39it/s]  \n"
     ]
    }
   ],
   "source": [
    "training_features = np.array(training_features)\n",
    "\n",
    "# Initialize the similarity matrix on the GPU\n",
    "sim_mat = np.zeros((training_features.shape[0], training_features.shape[0]))\n",
    "\n",
    "# Compute the cosine similarity using the GPU\n",
    "for i in tqdm(range(training_features.shape[0])):\n",
    "    for j in range(i):\n",
    "        sim_mat[i, j] = cos_sim(training_features[i], training_features[j])\n",
    "\n",
    "sim_mat = sim_mat + sim_mat.T\n",
    "np.save(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\sim_mat\\similarity_matrix.npy', sim_mat)\n",
    "#sim_mat = np.load(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\sim_mat\\similarity_matrix.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = np.min(np.max(sim_mat, axis=0))\n",
    "#sim_mat = np.where(sim_mat>=threshold,1,0)\n",
    "dim=adjacency_matrix.shape[0]\n",
    "D = np.zeros([dim,dim])\n",
    "for i in range(dim):\n",
    "    D[i,i] = adjacency_matrix[i].sum()\n",
    "L = D- adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = eigsh(L, k=32, which=\"SM\") # overvej max_iter, tolerance?\n",
    "np.save(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\eigenvectors\\eigenvectors_knn.npy', eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors = np.load(r'C:\\Users\\Test\\Desktop\\p7\\Spectral\\eigenvectors\\eigenvectors_knn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m threshold1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m eigenvectors_bin \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mwhere(eigenvectors \u001b[38;5;241m>\u001b[39m threshold1, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "threshold1 = 0\n",
    "eigenvectors_bin = np.where(eigenvectors > threshold1, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier().fit(training_features, eigenvectors_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hashes = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "(10000,)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "print(test_hashes.shape)\n",
    "print(y_test.shape)\n",
    "print(test_hashes[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(test_hashes, labels):\n",
    "    aps = []\n",
    "    for i, test_hash in enumerate(tqdm(test_hashes)):\n",
    "        label = labels[i]\n",
    "        distances = np.abs(test_hashes - test_hashes[i]).sum(axis=1)\n",
    "        tp = np.where(labels==label, 1, 0)\n",
    "        hash_df = pd.DataFrame({\"distances\":distances, \"tp\":tp}).reset_index()\n",
    "        hash_df = hash_df.drop(index=i)\n",
    "        hash_df = hash_df.sort_values([\"distances\", \"index\"]).reset_index(drop=True)\n",
    "        hash_df = hash_df.drop([\"index\", \"distances\"], axis=1).reset_index()\n",
    "        hash_df = hash_df[hash_df[\"tp\"]==1]\n",
    "        hash_df[\"tp\"] = hash_df[\"tp\"].cumsum()\n",
    "        hash_df[\"index\"] = hash_df[\"index\"] +1 \n",
    "        precision = np.array(hash_df[\"tp\"]) / np.array(hash_df[\"index\"])\n",
    "        ap = precision.mean()\n",
    "        aps.append(ap)\n",
    "    \n",
    "    return np.array(aps).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5096208333333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors_bin.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:31<00:00, 318.81it/s]\n"
     ]
    }
   ],
   "source": [
    "aps = mean_average_precision(test_hashes, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maps\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# JEG PREDICTED ET L (BOZOKODE )\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aps' is not defined"
     ]
    }
   ],
   "source": [
    "aps\n",
    "# JEG PREDICTED ET L (BOZOKODE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Kristians hyggekode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tal(sim_mat, bits, threshold):    \n",
    "    dim = sim_mat.shape[0]\n",
    "    #threshold = np.min(np.max(sim_mat, axis=1))\n",
    "\n",
    "    diag = np.sum((sim_mat > threshold), axis=1)\n",
    "    D = np.zeros([dim,dim])\n",
    "    for i in range(dim):\n",
    "        D[i,i] = diag[i]\n",
    "    L = D- sim_mat\n",
    "\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=bits, which=\"SM\")\n",
    "    threshold1 = np.median(eigenvectors)\n",
    "    eigenvectors_bin = np.where(eigenvectors > threshold1, 1, 0)\n",
    "    return eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tbl(sim_mat, bits, threshold):    \n",
    "    dim = sim_mat.shape[0]\n",
    "    #threshold = np.min(np.max(sim_mat, axis=1))\n",
    "\n",
    "    sim_mat = np.where(sim_mat>=threshold,1,0)\n",
    "    D = np.zeros([dim,dim])\n",
    "    for i in range(dim):\n",
    "        D[i,i] = sim_mat[i].sum()\n",
    "    L = D- sim_mat\n",
    "\n",
    "    eigenvalues, eigenvectors_bin = eigsh(L, k=bits, which=\"SM\")\n",
    "    return eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tbl_summed_diag(sim_mat, bits):    \n",
    "    dim = sim_mat.shape[0]\n",
    "\n",
    "    diag = np.sum(sim_mat, axis=1)\n",
    "    D = np.zeros([dim,dim])\n",
    "    for i in range(dim):\n",
    "        D[i,i] = diag[i]\n",
    "    L = D- sim_mat\n",
    "\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=bits, which=\"SM\")\n",
    "    threshold1 = np.median(eigenvectors)\n",
    "    eigenvectors_bin = np.where(eigenvectors > threshold1, 1, 0)\n",
    "    return eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_codes = test_tbl(sim_mat, 32, threshold = np.min(np.max(sim_mat, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(eigenvectors_bin, labels, k):\n",
    "    labels_dic = {i:0 for i in range(10)}\n",
    "    labels_size_dic = {i:0 for i in range(10)}\n",
    "    for i, eigenvector in enumerate(eigenvectors_bin):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for j, eigenvector2 in enumerate(eigenvectors_bin):\n",
    "            if np.abs(eigenvector - eigenvector2).sum() <= k:\n",
    "                if labels[i] == labels[j]:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        labels_dic[labels[i]] += tp/(tp+fp)\n",
    "        labels_size_dic[labels[i]] += 1\n",
    "    ap_dic = {i:labels_dic[i]/labels_size_dic[i] for i in range(10)}\n",
    "    map_value = np.array(list(ap_dic.values())).mean()\n",
    "    return map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_threshold = int(np.round(np.min(np.max(sim_mat, axis=1))*100))\n",
    "min_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(min_threshold,\u001b[38;5;241m95\u001b[39m,\u001b[38;5;241m2\u001b[39m)):\n\u001b[0;32m----> 6\u001b[0m         hashes_tbl \u001b[38;5;241m=\u001b[39m \u001b[43mtest_tbl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbits\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         hashes_tal \u001b[38;5;241m=\u001b[39m test_tal(sim_mat,bits,threshold\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m)   \n\u001b[1;32m      8\u001b[0m         map_tbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(hashes_tbl, labels, k)\n",
      "Cell \u001b[0;32mIn[138], line 11\u001b[0m, in \u001b[0;36mtest_tbl\u001b[0;34m(sim_mat, bits, threshold)\u001b[0m\n\u001b[1;32m      8\u001b[0m     D[i,i] \u001b[38;5;241m=\u001b[39m diag[i]\n\u001b[1;32m      9\u001b[0m L \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m-\u001b[39m sim_mat\n\u001b[0;32m---> 11\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m \u001b[43meigsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m threshold1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(eigenvectors)\n\u001b[1;32m     13\u001b[0m eigenvectors_bin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(eigenvectors \u001b[38;5;241m>\u001b[39m threshold1, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1360\u001b[0m, in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1355\u001b[0m             params\u001b[39m.\u001b[39miterate()\n\u001b[1;32m   1357\u001b[0m         \u001b[39mreturn\u001b[39;00m params\u001b[39m.\u001b[39mextract(return_eigenvectors)\n\u001b[0;32m-> 1360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meigsh\u001b[39m(A, k\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, M\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sigma\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, which\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLM\u001b[39m\u001b[39m'\u001b[39m, v0\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1361\u001b[0m           ncv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, maxiter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tol\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, return_eigenvectors\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1362\u001b[0m           Minv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, OPinv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m \u001b[39m    Find k eigenvalues and eigenvectors of the real symmetric square matrix\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m \u001b[39m    or complex Hermitian matrix A.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m     \u001b[39m# complex Hermitian matrices should be solved with eigs\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\"algorithm\", \"threshold\", \"hamming_distance\", \"bits\", \"map\"])\n",
    "c = 0\n",
    "for bits in [32, 64, 128]:\n",
    "    for k in range(1,4):\n",
    "        for threshold in tqdm(range(min_threshold,95,2)):\n",
    "            hashes_tbl = test_tbl(sim_mat,bits,threshold/100)\n",
    "            hashes_tal = test_tal(sim_mat,bits,threshold/100)   \n",
    "            map_tbl = map(hashes_tbl, labels, k)\n",
    "            map_tal = map(hashes_tal, labels, k)\n",
    "            results_df.loc[c] = [\"tbl\", threshold/100, k, bits, map_tbl]\n",
    "            results_df.loc[c] = [\"tal\", threshold/100, k, bits, map_tal]\n",
    "            c +=1\n",
    "        hashes_tbl_sd = test_tbl(sim_mat,bits,threshold/100)\n",
    "        map_tbl_sd = map(hashes_tbl, labels, k)\n",
    "        results_df.loc[c] = [\"tbl_sd\", pd.NA, k, bits, map_tbl_sd]\n",
    "        c+=1\n",
    "        results_df.to_csv(\"spectral_hashing_test_results.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_tal(images, bits):\n",
    "    dim = images.shape[0]\n",
    "    sim_mat = np.zeros([dim,dim])\n",
    "    for i in tqdm(range(dim)):\n",
    "        for j in range(i):\n",
    "            sim_mat[i, j] = cos_sim(images[i], images[j])\n",
    "    sim_mat = sim_mat + sim_mat.T\n",
    "    \n",
    "    threshold = np.min(np.max(sim_mat, axis=1))\n",
    "\n",
    "    diag = np.sum((sim_mat > threshold), axis=1)\n",
    "    D = np.zeros([dim,dim])\n",
    "    for i in range(dim):\n",
    "        D[i,i] = diag[i]\n",
    "    L = D- sim_mat\n",
    "\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=bits, which=\"SM\")\n",
    "    threshold1 = np.median(eigenvectors)\n",
    "    eigenvectors_bin = np.where(eigenvectors > threshold1, 1, 0)\n",
    "    return eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_tbl(images, bits):\n",
    "    dim = images.shape[0]\n",
    "    sim_mat = np.zeros([dim,dim])\n",
    "    for i in tqdm(range(dim)):\n",
    "        for j in range(i):\n",
    "            sim_mat[i, j] = cos_sim(images[i], images[j])\n",
    "    sim_mat = sim_mat + sim_mat.T\n",
    "    \n",
    "    threshold = np.min(np.max(sim_mat, axis=1))\n",
    "\n",
    "    sim_mat = np.where(sim_mat>=threshold,1,0)\n",
    "    D = np.zeros([dim,dim])\n",
    "    for i in range(dim):\n",
    "        D[i,i] = sim_mat[i].sum()\n",
    "    L = D- sim_mat\n",
    "\n",
    "    eigenvalues, eigenvectors_bin = eigsh(L, k=bits, which=\"SM\")\n",
    "    return eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_tbl_summed_diag(images, bits):\n",
    "    dim = images.shape[0]\n",
    "    sim_mat = np.zeros([dim,dim])\n",
    "    for i in tqdm(range(dim)):\n",
    "        for j in range(i):\n",
    "            sim_mat[i, j] = cos_sim(images[i], images[j])\n",
    "    sim_mat = sim_mat + sim_mat.T\n",
    "    \n",
    "    threshold = np.min(np.max(sim_mat, axis=1))\n",
    "\n",
    "    diag = np.sum(sim_mat, axis=1)\n",
    "    D = np.zeros([dim,dim])\n",
    "    for i in range(dim):\n",
    "        D[i,i] = diag[i]\n",
    "    L = D- sim_mat\n",
    "\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=bits, which=\"SM\")\n",
    "    threshold1 = np.median(eigenvectors)\n",
    "    eigenvectors_bin = np.where(eigenvectors > threshold1, 1, 0)\n",
    "    return eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.min(np.max(sim_mat, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.sum((sim_mat > threshold), axis=1)\n",
    "D = np.zeros([10000,10000])\n",
    "for i in range(10000):\n",
    "    D[i,i] = diag[i]\n",
    "\n",
    "L = D- sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2 = np.sum(sim_mat, axis=1)\n",
    "D2 = np.zeros([10000,10000])\n",
    "for i in range(10000):\n",
    "    D2[i,i] = diag2[i]\n",
    "\n",
    "L2 = D2- sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = eigsh(L, k=32, which=\"SM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues2, eigenvectors2 = eigsh(L2, k=32, which=\"SM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = np.median(eigenvectors)\n",
    "threshold2 = np.median(eigenvectors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors_bin = np.where(eigenvectors > threshold1, 1, 0)\n",
    "eigenvectors_bin2 = np.where(eigenvectors2 > threshold2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 1, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6911\n",
      "3211\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(eigenvectors_bin,axis = 0)))\n",
    "print(len(np.unique(eigenvectors_bin2,axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(eigenvectors_bin, labels, k):\n",
    "    labels_dic = {i:0 for i in range(10)}\n",
    "    labels_size_dic = {i:0 for i in range(10)}\n",
    "    for i, eigenvector in enumerate(tqdm(eigenvectors_bin)):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for j, eigenvector2 in enumerate(eigenvectors_bin):\n",
    "            if np.abs(eigenvector - eigenvector2).sum() <= k:\n",
    "                if labels[i] == labels[j]:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        labels_dic[labels[i]] += tp/(tp+fp)\n",
    "        labels_size_dic[labels[i]] += 1\n",
    "    ap_dic = {i:labels_dic[i]/labels_size_dic[i] for i in range(10)}\n",
    "    map_value = np.array(list(ap_dic.values())).mean()\n",
    "    return map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:08<00:00, 40.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7537130294700397"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(eigenvectors_bin, labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:03<00:00, 41.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37877593377796936"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(eigenvectors_bin2, labels, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
