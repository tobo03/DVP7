import pandas as pd
import numpy as np
from tqdm import tqdm
from scipy.sparse.linalg import eigsh
#from pretrainedModel import pretrainedModel
#from tensorflow import keras
from PIL import Image
from sklearn.preprocessing import StandardScaler
#import torch
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix
import time
import warnings
from sklearn.cluster import KMeans
import sys
import optuna
import os
import metrics_final # add 
from sklearn.model_selection import train_test_split
import datetime
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset, TensorDataset
import random
import numpy as np
from sklearn.decomposition import PCA
from typing import Tuple
from tqdm import tqdm
from scipy.spatial import distance_matrix
import pandas as pd

subic_hpo_dic = {12:{"Cifar":[4, 3, 0.005, 0.2], "Nus_Wide":[4, 3, 0.001, 0.4], "Imagenet":[4, 3, 0.001, 0.4]},
                   24:{"Cifar":[6, 4, 0.005, 0.6], "Nus_Wide":[6, 4, 0.001, 0.2], "Imagenet":[6, 4, 0.0001, 0.2]},
                   32:{"Cifar":[16, 2, 0.001, 0.6], "Nus_Wide":[16, 2, 0.001, 0.2], "Imagenet":[8, 4, 0.001, 0.4]},
                   48:{"Cifar":[12, 4, 0.0001, 0.2], "Nus_Wide":[12, 4, 0.0001, 0.2], "Imagenet":[24, 2, 0.0001, 0.8]}}

class SUBIC_encoder(nn.Module): 
    def __init__(self, input_size=4096, bits=48, num_classes=10, num_blocks=8, block_size=6):
        super(SUBIC_encoder, self).__init__()
       
        assert bits % num_blocks == 0, "Bits must be divisible by num_blocks"

        self.input_size = input_size
        self.bits = bits 
        self.num_blocks = num_blocks
        self.block_size = block_size
        

        # Define the encoder structure
        self.encoder = nn.Sequential(
            nn.Linear(input_size, 256), 
            nn.ReLU(),
            nn.Linear(256, bits)
        )  # Outputs binary feature vectors
        
        self.fc3 = nn.Linear(bits, num_classes)  # Logits for num_classes
    
    def block_softmax(self, x):
        
        batch_size = x.shape[0]
        block_size = x.shape[1] // self.num_blocks
        
        # Ensure that x has the expected shape
        assert x.shape[1] == self.bits, f"Expected shape [batch_size, {self.bits}], got {x.shape}"
        
        # Reshape and apply softmax
        x = x.view(batch_size, self.num_blocks, block_size)
        x = F.softmax(x, dim=-1) 
        return x.view(batch_size, -1) #-1 refers to the value that will match the original elements 
    
    def block_one_hot(self, x):
        batch_size = x.shape[0]

        x = x.view(batch_size, self.num_blocks, self.block_size)
        max_indices = x.argmax(dim=-1, keepdim=True)
        
        # Create one-hot encoding
        one_hot = torch.zeros_like(x).scatter_(-1, max_indices, 1)

        return one_hot.view(batch_size, self.bits)
    
    def forward(self, x, use_one_hot=False):
        # Ensure x is a flat tensor before passing to encoder
        batch_size = x.shape[0] if x.dim() > 1 else 1
        x = x.view(batch_size, -1)  # Flatten if necessary

        z = self.encoder(x)

        if use_one_hot:
            binary_codes = self.block_one_hot(z)
        else:
            binary_codes = self.block_softmax(z)

        class_probs = F.softmax(self.fc3(binary_codes), dim=-1) 

        return class_probs, binary_codes


def entropy(p):
    entropy_result = -torch.sum(p * torch.log2(p + 1e-30), dim=-1)
    return entropy_result


def cross_entropy(class_prob, target):
    if len(target.shape) >1:
        s = (class_prob*target).mean(axis=1)
    else:
        s = class_prob[torch.arange(len(target)), target]
    return -torch.log2(s)/torch.log2(torch.FloatTensor([class_prob.shape[1]]))

def compute_total_loss(class_probs, target, binary_codes, num_blocks, block_size, gamma=0.5, mu=0.5):
    """
    Computes the total loss, which includes:
    - Cross-entropy classification loss
    - Mean entropy loss (encouraging one-hot encoding within each block)
    - Batch entropy loss (encouraging uniform distribution across blocks)
    
    Parameters:
    - class_probs: The class probabilities from the classification layer.
    - target: The true labels.
    - binary_codes: The binary codes generated by the encoder.
    - num_blocks: The number of blocks in the binary codes.
    - block_size: The size of each block in the binary codes.
    - gamma: Weight for the mean entropy loss.
    - mu: Weight for the batch entropy loss.
    
    """



    classification_loss = cross_entropy(class_probs, target)

    batch_size = binary_codes.shape[0]
    binary_codes = binary_codes.view(batch_size, num_blocks, block_size) #used in structure encoding



    #Mean Entropy Loss (encourages each block to resemble a one-hot vector) using softmax binary code
    mean_entropy_loss = entropy(binary_codes).mean(dim=1)

    #Batch Entropy Loss (encourages uniform distribution across blocks)
    average_support = binary_codes.mean(dim=0)  
    batch_entropy_loss = entropy(average_support).mean(dim=0)

    #Combine losses with weights gamma and mu
    entropy_loss = (gamma * mean_entropy_loss - mu * batch_entropy_loss)/torch.log2(torch.FloatTensor([block_size]))
    total_loss = (classification_loss + entropy_loss).mean()
    
    
    return total_loss



def train_subic(X_train, y_train, epochs, bits, num_blocks, block_size, lr, gamma_mu):
    X_train_tensor = torch.tensor(X_train)
    y_train_tensor = torch.tensor(y_train, dtype=torch.long)
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    model = SUBIC_encoder(bits = bits, input_size=X_train.shape[1], num_classes = y_train.shape[-1], num_blocks=num_blocks, block_size=block_size)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    losses = []

    for epoch in range(epochs):
        model.train()
        total_loss = 0.0

        for images, labels in train_loader:
            
            images, labels = images.to(device), labels.to(device)
            class_probs, binary_codes = model.forward(images, use_one_hot=False)


            # Compute loss and update model
            loss = compute_total_loss(class_probs, labels, binary_codes, num_blocks=16, block_size=3, gamma=gamma_mu, mu=gamma_mu)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
        losses.append(total_loss / len(train_loader))
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}")
    return model


results_df = pd.DataFrame(columns=["dataset", "bits", "training_time", "query_time", "map", "p@k_1", "p@k_2", "p@k_3", "p@0", "p@1", "p@2", "p@3"])

model_name = "subic"

bits = [12, 24,32, 48] #  udkommenteret.

names = ["Cifar","Nus_Wide","Imagenet"]

def load_data(i):
    dir_list = [r"c:\Users\Test\Desktop\FINAL P7 FEATURES !!!!\Cifar",r"C:\Users\Test\Desktop\FINAL P7 FEATURES !!!!\Nus Wide",r"C:\Users\Test\Desktop\FINAL P7 FEATURES !!!!\Imagenet"]
    print(datetime.datetime.now())
    data_dir = dir_list[i]
    names = ["Cifar","Nus_Wide","Imagenet"]
    # Iterate over the files in the directory
    for filename in os.listdir(dir_list[i]):
        if "X_train" in filename:
            training = np.load(os.path.join(data_dir, filename))
            #database = database[:55000]
            print(f"Loaded {filename} into X_train")
        elif "y_train" in filename:
            training_labels = np.load(os.path.join(data_dir, filename))
            #database_labels = database_labels[:55000]
            print(f"Loaded {filename} into y_train")
        elif "X_test" in filename:
            query = np.load(os.path.join(data_dir, filename)) 
            print(f"query len: {len(query)}")
            print(f"Loaded {filename} into X_test")
        elif "y_test" in filename:
            query_labels = np.load(os.path.join(data_dir, filename))
            #print(np.sum(query_labels,axis = 0))
            #print(query_labels[:5])

            print(f"Loaded {filename} into y_test")
    return training, training_labels, query, query_labels


for i in range(2): # QUick fix to run it just once (Image)

    database, database_labels, query, query_labels = load_data(i)
            

    if i ==2:
        ks = [10000, 50000, 100000]
        _, database, _, database_labels = train_test_split(database, database_labels, train_size=1-0.10, random_state=42, stratify=database_labels)
        _ = 0
      

    else: 
        ks = [1000, 5000, 10000]
        #database = training
        #database_labels = training_labels

    dists = [0,1,2,3]

    for bit in bits:
        pr_df = pd.DataFrame(columns=["precision", "recall"])
        print(names[i], bit)
        training_time_start = time.time()
        #train model
        model = train_subic(database, database_labels, 100, bit, subic_hpo_dic[bit][names[i]][0], subic_hpo_dic[bit][names[i]][1], subic_hpo_dic[bit][names[i]][2], subic_hpo_dic[bit][names[i]][3])
        training_time = time.time() - training_time_start 

        #run database through model
        print("model_training done")
        database_hashes = model.forward(database).detach().numpy()
        #run query set through model
        query_hashes = model.forward(query).detach().numpy()

        print("map")
        st = time.time()
        map_score = metrics_final.meanAveragePrecisionOptimized(query_hashes, database_hashes, query_labels, database_labels)
        print(f"time optimized map {time.time() - st}")
        print(map_score)

        #st = time.time()
       # map_score_2 = metrics.meanAveragePrecision(query_hashes, database_hashes, query_labels, database_labels)
        # print(f"time normal map {time.time() - st}")
       # print(map_score_2)

        print("p@k")
        p_at_k = metrics_final.p_at_k_optimized(query_hashes, database_hashes, query_labels, database_labels, ks)
        print("p@d")
        p_at_dist = metrics_final.p_at_dist_optimized(query_hashes, database_hashes, query_labels, database_labels, dists) # add optimized!!! 
        print("precision recall")
        _, pr_query_hashes, _, pr_query_labels = train_test_split(query_hashes, query_labels, train_size=1-0.10, random_state=42, stratify=query_labels)
        recall, precision = metrics_final.interpolated_pr_curve_optimized(pr_query_hashes, database_hashes, pr_query_labels, database_labels, num_points=100) # add optimized 
            
        print("query time")
        database, database_labels, query, query_labels = load_data(i)
        database = model.forward(database).detach().numpy()

        query_image = query[22]
        query_time_start = time.time()
        # run single image thorugh model
        query_hash = model.forward(query_image).detach().numpy()
        images = metrics_final.query_optimized(query_hash, database)
        query_time = time.time() - query_time_start
        database = 0
        if i ==2 and bit==48:
            images = images[:5]
            np.save(fr"C:\Users\Test\Desktop\Local_folder\Result_folder\query_{model_name}_5_images.npy", images)
            np.save(fr"C:\Users\Test\Desktop\Local_folder\Result_folder\Hash_codes_query_{model_name}_all_images.numpy",query_hashes)

        if i == 0 and bit == 48:
           np.save(fr"C:\Users\Test\Desktop\Local_folder\Result_folder\tsne_{model_name}_hashes.npy",query_hashes)

            
        results_df.loc[results_df.shape[0]] = (names[i], bit, training_time, query_time, map_score) + p_at_k + p_at_dist
        results_df.to_csv(f"{model_name}_{names[i]}_testing.csv", index=False) # addet csv

        pr_df = pd.DataFrame(data=np.array([precision, recall]).T, columns=["precision", "recall"])
        pr_df.to_csv(f"{model_name}_{names[i]}_{bit}_pr_curve.csv") # addet csv 
        print(datetime.datetime.now())

        
